--- CONTEXTO DEL PROYECTO ---
Estructura de archivos aplanada para an√°lisis.


==================================================
ARCHIVO: launch.json
==================================================
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug API",
      "type": "python",
      "request": "launch",
      "module": "app.main",
      "cwd": "${workspaceFolder}"
    },
    {
      "name": "Debug sync",
      "type": "python",
      "request": "launch",
      "module": "app.jobs.sync",
      "cwd": "${workspaceFolder}"
    }
  ]
}

==================================================
ARCHIVO: notas.md
==================================================
"id": 2142,
    "code": "003310",
    "name": "Juan Carlos Gonzalez",
    "tax_residence": "Amenabar 123",
    "type": "no_fiscal_invoice",
    "tax_situation_id": 4,
    "identification_type_id": 7,
    "doc_number": "99123123",
    "auto_bill_sending": 1,
    "auto_payment_recipe_sending": 1,
    "nickname": null,
    "comercial_activity": null,
    "address": "Amenabar 123",
    "between_address1": null,
    "between_address2": null,
    "city_id": 1,
    "lat": "-33.1234546",
    "lng": "-65.1235016",
    "extra1": null,
    "extra2": null,
    "entity_id": 2,
    "collector_id": 44,
    "seller_id": 33,
    "block": 1,
    "free": 0,
    "apply_late_payment_due": 1,
    "apply_reconnection": 1,
    "contract": 1,
    "contract_type_id": null,
    "contract_expiration_date": null,
    "paycomm": null,
    "expiration_type_id": 1,
    "business_id": 1,
    "first_expiration_date": null,
    "second_expiration_date": null,
    "next_month_corresponding_date": 0,
    "start_date": "2022-09-01 00:00:00",
    "perception_id": null,
    "phonekey": null,
    "debt": "0.00",
    "duedebt": "0.00",
    "speed_limited": 0,
    "status": "enabled",
    "enable_date": null,
    "block_date": null,
    "created_at": "2022-09-01T15:20:49.000000Z",
    "updated_at": "2022-09-01T15:57:52.000000Z",
    "deleted_at": null,
    "temporary": 0,
    "tax_situation": {
      "id": 4,
      "name": "Consumidor Final",
      "selected": ""
    },
    "identification_type": {
      "id": 7,
      "name": "DNI"
    },
    "city": {
      "id": 1,
      "name": "Barrio Numero 1"
    },
    "entity": {
      "id": 2,
      "name": "Caja",
      "tags_ids": [
        "[]"
      ],
      "selected_default": true,
      "tags": []
    },
    "contact_emails": [
      {
        "customer_id": 2142,
        "email": "cliente@gmail.com"
      }
    ],
    "phones": [
      {
        "customer_id": 2142,
        "number": "119876543"
      }
    ],
    "business": {
      "id": 1,
      "name": "Empresa SRL"
    }
  }
]

==================================================
ARCHIVO: README.md
==================================================
# Beholder

Beholder es un servicio de diagn√≥stico centralizado para ISP.  
Su objetivo es unificar consultas t√©cnicas a SmartOLT, Mikrotik y GenieACS, resolviendo diagn√≥sticos de clientes a partir de su usuario PPPoE.

## ‚ú® Caracter√≠sticas
- API HTTP basada en FastAPI.
- Endpoint `/diagnostico?pppoeUser=...` que devuelve panorama t√©cnico.
- Sincronizaci√≥n diaria de suscriptores desde SmartOLT.
- Base local (SQLite/Redis) para lookups r√°pidos.
- Seguridad con API key y rate limiting.
- Logs estructurados con Loguru.

## üìÇ Estructura del proyecto

beholder
 ‚îú‚îÄ readme.md
 ‚îú‚îÄ requirements.txt
 ‚îú‚îÄ test.http
 ‚îú‚îÄ app/
 ‚îÇ   ‚îú‚îÄ __init__.py
 ‚îÇ   ‚îú‚îÄ config.py
 ‚îÇ   ‚îú‚îÄ main.py
 ‚îÇ   ‚îî‚îÄ nightly.py
 ‚îú‚îÄ config/
 ‚îÇ   ‚îî‚îÄ .env
 ‚îú‚îÄ data/
 ‚îÇ   ‚îî‚îÄ diag.db
 ‚îî‚îÄ services/
     ‚îú‚îÄ __init__.py
     ‚îú‚îÄ ispcube.py
     ‚îú‚îÄ mikrotik.py
     ‚îî‚îÄ smartolt.py



beholder/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI app principal
‚îÇ   ‚îú‚îÄ‚îÄ config.py        # carga de variables .env
‚îÇ   ‚îú‚îÄ‚îÄ security.py      # API key + rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ models.py        # esquemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ services/        # l√≥gica de diagn√≥stico
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ diagnostico.py
‚îÇ   ‚îú‚îÄ‚îÄ clients/         # conectores a APIs externas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smartolt.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mikrotik.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ genieacs.py
‚îÇ   ‚îú‚îÄ‚îÄ db/              # acceso a base local
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sqlite.py
‚îÇ   ‚îî‚îÄ‚îÄ jobs/            # tareas programadas
‚îÇ       ‚îî‚îÄ‚îÄ sync_smartolt.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ .env.example     # variables de entorno
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py      # pruebas unitarias
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore

## üöÄ Uso r√°pido

Levantar el servicio en modo desarrollo:

```bash
uvicorn app.main:app --reload --port 8088

curl -H "x-api-key: your-key" "http://127.0.0.1:8088/diagnostico?pppoeUser=usuarioprueba"


http://127.0.0.1:8088/health

==================================================
ARCHIVO: requirements.txt
==================================================
# Requisitos del proyecto Beholder
RouterOS-api==0.21.0

# Framework web
fastapi==0.115.0
uvicorn[standard]==0.30.0

# Base de datos


# Cliente Mikrotik
RouterOS-api==0.21.0

# Logging y utilidades
python-dotenv==1.0.1    # para manejar variables de entorno (.env)
loguru==0.7.2
# Dependencias comunes
requests==2.32.3        # para llamadas HTTP (SmartOLT, ISPCube)

==================================================
ARCHIVO: TODO_EL_PROYECTO.txt
==================================================


==================================================
ARCHIVO: TODO_EL_PROYECTO_backend.txt
==================================================
--- CONTEXTO DEL PROYECTO ---
Estructura de archivos aplanada para an√°lisis.


==================================================
ARCHIVO: launch.json
==================================================
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug API",
      "type": "python",
      "request": "launch",
      "module": "app.main",
      "cwd": "${workspaceFolder}"
    },
    {
      "name": "Debug sync",
      "type": "python",
      "request": "launch",
      "module": "app.jobs.sync",
      "cwd": "${workspaceFolder}"
    }
  ]
}

==================================================
ARCHIVO: notas.md
==================================================
"id": 2142,
    "code": "003310",
    "name": "Juan Carlos Gonzalez",
    "tax_residence": "Amenabar 123",
    "type": "no_fiscal_invoice",
    "tax_situation_id": 4,
    "identification_type_id": 7,
    "doc_number": "99123123",
    "auto_bill_sending": 1,
    "auto_payment_recipe_sending": 1,
    "nickname": null,
    "comercial_activity": null,
    "address": "Amenabar 123",
    "between_address1": null,
    "between_address2": null,
    "city_id": 1,
    "lat": "-33.1234546",
    "lng": "-65.1235016",
    "extra1": null,
    "extra2": null,
    "entity_id": 2,
    "collector_id": 44,
    "seller_id": 33,
    "block": 1,
    "free": 0,
    "apply_late_payment_due": 1,
    "apply_reconnection": 1,
    "contract": 1,
    "contract_type_id": null,
    "contract_expiration_date": null,
    "paycomm": null,
    "expiration_type_id": 1,
    "business_id": 1,
    "first_expiration_date": null,
    "second_expiration_date": null,
    "next_month_corresponding_date": 0,
    "start_date": "2022-09-01 00:00:00",
    "perception_id": null,
    "phonekey": null,
    "debt": "0.00",
    "duedebt": "0.00",
    "speed_limited": 0,
    "status": "enabled",
    "enable_date": null,
    "block_date": null,
    "created_at": "2022-09-01T15:20:49.000000Z",
    "updated_at": "2022-09-01T15:57:52.000000Z",
    "deleted_at": null,
    "temporary": 0,
    "tax_situation": {
      "id": 4,
      "name": "Consumidor Final",
      "selected": ""
    },
    "identification_type": {
      "id": 7,
      "name": "DNI"
    },
    "city": {
      "id": 1,
      "name": "Barrio Numero 1"
    },
    "entity": {
      "id": 2,
      "name": "Caja",
      "tags_ids": [
        "[]"
      ],
      "selected_default": true,
      "tags": []
    },
    "contact_emails": [
      {
        "customer_id": 2142,
        "email": "cliente@gmail.com"
      }
    ],
    "phones": [
      {
        "customer_id": 2142,
        "number": "119876543"
      }
    ],
    "business": {
      "id": 1,
      "name": "Empresa SRL"
    }
  }
]

==================================================
ARCHIVO: README.md
==================================================
# Beholder

Beholder es un servicio de diagn√≥stico centralizado para ISP.  
Su objetivo es unificar consultas t√©cnicas a SmartOLT, Mikrotik y GenieACS, resolviendo diagn√≥sticos de clientes a partir de su usuario PPPoE.

## ‚ú® Caracter√≠sticas
- API HTTP basada en FastAPI.
- Endpoint `/diagnostico?pppoeUser=...` que devuelve panorama t√©cnico.
- Sincronizaci√≥n diaria de suscriptores desde SmartOLT.
- Base local (SQLite/Redis) para lookups r√°pidos.
- Seguridad con API key y rate limiting.
- Logs estructurados con Loguru.

## üìÇ Estructura del proyecto

beholder
 ‚îú‚îÄ readme.md
 ‚îú‚îÄ requirements.txt
 ‚îú‚îÄ test.http
 ‚îú‚îÄ app/
 ‚îÇ   ‚îú‚îÄ __init__.py
 ‚îÇ   ‚îú‚îÄ config.py
 ‚îÇ   ‚îú‚îÄ main.py
 ‚îÇ   ‚îî‚îÄ nightly.py
 ‚îú‚îÄ config/
 ‚îÇ   ‚îî‚îÄ .env
 ‚îú‚îÄ data/
 ‚îÇ   ‚îî‚îÄ diag.db
 ‚îî‚îÄ services/
     ‚îú‚îÄ __init__.py
     ‚îú‚îÄ ispcube.py
     ‚îú‚îÄ mikrotik.py
     ‚îî‚îÄ smartolt.py



beholder/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI app principal
‚îÇ   ‚îú‚îÄ‚îÄ config.py        # carga de variables .env
‚îÇ   ‚îú‚îÄ‚îÄ security.py      # API key + rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ models.py        # esquemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ services/        # l√≥gica de diagn√≥stico
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ diagnostico.py
‚îÇ   ‚îú‚îÄ‚îÄ clients/         # conectores a APIs externas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smartolt.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mikrotik.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ genieacs.py
‚îÇ   ‚îú‚îÄ‚îÄ db/              # acceso a base local
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sqlite.py
‚îÇ   ‚îî‚îÄ‚îÄ jobs/            # tareas programadas
‚îÇ       ‚îî‚îÄ‚îÄ sync_smartolt.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ .env.example     # variables de entorno
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py      # pruebas unitarias
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore

## üöÄ Uso r√°pido

Levantar el servicio en modo desarrollo:

```bash
uvicorn app.main:app --reload --port 8088

curl -H "x-api-key: your-key" "http://127.0.0.1:8088/diagnostico?pppoeUser=usuarioprueba"


http://127.0.0.1:8088/health

==================================================
ARCHIVO: requirements.txt
==================================================
# Requisitos del proyecto Beholder
RouterOS-api==0.21.0

# Framework web
fastapi==0.115.0
uvicorn[standard]==0.30.0

# Base de datos


# Cliente Mikrotik
RouterOS-api==0.21.0

# Logging y utilidades
python-dotenv==1.0.1    # para manejar variables de entorno (.env)
loguru==0.7.2
# Dependencias comunes
requests==2.32.3        # para llamadas HTTP (SmartOLT, ISPCube)

==================================================
ARCHIVO: TODO_EL_PROYECTO.txt
==================================================


==================================================
ARCHIVO: app\config.py
==================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv(dotenv_path=os.path.join("config", ".env"))

# Variables de entorno
API_KEY = os.getenv("API_KEY")
SMARTOLT_BASEURL = os.getenv("SMARTOLT_BASEURL")
SMARTOLT_TOKEN = os.getenv("SMARTOLT_TOKEN")
MK_HOST = os.getenv("MK_HOST")
MK_USER = os.getenv("MK_USER")
MK_PASS = os.getenv("MK_PASS")
MK_PORT = int(os.getenv("MK_PORT", 8799))
GENIEACS_URL = os.getenv("GENIEACS_URL")
ISPCUBE_BASEURL=os.getenv("ISPCUBE_BASEURL")
ISPCUBE_APIKEY=os.getenv("ISPCUBE_APIKEY")
ISPCUBE_USER=os.getenv("ISPCUBE_USER")
ISPCUBE_PASSWORD=os.getenv("ISPCUBE_PASSWORD")
ISPCUBE_CLIENTID=os.getenv("ISPCUBE_CLIENTID")

DB_PATH = os.path.abspath(os.getenv("DB_PATH", "data/diag.db"))

# Crear carpeta data/ si no existe
db_dir = os.path.dirname(DB_PATH)
if not os.path.exists(db_dir):
    os.makedirs(db_dir, exist_ok=True)

# Logging centralizado
log_dir = os.path.join(db_dir, "logs")
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(log_dir, "sync.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("beholder")

==================================================
ARCHIVO: app\main.py
==================================================

from fastapi import FastAPI, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
from app import config
from app.services.diagnostico import consultar_diagnostico
from app.security import get_api_key
from fastapi import FastAPI, Depends
from app.config import logger
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Beholder - Diagn√≥stico Centralizado")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # o ["http://localhost:5173"] si quer√©s restringir
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
def startup_event():
    config.logger.info("Servicio Beholder iniciado.")

# API key middleware (modificado para permitir OPTIONS)
@app.middleware("http")
async def check_api_key(request: Request, call_next):
    if request.method == "OPTIONS":
        return await call_next(request)

    key = request.headers.get("x-api-key")
    if key != config.API_KEY:
        return JSONResponse(status_code=401, content={"detail": "unauthorized"})

    return await call_next(request)


@app.get("/health")
def health():
    return {"ok": True, "service": "beholder", "status": "running"}

@app.get("/diagnosis/{pppoe_user}")
def diagnosis(pppoe_user: str):
    try:
        row = consultar_diagnostico(pppoe_user)
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}")
        raise HTTPException(status_code=500, detail=str(e))
    if "error" in row:
        raise HTTPException(status_code=404, detail=row["error"])
    return row

    
    # row = consultar_diagnostico(pppoe_user)
    # if "error" in row:
    #     return JSONResponse(status_code=404, content={"detail": row["error"]})
    # return row  # devuelve el dict completo con claves sem√°nticas

@app.get("/")
def read_root(api_key: str = Depends(get_api_key)):
    return {"status": "ok", "service": "Beholder API"}


==================================================
ARCHIVO: app\security.py
==================================================
import os
from fastapi import FastAPI, Depends, HTTPException, Security
from fastapi.security.api_key import APIKeyHeader
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")
api_key_header = APIKeyHeader(name="X-API-Key")

def get_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="unauthorized")
    return api_key

==================================================
ARCHIVO: app\clients\ispcube.py
==================================================

import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call

ISPCUBE_BASEURL = config.ISPCUBE_BASEURL
ISPCUBE_APIKEY = config.ISPCUBE_APIKEY
ISPCUBE_USER = config.ISPCUBE_USER
ISPCUBE_PASSWORD = config.ISPCUBE_PASSWORD
ISPCUBE_CLIENTID = config.ISPCUBE_CLIENTID

# Cache interno del token
_token_cache = None


def _obtener_token():
    """Solicita un nuevo token a ISPCube."""
    url = f"{ISPCUBE_BASEURL}/sanctum/token"
    payload = {"username": ISPCUBE_USER, "password": ISPCUBE_PASSWORD}
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api"
    }
    resp = requests.post(url, json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()["token"]


def _get_token(force_refresh=False):
    """Devuelve un token v√°lido, renovando si es necesario."""
    global _token_cache
    if force_refresh or _token_cache is None:
        _token_cache = _obtener_token()
    return _token_cache

def _headers(token=None):
    """Headers est√°ndar para todas las llamadas."""
    return {
        "Authorization": f"Bearer {token or _get_token()}",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api",
        "Accept": "application/json",
        "username": ISPCUBE_USER
    }


def _request(method, url, **kwargs):
    """
    Wrapper de requests que maneja expiraci√≥n de token.
    Si recibe 401, renueva token y reintenta una vez.
    """
    token = _get_token()
    headers = kwargs.pop("headers", {})
    headers.update(_headers(token))
    resp = requests.request(method, url, headers=headers, **kwargs)
    if resp.status_code == 401:
        # Token expirado ‚Üí renovar y reintentar
        logger.warning("Token expirado, renovando...")
        token = _get_token(force_refresh=True)
        headers.update(_headers(token))
        resp = requests.request(method, url, headers=headers, **kwargs)
    resp.raise_for_status()
    return resp

# ------------------ Funciones p√∫blicas ------------------

def obtener_nodos():
    """Devuelve lista de nodos con id, name, ip."""
    url = f"{ISPCUBE_BASEURL}/nodes/nodes_list"
    resp = _request("GET", url)
    body = resp.json()
    items = body["data"] if isinstance(body, dict) and "data" in body else body
    nodos = []
    for n in items:
        nodos.append({
            "id": n.get("id"),
            "name": n.get("comment"),
            "ip": n.get("ip"),
            "puerto": n.get("port")
        })
    return nodos


def obtener_conexion(pppoe):
    """Busca conexi√≥n por PPPoE y devuelve (conn_id, nodo_actual)."""
    url = f"{ISPCUBE_BASEURL}/connections?pppoe={pppoe}"
    resp = _request("GET", url)
    data = resp.json()
    if data:
        conn = data[0]
        return conn["id"], conn.get("node_id")
    logger.error(f"No se encontr√≥ conexi√≥n en ISPCube para {pppoe}")


def obtener_conexion_por_pppoe(pppoe_user):
    """
    Busca cliente por PPPoE y devuelve (conn_id, nodo_actual).
    """
    url = f"{ISPCUBE_BASEURL}/connection?user={pppoe_user}"
    resp = _request("GET", url)
    cliente = resp.json()

    conexiones = cliente.get("connections", [])
    if not conexiones:
        logger.error(f"No se encontraron conexiones para PPPoE {pppoe_user}")

    for conn in conexiones:
        if conn.get("conntype") == "pppoe" and conn.get("user") == pppoe_user:
            return conn["id"], conn.get("node_id")

    logger.error(f"No se encontr√≥ conexi√≥n PPPoE exacta para {pppoe_user}")


def obtener_todas_conexiones():
    """
    Devuelve lista de conexiones con datos b√°sicos:
    user (PPPoE), customer_id, id (conn_id), node_id, plan_id.
    """
    url = f"{ISPCUBE_BASEURL}/connections/connections_list"
    resp = _request("GET", url)
    conexiones = resp.json()

    if not isinstance(conexiones, list):
        logger.error("Respuesta inesperada de ISPCube al listar conexiones")

    resultado = []
    for c in conexiones:
        if c.get("conntype") == "pppoe":
            resultado.append({
                "user": c.get("user"),
                "customer_id": c.get("customer_id"),
                "id": c.get("id"),
                "node_id": c.get("node_id"),
                "plan_id": c.get("plan_id"),
                "direccion": c.get("address")
            })
    return resultado


def obtener_planes():
    """
    Devuelve lista de planes con id, nombre, velocidad y descripci√≥n.
    """
    url = f"{ISPCUBE_BASEURL}/plans/plans_list"
    resp = _request("GET", url)
    planes = resp.json()

    if not isinstance(planes, list):
        logger.error("Respuesta inesperada de ISPCube al listar planes")

    resultado = []
    for p in planes:
        resultado.append({
            "id": p.get("id"),
            "name": p.get("name"),
            "speed": p.get("speed"),
            "comment": p.get("comment")
        })
    return resultado

def obtener_clientes():
    """
    Devuelve lista completa de clientes desde ISPCube.
    Incluye todos los campos que el endpoint expone.
    """
    url = f"{ISPCUBE_BASEURL}/customers/customers_list"
    resp = _request("GET", url)
    data = resp.json()

    if not isinstance(data, list):
        logger.error("Respuesta inesperada de ISPCube al listar clientes")
        return []

    return data



==================================================
ARCHIVO: app\clients\mikrotik.py
==================================================
import time
from app.config import logger
from app.utils.safe_call import safe_call
from routeros_api import RouterOsApiPool
from app import config

# Credenciales comunes para todos los Mikrotik
MIKROTIK_USER = config.MK_USER
MIKROTIK_PASS = config.MK_PASS
MIKROTIK_PORT = config.MK_PORT   # üëà tu puerto personalizado
MIKROTIK_IP   = config.MK_HOST  

#Nota para producci√≥n: borrar =MIKROTIK_IP y pasar IP como par√°metro en cada funci√≥n

def _connect(router_ip, port, username=MIKROTIK_USER, password=MIKROTIK_PASS):
    try:
        pool = RouterOsApiPool(
            router_ip,
            username=username, # type: ignore
            password=password, # type: ignore
            port=port,              
            plaintext_login=True
        )
        return pool, pool.get_api()
    except Exception as e:
        logger.error(f"Error de conexi√≥n al router {router_ip}: {e}")
        return {"error": str(e)}

def obtener_secret(router_ip, pppoe_user, puerto): #MIKROTIK_IP, router_ip
    try:
        pool, api = _connect(router_ip, puerto)
        secrets = api.get_resource('/ppp/secret')
        result = secrets.get(name=pppoe_user)
        pool.disconnect()
        if not result:
            logger.error(f"Secret {pppoe_user} no encontrado en {router_ip}")
        return result[0]
    except Exception as e:
        logger.error(f"Error al obtener secret {pppoe_user} en {router_ip}: {e}")
        return {"error": str(e)}
    
# def crear_secret(router_ip, datos_secret):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     secrets.add(
#         name=datos_secret['name'] + "R", # Borrar la "R" para producci√≥n
#         password=datos_secret['password'],
#         profile=datos_secret.get('profile', 'default'),
#         service=datos_secret.get('service', 'pppoe')
#     )
#     pool.disconnect()
#     logger.info(f"Secret {datos_secret['name']} creado en {router_ip}")

# def borrar_secret(router_ip, pppoe_user):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     result = secrets.get(name=pppoe_user)
#     if result:
#         secret = result[0]
#         secret_id = secret.get('.id') or secret.get('id')

#         #id=result[0]['.id']
#         secrets.remove(id=secret_id)
#         logger.info(f"Secret {pppoe_user} eliminado de {router_ip}")
#     pool.disconnect()

# def migrar_secret(origen_ip, destino_ip, pppoe_user):
   
#     datos = obtener_secret(origen_ip, pppoe_user)


#     crear_secret(destino_ip, datos)
#     # Validaci√≥n inicial
#     if not validar_pppoe(destino_ip, pppoe_user):
#         logger.info(f"Esperando 60s para revalidar {pppoe_user} en {destino_ip}...")
#         time.sleep(60)

#         # Segundo intento
#         if not validar_pppoe(destino_ip, pppoe_user):
#             logger.error(f"‚ùå {pppoe_user} no levant√≥ en {destino_ip}, rollback.")
#             #borrar_secret(destino_ip, pppoe_user)
#             return False

#     # Si lleg√≥ ac√°, est√° online ‚Üí borrar en origen
#     borrar_secret(origen_ip, pppoe_user)
#     logger.info(f"‚úÖ {pppoe_user} migrado de {origen_ip} a {destino_ip}")
#     return True


# def rollback_secret(origen_ip, destino_ip, pppoe_user):
    
#     origen_ip = MIKROTIK_IP #borrar para producci√≥n
#     destino_ip = MIKROTIK_IP #borrar para producci√≥n

#     datos = obtener_secret(destino_ip, pppoe_user)
#     crear_secret(origen_ip, datos)
#     borrar_secret(destino_ip, pppoe_user)
#     return True

def validar_pppoe(router_ip: str, pppoe_user: str, puerto: str) -> dict:
    try:
        pool, api = _connect(router_ip, puerto)
        #pool, api = _connect(MIKROTIK_IP) #borrar para producci√≥n
        activos = api.get_resource('/ppp/active')
        result = activos.get(name=pppoe_user)
        pool.disconnect()

        if result:
            logger.info(f"PPP user {pppoe_user} activo en {router_ip}")
            return {"active": True, **result[0]}
        else:
            logger.warning(f"PPP user {pppoe_user} NO activo en {router_ip}")
            try:
                #modificar aca
                secret = obtener_secret(router_ip, pppoe_user, puerto)
                return {"active": False, "secret": secret}
            except Exception:
                return {"active": False}
    except Exception as e:
        logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
        return {"active": False, "error": str(e)}
        # Si no est√° activo y no se encuentra el secret, no se puede obtener m√°s info
# def validar_pppoe(router_ip: str, pppoe_user: str) -> dict:
#     try:
#         pool, api = _connect(router_ip)
#         activos = api.get_resource('/ppp/active')
#         result = activos.get(name=pppoe_user)
#         pool.disconnect()

#         if result:
#             # Tomamos el primer dict y lo expandimos directamente
#             return {"active": True, **result[0]}
#         else:
#             return {"active": False}
#     except Exception as e:
#         logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
#         return {"active": False, "error": str(e)}


==================================================
ARCHIVO: app\clients\smartolt.py
==================================================
import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call 

SMARTOLT_BASEURL = config.SMARTOLT_BASEURL
SMARTOLT_TOKEN = config.SMARTOLT_TOKEN


def _request(method, endpoint, **kwargs):
    try:
        headers = kwargs.pop("headers", {})
        headers["X-Token"] = SMARTOLT_TOKEN
        url = f"{SMARTOLT_BASEURL}{endpoint}"
        resp = requests.request(method, url, headers=headers, **kwargs)
        resp.raise_for_status()
        return resp
    except Exception as e:
        logger.error(f"Error en request API smartOLT: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}


def get_all_onus():
    try:
        """Devuelve el lote completo de ONUs desde SmartOLT."""
        resp = _request("GET", "/onu/get_all_onus_details")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error("SmartOLT no devolvi√≥ estado OK")
        return data.get("onus", [])
    except Exception as e:
        logger.error(f"Error al obtener listado de onus: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}
    

def get_onu_status(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_status/{onu_id}")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data 
    except Exception as e:
        logger.error(f"Error al consultar estado ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}


def get_onu_signals(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_signal/{onu_id}")
        data = resp.json()  # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data
    except Exception as e:
        logger.error(f"Error al consultar se√±ales ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}
    
def get_attached_vlans(onu_id):
    """Obtiene las VLANs adjuntas de una ONU por external_id."""
    #lista el detalle de la onu, para sacar las attached vlans de sus serviceports
    
    resp = _request("GET", f"/onu/get_onu_details/{onu_id}")
    data = resp.json()
    vlans = []
    if data.get("status"):
        serviceports = data["onu_details"].get("service_ports", [])
        vlans = [sp["vlan"] for sp in serviceports if "vlan" in sp]

    return vlans

==================================================
ARCHIVO: app\clients\__init__.py
==================================================


==================================================
ARCHIVO: app\db\sqlite.py
==================================================
# app/db/sqlite.py
import sqlite3
from app import config
from datetime import datetime


class Database:
    def __init__(self, path=config.DB_PATH):
        self.conn = sqlite3.connect(path)
        self.cursor = self.conn.cursor()

    def insert_subscriber(self, unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode):
        self.cursor.execute("""
            INSERT OR REPLACE INTO subscribers (
                unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, pppoe_username, mode
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode))

    def insert_node(self, node_id, name, ip_address, puerto):
        self.cursor.execute("""
            INSERT OR REPLACE INTO nodes (node_id, name, ip_address, puerto)
            VALUES (?, ?, ?, ?)
        """, (node_id, name, ip_address, puerto))

    def insert_plan(self, plan_id, name, speed, description):
        self.cursor.execute("""
            INSERT OR REPLACE INTO plans (plan_id, name, speed, description)
            VALUES (?, ?, ?, ?)
        """, (plan_id, name, speed, description))

    def insert_connection(self, connection_id, pppoe_username, customer_id, node_id, plan_id, direccion=None):
        self.cursor.execute("""
            INSERT OR REPLACE INTO connections (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion))

    def insert_cliente(self, cliente_data: dict):
        columns = ', '.join(cliente_data.keys())
        placeholders = ', '.join('?' for _ in cliente_data)
        values = tuple(cliente_data.values())
        self.cursor.execute(f"""
            INSERT OR REPLACE INTO clientes ({columns})
            VALUES ({placeholders})
        """, values)
    
    def insert_cliente_email(self, customer_id: int, email: str):
        self.cursor.execute("""
            INSERT INTO clientes_emails (customer_id, email)
            VALUES (?, ?)
        """, (customer_id, email))
    
    def insert_cliente_telefono(self, customer_id: int, number: str):
        self.cursor.execute("""
            INSERT INTO clientes_telefonos (customer_id, number)
            VALUES (?, ?)
        """, (customer_id, number))
    
    def match_connections(self):
        self.cursor.execute("""
            UPDATE subscribers
            SET node_id = (
                SELECT node_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            ),
            connection_id = (
                SELECT connection_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            )
        """)
    
    def log_sync_status(self, fuente: str, estado: str, detalle: str = ""):
        """Registra el estado de sincronizaci√≥n de una fuente"""
        self.cursor.execute("""
            INSERT INTO sync_status (fuente, ultima_actualizacion, estado, detalle)
            VALUES (?, ?, ?, ?)
        """, (fuente, datetime.now(), estado, detalle))
        self.commit()

    def get_diagnosis(self, pppoe_user: str) -> dict:
        query = """
        SELECT s.unique_external_id,
                s.pppoe_username,
                s.sn AS onu_sn,
                s.mode as Modo,
                s.olt_name AS OLT,
                n.name AS nodo_nombre,
                n.ip_address AS nodo_ip,
                n.puerto AS puerto,
                p.name AS plan,
                c.direccion AS direccion,
                l.name AS cliente_nombre
        FROM clientes l
        LEFT JOIN connections c ON l.id = c.customer_id
        LEFT JOIN subscribers s ON c.pppoe_username = s.pppoe_username
        LEFT JOIN nodes n ON c.node_id = n.node_id
        LEFT JOIN plans p ON c.plan_id = p.plan_id
        WHERE c.pppoe_username = ?
        """
        self.cursor.execute(query, (pppoe_user,))
        row = self.cursor.fetchone()

        if not row:
            return {"error": f"Cliente {pppoe_user} no encontrado"}

        diagnosis = {
            "unique_external_id": row[0],
            "pppoe_username": row[1],
            "onu_sn": row[2],
            "Modo": row[3],
            "OLT": row[4],
            "nodo_nombre": row[5],
            "nodo_ip": row[6],
            "puerto": row[7],
            "plan": row[8],
            "direccion": row[9],
            "cliente_nombre": row[10]
        }
        return diagnosis
    
    

    def commit(self):
        self.conn.commit()

    def close(self):
        self.conn.close()

### Fin de la clase Database ###
def columnas_tabla(conn, tabla: str) -> set:
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({tabla})")
        return {row[1] for row in cur.fetchall()}  # row[1] = nombre columna

def insert_cliente_safe(db, json_cliente: dict):
    cols = columnas_tabla(db.conn, "clientes")
    data = mapear_cliente(json_cliente)

    # Filtrar a solo columnas v√°lidas
    data_filtrada = {k: v for k, v in data.items() if k in cols}

    # Reusar tu m√©todo din√°mico
    db.insert_cliente(data_filtrada)


# Inicializaci√≥n de la base de datos y creaci√≥n de tablas
def init_db():
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # Tabla de suscriptores (SmartOLT)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS subscribers (
            unique_external_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            sn TEXT,
            olt_name TEXT,
            olt_id TEXT,
            board TEXT,
            port TEXT,
            onu TEXT,
            onu_type_id TEXT,
            mode TEXT,
            node_id TEXT,
            connection_id TEXT,
            vlan TEXT
        )
    """)

    # Tabla de nodos (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS nodes (
            node_id TEXT PRIMARY KEY,
            name TEXT,          -- nombre del nodo (comment en ISPCube)
            ip_address TEXT,
            puerto TEXT
        )
    """)

    # Tabla de planes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS plans (
            plan_id TEXT PRIMARY KEY,
            name TEXT,
            speed TEXT,
            description TEXT
        )
    """)

    # Tabla de conexiones (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS connections (
            connection_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            customer_id TEXT,
            node_id TEXT,
            plan_id TEXT,
            direccion TEXT
        )
    """)
    
     # Tabla de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes (
            id INTEGER PRIMARY KEY,              -- id del cliente
            code TEXT,
            name TEXT,
            tax_residence TEXT,
            type TEXT,
            tax_situation_id INTEGER,
            identification_type_id INTEGER,
            doc_number TEXT,
            auto_bill_sending INTEGER,
            auto_payment_recipe_sending INTEGER,
            nickname TEXT,
            comercial_activity TEXT,
            address TEXT,
            between_address1 TEXT,
            between_address2 TEXT,
            city_id INTEGER,
            lat TEXT,
            lng TEXT,
            extra1 TEXT,
            extra2 TEXT,
            entity_id INTEGER,
            collector_id INTEGER,
            seller_id INTEGER,
            block INTEGER,
            free INTEGER,
            apply_late_payment_due INTEGER,
            apply_reconnection INTEGER,
            contract INTEGER,
            contract_type_id INTEGER,
            contract_expiration_date TEXT,
            paycomm TEXT,
            expiration_type_id INTEGER,
            business_id INTEGER,
            first_expiration_date TEXT,
            second_expiration_date TEXT,
            next_month_corresponding_date INTEGER,
            start_date TEXT,
            perception_id INTEGER,
            phonekey TEXT,
            debt TEXT,
            duedebt TEXT,
            speed_limited INTEGER,
            status TEXT,
            enable_date TEXT,
            block_date TEXT,
            created_at TEXT,
            updated_at TEXT,
            deleted_at TEXT,
            temporary INTEGER
        )

    """)

    #Tabla de emails de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_emails (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            email TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    #Tabla de tel√©fonos de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_telefonos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            number TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    # Tabla de estados de sincronizaci√≥n
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS sync_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            fuente TEXT NOT NULL,                 -- 'smartolt', 'ispcube', 'mikrotik', etc.
            ultima_actualizacion TEXT NOT NULL,   -- ISO 8601 (ej. '2025-11-26T19:45:00')
            estado TEXT NOT NULL,                 -- 'ok', 'empty', 'error'
            detalle TEXT
        )
    """)

    # √çndice √∫til para consultas por fuente y fecha
    cursor.execute("""
    CREATE INDEX IF NOT EXISTS idx_sync_status_fuente_fecha
    ON sync_status (fuente, ultima_actualizacion)
    """)


    conn.commit()
    conn.close()


==================================================
ARCHIVO: app\db\__init__.py
==================================================


==================================================
ARCHIVO: app\jobs\sync.py
==================================================
from app.db.sqlite import Database, init_db
from app.clients import smartolt, ispcube
from app import config
from app.utils.safe_call import safe_call


def sync_onus(db):
    onus = smartolt.get_all_onus()
    if onus:
        db.cursor.execute("DELETE FROM subscribers")
        for onu in onus:
            db.insert_subscriber(
                onu.get("unique_external_id"), # type: ignore
                onu.get("sn"), # type: ignore
                onu.get("olt_name"), # type: ignore
                onu.get("olt_id"), # type: ignore
                onu.get("board"), # type: ignore
                onu.get("port"), # type: ignore
                onu.get("onu"), # type: ignore
                onu.get("onu_type_id"), # type: ignore
                onu.get("name"), # type: ignore
                onu.get("mode") # type: ignore
            )
        db.log_sync_status("smartolt", "ok", f"{len(onus)} ONUs sincronizadas")
        config.logger.info(f"[SYNC] {len(onus)} ONUs sincronizadas.")
    else:
        db.log_sync_status("smartolt", "empty", "SmartOLT no devolvi√≥ datos, se mantienen registros anteriores")
        config.logger.info(f"[SYNC] no se pudo sincronizar ONUs.")


def sync_nodes(db):
    nodes = ispcube.obtener_nodos()
    if nodes:
        db.cursor.execute("DELETE FROM nodes")  # Limpia la tabla antes de insertar
    for n in nodes:
        db.insert_node(n["id"], n["name"], n["ip"], n["puerto"])
    config.logger.info(f"[SYNC] {len(nodes)} nodos sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(nodes)} nodos sincronizadas")


def sync_plans(db):
    planes = ispcube.obtener_planes()
    if planes:
        db.cursor.execute("DELETE FROM plans")  # Limpia la tabla antes de insertar 
    for p in planes:
        db.insert_plan(p["id"], p["name"], p.get("speed"), p.get("comment"))
    config.logger.info(f"[SYNC] {len(planes)} planes sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(planes)} planes sincronizadas")


def sync_connections(db):
    conexiones = ispcube.obtener_todas_conexiones()
    if conexiones:
        db.cursor.execute("DELETE FROM connections")  # Limpia la tabla antes de insertar
    for c in conexiones:
        db.insert_connection(c["id"], c["user"], c["customer_id"], c["node_id"], c["plan_id"], c.get("direccion"))
    config.logger.info(f"[SYNC] {len(conexiones)} conexiones sincronizadas.")
    db.log_sync_status("ispcube", "ok", f"{len(conexiones)} conecciones sincronizadas")

def sync_clientes(db):
    clientes = ispcube.obtener_clientes()  # debe devolver la lista completa cruda del endpoint
    if clientes:
        db.cursor.execute("DELETE FROM clientes")
        db.cursor.execute("DELETE FROM clientes_emails")
        db.cursor.execute("DELETE FROM clientes_telefonos")

        for c in clientes:
            cliente_data = mapear_cliente(c)
            db.insert_cliente(cliente_data)
            insertar_contactos_relacionados(db, c)

        db.commit()
        config.logger.info(f"[SYNC] {len(clientes)} clientes sincronizados.")
        db.log_sync_status("ispcube", "ok", f"{len(clientes)} clientes sincronizados")
    else:
        config.logger.warning("[SYNC] ISPCube no devolvi√≥ clientes")
        db.log_sync_status("ispcube", "empty", "Sin datos de clientes")

def insertar_contactos_relacionados(db, json_cliente: dict):
    # Emails
    for email_obj in json_cliente.get("contact_emails", []):
        email = email_obj.get("email")
        if email:
            db.insert_cliente_email(json_cliente["id"], email)

    # Tel√©fonos
    for tel_obj in json_cliente.get("phones", []):
        number = tel_obj.get("number")
        if number:
            db.insert_cliente_telefono(json_cliente["id"], number)

def nightly_sync():
    init_db()  # asegura el esquema antes de cualquier operaci√≥n
    db = Database()
    try:
        sync_onus(db)
        sync_clientes(db)
        sync_nodes(db)
        sync_plans(db)
        sync_connections(db)
        db.match_connections()
        db.commit()
        config.logger.info("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
        print("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
    finally:
        db.close()


#------------------ Funciones de mapeo ------------------
#------------------
def mapear_cliente(json_cliente: dict) -> dict:
    """
    Convierte el JSON de ISPCube en un dict compatible con la tabla clientes.
    Incluye casi todos los campos del ejemplo.
    """
    return {
        "id": json_cliente.get("id"),
        "code": json_cliente.get("code"),
        "name": json_cliente.get("name"),
        "tax_residence": json_cliente.get("tax_residence"),
        "type": json_cliente.get("type"),
        "tax_situation_id": json_cliente.get("tax_situation_id"),
        "identification_type_id": json_cliente.get("identification_type_id"),
        "doc_number": json_cliente.get("doc_number"),
        "auto_bill_sending": json_cliente.get("auto_bill_sending"),
        "auto_payment_recipe_sending": json_cliente.get("auto_payment_recipe_sending"),
        "nickname": json_cliente.get("nickname"),
        "comercial_activity": json_cliente.get("comercial_activity"),
        "address": json_cliente.get("address"),
        "between_address1": json_cliente.get("between_address1"),
        "between_address2": json_cliente.get("between_address2"),
        "city_id": json_cliente.get("city_id"),
        "lat": json_cliente.get("lat"),
        "lng": json_cliente.get("lng"),
        "extra1": json_cliente.get("extra1"),
        "extra2": json_cliente.get("extra2"),
        "entity_id": json_cliente.get("entity_id"),
        "collector_id": json_cliente.get("collector_id"),
        "seller_id": json_cliente.get("seller_id"),
        "block": json_cliente.get("block"),
        "free": json_cliente.get("free"),
        "apply_late_payment_due": json_cliente.get("apply_late_payment_due"),
        "apply_reconnection": json_cliente.get("apply_reconnection"),
        "contract": json_cliente.get("contract"),
        "contract_type_id": json_cliente.get("contract_type_id"),
        "contract_expiration_date": json_cliente.get("contract_expiration_date"),
        "paycomm": json_cliente.get("paycomm"),
        "expiration_type_id": json_cliente.get("expiration_type_id"),
        "business_id": json_cliente.get("business_id"),
        "first_expiration_date": json_cliente.get("first_expiration_date"),
        "second_expiration_date": json_cliente.get("second_expiration_date"),
        "next_month_corresponding_date": json_cliente.get("next_month_corresponding_date"),
        "start_date": json_cliente.get("start_date"),
        "perception_id": json_cliente.get("perception_id"),
        "phonekey": json_cliente.get("phonekey"),
        "debt": json_cliente.get("debt"),
        "duedebt": json_cliente.get("duedebt"),
        "speed_limited": json_cliente.get("speed_limited"),
        "status": json_cliente.get("status"),
        "enable_date": json_cliente.get("enable_date"),
        "block_date": json_cliente.get("block_date"),
        "created_at": json_cliente.get("created_at"),
        "updated_at": json_cliente.get("updated_at"),
        "deleted_at": json_cliente.get("deleted_at"),
        "temporary": json_cliente.get("temporary"),
    }
#------------------

if __name__ == "__main__":
    try:
        nightly_sync()
    except Exception as e:
        print(f"[ERROR] Fall√≥ la sincronizaci√≥n: {e}")



==================================================
ARCHIVO: app\jobs\__init__.py
==================================================


==================================================
ARCHIVO: app\services\diagnostico.py
==================================================
Ôªøfrom app.db.sqlite import Database
from app.clients import mikrotik, smartolt, ispcube
from app.config import logger
from app.utils.safe_call import safe_call


def consultar_diagnostico(pppoe_user: str) -> dict:
    db = Database()
    try:
        base = db.get_diagnosis(pppoe_user)
        if "error" in base:
            return base

        diagnosis = base.copy()

        # Mikrotik ‚Üí validaci√≥n PPPoE usando nodo_ip
        pppoe_info = mikrotik.validar_pppoe(base["nodo_ip"], pppoe_user, base["puerto"])
        diagnosis["mikrotik"] = pppoe_info
        # if pppoe_info.get("active"):
        #     diagnosis["pppoe_active"] = True
        # else:
        #     diagnosis["pppoe_active"] = False
        #     diagnosis["last_disconnect"] = pppoe_info.get("last_disconnect")
        #     diagnosis["disconnect_reason"] = pppoe_info.get("reason")

        # SmartOLT
        diagnosis["onu_status_smrt"] = smartolt.get_onu_status(base["unique_external_id"])
        diagnosis["onu_signal_smrt"] = smartolt.get_onu_signals(base["unique_external_id"])
        diagnosis["onu_vlan"] = smartolt.get_attached_vlans(base["unique_external_id"])

        # ISPCube
        # conn_info = ispcube.obtener_conexion_por_pppoe(pppoe_user)
        # diagnosis["ispcube_status"] = conn_info.get("status")

        # plan = ispcube.obtener_plan(conn_info.get("plan_id"))
        # diagnosis["plan"] = plan.get("name")
        # diagnosis["speed"] = plan.get("speed")

        return diagnosis
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}. Detalles: {e}")
        return diagnosis # type: ignore
    finally:
        db.close()

==================================================
ARCHIVO: app\services\__init__.py
==================================================


==================================================
ARCHIVO: app\utils\safe_call.py
==================================================
from functools import wraps
from app.config import logger

def safe_call(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            result = func(*args, **kwargs)
            if isinstance(result, dict):
                return {"estado": "ok", **result}
            return {"estado": "ok", "resultado": result}
        except Exception as e:
            logger.error(f"Error en {func.__name__}: {e}")
            return {"estado": "error", "detalle": str(e)}
    return wrapper

==================================================
ARCHIVO: docs\adr001.md
==================================================

# ADR-001: Uso de SQLite como base de datos inicial

## Contexto
Beholder necesita una base de datos para almacenar clientes, conexiones, planes, nodos y suscriptores (fibra y antena).  
El sistema est√° en fase inicial, con un equipo reducido y foco en rapidez de desarrollo y despliegue.  
Las opciones consideradas fueron:
- **PostgreSQL**: robusto, escalable, multiusuario, con soporte avanzado de √≠ndices y particiones.  
- **SQLite**: liviano, embebido, sin necesidad de servidor, f√°cil de administrar.  

El entorno actual es un ISP en crecimiento, con despliegues r√°pidos y necesidad de simplicidad operativa.

## Decisi√≥n
Se decidi√≥ usar **SQLite** como base de datos inicial para Beholder.  
Motivos:
- Simplicidad de instalaci√≥n y cero mantenimiento de servidor.  
- Integraci√≥n directa con Python sin dependencias externas.  
- Suficiente rendimiento para el volumen actual de clientes y antenas.  
- Facilita pruebas y despliegues r√°pidos en entornos de desarrollo y producci√≥n.  

## Consecuencias
**Positivas:**
- Menor complejidad operativa.  
- Deploy m√°s sencillo (solo archivo `.db`).  
- Ideal para prototipado y validaci√≥n r√°pida.  

**Negativas:**
- Limitaciones de concurrencia (solo un escritor a la vez).  
- Escalabilidad reducida para grandes vol√∫menes de datos.  
- Migraci√≥n futura necesaria a PostgreSQL u otro motor m√°s robusto.  

**Mitigaci√≥n:**
- Dise√±o modular de acceso a datos (`db.py`) para facilitar migraci√≥n.  
- Documentaci√≥n clara del esquema y relaciones.  
- Plan de roadmap para migrar a PostgreSQL cuando el volumen lo requiera.  



==================================================
ARCHIVO: docs\adr002.md
==================================================


# ADR-002: Deploy mediante Git Hooks y sudoers NOPASSWD

## Contexto
Beholder necesita un mecanismo de despliegue simple y confiable para actualizar c√≥digo en producci√≥n.  
Las opciones consideradas fueron:
- **CI/CD externo** (GitHub Actions, GitLab CI, Jenkins): m√°s potente pero requiere infraestructura adicional.  
- **Deploy manual v√≠a SSH**: flexible pero propenso a errores humanos.  
- **Git hooks en el servidor**: automatizan el proceso al recibir un `git push`.  

El sistema corre en servidores propios del ISP, con usuarios t√©cnicos limitados y necesidad de rapidez en cambios.

## Decisi√≥n
Se decidi√≥ implementar **deploy autom√°tico mediante git hooks** en el repositorio remoto, combinados con reglas en `sudoers` para permitir reinicios de servicios sin contrase√±a.  
Motivos:
- Simplicidad: un `git push production main` actualiza y reinicia el servicio.  
- Bajo costo: no requiere infraestructura adicional ni pipelines externos.  
- Control local: todo corre en el servidor del ISP, sin depender de terceros.  
- Seguridad: `sudoers` limita los comandos permitidos (solo `systemctl reload nginx` y `systemctl restart beholder.service`).

## Consecuencias
**Positivas:**
- Deploy r√°pido y reproducible.  
- Menor riesgo de olvidar pasos manuales.  
- Operadores pueden actualizar sin conocimientos avanzados de Linux.  

**Negativas:**
- Menor flexibilidad que un pipeline CI/CD (no hay tests autom√°ticos).  
- Riesgo de que un hook mal escrito rompa el deploy.  
- Escalabilidad limitada si se agregan m√∫ltiples servidores.  

**Mitigaci√≥n:**
- Documentar el hook y mantenerlo versionado.  
- Usar `sudoers` con comandos espec√≠ficos para evitar abusos.  
- Planear migraci√≥n futura a CI/CD cuando el equipo crezca.  



==================================================
ARCHIVO: docs\adr003.md
==================================================


# ADR-003: Separaci√≥n de Mappers, Helpers y Acceso a Base de Datos

## Contexto
Beholder necesita sincronizar y transformar datos provenientes de m√∫ltiples fuentes externas (SmartOLT, ISPCube, cnMaestro).  
En las primeras versiones, la l√≥gica de transformaci√≥n, validaci√≥n y acceso a la base de datos estaba mezclada en scripts monol√≠ticos, lo que dificultaba:
- La mantenibilidad del c√≥digo.  
- La incorporaci√≥n de nuevos desarrolladores.  
- La reutilizaci√≥n de funciones comunes.  

El sistema debe ser modular y escalable, permitiendo agregar nuevas integraciones sin romper las existentes.

## Decisi√≥n
Se decidi√≥ separar la l√≥gica en tres capas principales:
- **Mappers**: traducen datos externos (JSON/API) al modelo interno de Beholder.  
- **Helpers**: funciones utilitarias para validaci√≥n, normalizaci√≥n y manejo de edge cases.  
- **DB Access**: m√≥dulo dedicado (`db.py`) para consultas y operaciones sobre la base de datos.  

Motivos:
- Claridad en la responsabilidad de cada m√≥dulo.  
- Facilita pruebas unitarias y debugging.  
- Permite reemplazar o extender cada capa sin afectar las dem√°s.  
- Mejora la documentaci√≥n y onboarding de nuevos desarrolladores.

## Consecuencias
**Positivas:**
- C√≥digo m√°s legible y mantenible.  
- Escalabilidad: f√°cil agregar nuevos mappers para otras APIs.  
- Reducci√≥n de errores por mezcla de responsabilidades.  
- Documentaci√≥n m√°s clara (cada m√≥dulo tiene su prop√≥sito definido).  

**Negativas:**
- Mayor cantidad de archivos y estructura m√°s compleja.  
- Requiere disciplina para mantener la separaci√≥n y no mezclar l√≥gica.  

**Mitigaci√≥n:**
- Definir convenciones de nombres y carpetas (`mappers/`, `helpers/`, `db/`).  
- Documentar ejemplos de uso en cada m√≥dulo.  
- Revisar PRs con foco en mantener la separaci√≥n de responsabilidades.  



==================================================
ARCHIVO: docs\adr004.md
==================================================


# ADR-004: Migraci√≥n de SQLite a PostgreSQL

## Contexto
Beholder actualmente utiliza **SQLite** como motor de base de datos.  
Esta elecci√≥n inicial permiti√≥ simplicidad en despliegue y prototipado r√°pido. Sin embargo, el crecimiento del ISP y la necesidad de manejar mayor volumen de clientes (fibra y antena), integraciones m√∫ltiples y consultas concurrentes hacen que SQLite empiece a mostrar limitaciones:
- Concurrencia reducida (un solo escritor a la vez).  
- Escalabilidad limitada para grandes datasets.  
- Falta de caracter√≠sticas avanzadas como particionamiento, materialized views y roles de seguridad.  

El roadmap del proyecto contempla expansi√≥n y mayor n√∫mero de operadores, lo que requiere un motor m√°s robusto.

## Decisi√≥n
Se decidi√≥ planificar la **migraci√≥n de SQLite a PostgreSQL** como parte del roadmap de escalabilidad.  
Motivos:
- PostgreSQL ofrece mayor rendimiento y soporte para concurrencia.  
- Funcionalidades avanzadas de indexaci√≥n (GIN, trigram, btree) ya alineadas con las pr√°cticas de Beholder.  
- Mejor soporte para integraciones futuras y auditor√≠a.  
- Comunidad amplia y soporte empresarial.  

## Consecuencias
**Positivas:**
- Escalabilidad para manejar decenas de miles de clientes y conexiones.  
- Mejor seguridad y control de acceso.  
- Posibilidad de optimizar consultas con particionamiento y materialized views.  
- Integraci√≥n m√°s sencilla con herramientas externas (BI, reporting).  

**Negativas:**
- Mayor complejidad operativa (necesidad de administrar un servidor de base de datos).  
- Migraci√≥n requiere scripts de conversi√≥n y validaci√≥n de datos.  
- Curva de aprendizaje para operadores y desarrolladores nuevos.  

**Mitigaci√≥n:**
- Mantener acceso a datos encapsulado en `db.py` para facilitar migraci√≥n.  
- Documentar esquema y relaciones en detalle.  
- Planificar migraci√≥n gradual: primero staging, luego producci√≥n.  
- Capacitar al equipo en administraci√≥n b√°sica de PostgreSQL.  



==================================================
ARCHIVO: docs\backend.md
==================================================
## 2. Entorno de Producci√≥n

### 2.1 Servidor
- **Sistema operativo**: Debian GNU/Linux 12.12 (Bookworm)
- **Hostname**: debian-acsserver
- **Usuario de despliegue**: administrador
- **IP p√∫blica**: 138.59.172.24
- **Ruta del c√≥digo**: /home/administrador/apps/beholder
- **Repositorio bare Git**: /home/administrador/repos/beholder.git

### 2.2 Servicio Beholder
- **Archivo systemd**: /etc/systemd/system/beholder.service
- **Comandos √∫tiles**:
  - `systemctl status beholder.service`
  - `systemctl restart beholder.service`
- **Logs**:
  - API: /home/administrador/apps/beholder/data/logs/sync.log
  - Systemd: `journalctl -u beholder.service`

### 2.3 API Backend
- **Puerto expuesto**: 8500
- **URL interna**: http://localhost:8500
- **URL externa**: http://138.59.172.24:8500
- **Endpoints principales**:
  - `/diagnosis/{pppoe_user}`
  - `/health`

### 2.4 Nginx
- **Archivo de configuraci√≥n**: /etc/nginx/sites-enabled/beholder.conf
- **Funci√≥n**: proxy inverso hacia FastAPI en puerto 8500
- **Certificados SSL**: /etc/letsencrypt/live/ (si se usa HTTPS)

==================================================
ARCHIVO: docs\Beholder.md
==================================================


# üìñ Documentaci√≥n Backend Beholder

## 1. Introducci√≥n
Beholder es una API de diagn√≥stico centralizado para clientes ISP (fibra y antena).  
Su backend combina:
- **FastAPI** para exponer endpoints REST.  
- **SQLite** como base local de sincronizaci√≥n.  
- **Integraciones externas** con SmartOLT, ISPCube, Mikrotik y GenieACS a trav√©s de sus respectivas API.
- **Proceso nocturno de sincronizaci√≥n** que actualiza la base con datos de las APIs externas, nutriendo datos de dificil acceso a trav√©s de los Endpoints de consultas de las API clientes.

Ruta repositorio GitHub:
https://github.com/LukeSkywalker66/beholder.git
---

## 2. Entorno de Producci√≥n
- **Servidor Debian**  
  - C√≥digo: `/home/administrador/apps/beholder`  
  - Repositorio Git: `/home/administrador/repos/beholder.git`  
  - Servicio systemd: `/etc/systemd/system/beholder.service`  
  - Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder.conf`  
  - Logs: `/var/log/beholder/`  

- **Deploy**  
  - `git push production main` ‚Üí hook ‚Üí reload nginx + restart beholder.service.  
  - Sudoers configurado con NOPASSWD para `systemctl reload nginx` y `systemctl restart beholder.service`.  

---

## 3. Estructura del Backend
```
app/
‚îú‚îÄ‚îÄ main.py              # FastAPI, endpoints /diagnosis y /health
‚îú‚îÄ‚îÄ config.py            # Variables de entorno, logging centralizado
‚îú‚îÄ‚îÄ security.py          # Middleware API Key
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ diagnostico.py   # L√≥gica de diagn√≥stico por PPPoE
‚îú‚îÄ‚îÄ clients/             # Integraciones externas
‚îÇ   ‚îú‚îÄ‚îÄ smartolt.py      # API SmartOLT
‚îÇ   ‚îú‚îÄ‚îÄ ispcube.py       # API ISPCube
‚îÇ   ‚îî‚îÄ‚îÄ mikrotik.py      # API RouterOS Mikrotik
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ sqlite.py        # Clase Database, esquema y queries
‚îú‚îÄ‚îÄ sync.py              # Proceso de sincronizaci√≥n nocturna
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ safe_call.py     # Wrapper defensivo para llamadas externas
```

---

## 4. Definici√≥n de Archivos Fuente

### `main.py`
- FastAPI con endpoints:
  - `/diagnosis/{pppoe_user}` ‚Üí devuelve diagn√≥stico completo.  
  - `/health` ‚Üí chequeo de estado.  
- Middleware de API Key (`X-API-Key`).  
- CORS habilitado para frontend.  

### `config.py`
- Carga variables desde `.env`.  
- Define rutas (`DB_PATH`, `SMARTOLT_BASEURL`, etc.).  
- Configura logging centralizado en `data/logs/sync.log`.  

### `security.py`
- Middleware para validar API Key.  
- Devuelve `401 unauthorized` si la clave no coincide.  

### `services/diagnostico.py`
- Funci√≥n `consultar_diagnostico(pppoe_user)`:
  - Consulta base local (`db.get_diagnosis`).  
  - Valida PPPoE en Mikrotik.  
  - Consulta estado, se√±ales y VLANs en SmartOLT.  
  - Integra datos de ISPCube.  

### `clients/smartolt.py`
- Funciones para interactuar con SmartOLT:
  - `get_all_onus()` ‚Üí listado completo de ONUs.  
  - `get_onu_status(id)` ‚Üí estado de ONU.  
  - `get_onu_signals(id)` ‚Üí se√±ales √≥pticas.  
  - `get_attached_vlans(id)` ‚Üí VLANs asociadas.  

### `clients/ispcube.py`
- Autenticaci√≥n v√≠a token.  
- Funciones:
  - `obtener_nodos()` ‚Üí lista de nodos.  
  - `obtener_todas_conexiones()` ‚Üí conexiones PPPoE.  
  - `obtener_planes()` ‚Üí planes de servicio.  
  - `obtener_clientes()` ‚Üí clientes completos.  

### `clients/mikrotik.py`
- Conexi√≥n a RouterOS v√≠a `routeros_api`.  
- Funciones:
  - `obtener_secret(router_ip, pppoe_user, puerto)` ‚Üí busca secret PPPoE.  
  - `validar_pppoe(router_ip, pppoe_user, puerto)` ‚Üí chequea si est√° activo.  
- Comentados: crear, borrar y migrar secrets.  

### `db/sqlite.py`
- Clase `Database` con m√©todos `insert_*` para cada tabla.  
- `get_diagnosis(pppoe_user)` ‚Üí query principal de diagn√≥stico.  
- `init_db()` ‚Üí crea esquema de tablas (`subscribers`, `nodes`, `plans`, `connections`, `clientes`, `sync_status`).  

### `sync.py`
- Funciones de sincronizaci√≥n:
  - `sync_onus()`, `sync_nodes()`, `sync_plans()`, `sync_connections()`, `sync_clientes()`.  
- `nightly_sync()` ‚Üí ejecuta todo el proceso y actualiza relaciones PPPoE ‚Üî node_id ‚Üî connection_id.  

---

## 5. Flujo de Diagn√≥stico
1. **Frontend** llama a `/diagnosis/{pppoe_user}`.  
2. **Backend** consulta DB local (`get_diagnosis`).  
3. **Mikrotik** valida PPPoE activo/inactivo.  
4. **SmartOLT** devuelve estado, se√±ales y VLANs.  
5. **ISPCube** aporta datos de cliente, plan y nodo.  
6. Respuesta JSON consolidada para el operador.  

---

## 6. Flujo de Sincronizaci√≥n Nocturna
1. `cron` ejecuta `python sync.py`.  
2. Se inicializa DB (`init_db`).  
3. Se descargan datos de SmartOLT, ISPCube.  
4. Se insertan en tablas locales.  
5. Se actualizan relaciones (`match_connections`).  
6. Se registra estado en `sync_status`.  

---

## 7. ADRs relevantes
- **ADR-001**: Uso de SQLite como base inicial.  
- **ADR-002**: Deploy con git hooks + sudoers NOPASSWD.  
- **ADR-003**: Separaci√≥n modular (mappers, helpers, DB).  
- **ADR-004**: Roadmap migraci√≥n a PostgreSQL.  

---

## 8. Roadmap Backend
- Migrar DB a PostgreSQL.  
- Integrar cnMaestro para clientes wireless.  
- Extender diagn√≥stico con alarmas GenieACS.  
- Automatizar tests en deploy.  



==================================================
ARCHIVO: docs\Beholder_UI.md
==================================================

# üìñ Documentaci√≥n Frontend Beholder

## 1. Introducci√≥n
El frontend de Beholder es una aplicaci√≥n **React + Vite** que consume la API backend (FastAPI).  
Su prop√≥sito es ofrecer a los operadores una interfaz clara y amigable para realizar diagn√≥sticos de clientes ISP.
Repositorio de GitHub:
https://github.com/LukeSkywalker66/beholder_ui.git

---

## 2. Entorno de Producci√≥n
- **Servidor Debian**: mismo host que el backend.  
- **Web server**: Nginx sirve los archivos est√°ticos del build (`dist/`).  
- **Ruta t√≠pica de deploy**:  
  - C√≥digo fuente: `/home/administrador/repos/beholder_ui`  
  - Build: `/home/administrador/apps/beholder-ui`  
  - Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder`  
- **Variables de entorno**: `/config/.env` para backend y `.env` para frontend.  
  - `VITE_API_URL=http://138.59.172.24:8500`  
  - `VITE_API_KEY=Zo9fUbuGS5Qh...`  

---

## 3. Estructura del Frontend
```
src/
‚îú‚îÄ‚îÄ App.tsx             # Layout principal, sidebar + resultados
‚îú‚îÄ‚îÄ App.css             # Estilos globales, grilla, dark mode, responsive
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ beholder2.png   # Logo
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ SearchBox.tsx   # Input PPPoE + bot√≥n buscar
‚îÇ   ‚îú‚îÄ‚îÄ OutputBox.tsx   # Renderizado de diagn√≥stico normalizado
‚îÇ   ‚îî‚îÄ‚îÄ CopyButton.tsx  # Bot√≥n para copiar diagn√≥stico al portapapeles
‚îî‚îÄ‚îÄ env2                # Variables de entorno (API URL y API Key)
```

---

## 4. Definici√≥n de Archivos Fuente

### `App.tsx`
- Layout dividido en dos paneles:
  - **Sidebar**: logo, t√≠tulo, `SearchBox`.  
  - **Results**: muestra `OutputBox` con datos del diagn√≥stico.  
- Estado global `resultData` que se actualiza con la b√∫squeda.

### `SearchBox.tsx`
- Input para PPPoE.  
- Bot√≥n ‚ÄúBuscar‚Äù que llama al backend (`/diagnosis/{pppoe_user}`).  
- Maneja estados de `loading` y `error`.  
- Env√≠a resultado al padre (`App.tsx`) v√≠a `onResult`.

### `OutputBox.tsx`
- Recibe `data` y lo muestra en grilla.  
- Traduce estados t√©cnicos a lenguaje operator-friendly (ej. `Online ‚Üí En l√≠nea`).  
- Incluye bot√≥n `CopyButton` para copiar diagn√≥stico en texto plano.  
- Usa estilos condicionales (`estado-ok`, `estado-error`) para resaltar estado PPPoE y ONU.

### `CopyButton.tsx`
- Copia al portapapeles el texto normalizado del diagn√≥stico.  
- Feedback visual: ‚úî Copiado durante 2 segundos.  
- Implementa fallback para navegadores sin `navigator.clipboard`.

### `App.css`
- Define layout (sidebar + results).  
- Grilla responsive para resultados.  
- Estilos condicionales (`estado-ok`, `estado-error`).  
- Dark mode autom√°tico con `prefers-color-scheme`.  
- Responsive para m√≥viles (columna √∫nica).

---

## 5. Flujo de Diagn√≥stico en Frontend
1. Operador ingresa PPPoE en `SearchBox`.  
2. Se llama al backend con `fetch` y API Key.  
3. Respuesta JSON se guarda en `resultData`.  
4. `OutputBox` muestra diagn√≥stico normalizado.  
5. Operador puede copiar texto plano con `CopyButton` al portapapeles, para poder pegarlo en otras plataformas de forma simple y ordenada.

---

## 6. Deploy Frontend

Manual: 
- Build con Vite:
  ```bash
  npm run build
  ```
- Copiar carpeta `dist/` al servidor Debian.  
- Configurar Nginx para servir `dist/` como sitio est√°tico.  
- Asegurar que `VITE_API_URL` apunte al backend en producci√≥n.  

Con el hook de /home/administrador/repos/beholder_ui.git/hooks/post-receive/:
git push production main

hook:

<!-- {
    #!/bin/bash

    # Ruta de trabajo (checkout del repo)
    WORK_TREE=/home/administrador/repos/beholder_ui_checkout
    # Carpeta de destino para Nginx
    DEPLOY_DIR=/home/administrador/apps/beholder-ui
    # Archivo de log
    LOG_FILE=/var/log/beholder-deploy.log

    log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> $LOG_FILE
    }

    log "==== Deploy iniciado: $(date) ===="

    # Checkout del c√≥digo
    log "[INFO] Haciendo checkout de main..."
    GIT_WORK_TREE=$WORK_TREE git checkout -f main >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ el checkout de main"
    exit 1
    fi

    # Instalar dependencias
    cd $WORK_TREE || exit 1
    log "[INFO] Ejecutando npm install..."
    npm install --legacy-peer-deps >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ npm install"
    exit 1
    fi

    # Build del proyecto
    log "[INFO] Ejecutando npm run build..."
    npm run build >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ npm run build"
    exit 1
    fi

    # Copiar artefactos al deploy
    log "[INFO] Copiando build a $DEPLOY_DIR..."
    rm -rf $DEPLOY_DIR/*
    cp -r $WORK_TREE/dist/* $DEPLOY_DIR/ >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ la copia de artefactos"
    exit 1
    fi

    # Recargar Nginx
    log "[INFO] Recargando Nginx..."
    sudo -n systemctl reload nginx >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ reload de Nginx"
    exit 1
    fi

    log "[SUCCESS] Deploy completado correctamente"


}
 -->



Entrada en sudoers habilita la ejecuci√≥n de sudo systemctl sin ingresar contrase√±a, para poder correr en un proceso sin terminal y recargar el servicio de la p√°gina web.
---

## 7. Roadmap Frontend
- Extender `OutputBox` con m√°s campos de cliente (tel√©fonos, emails).  
- Internacionalizaci√≥n (i18n) para soportar m√∫ltiples idiomas.  
- Mejorar feedback visual en errores de conexi√≥n.  
- Dashboard con m√©tricas de sincronizaci√≥n (`sync_status`).  



==================================================
ARCHIVO: docs\Guia de proyecto.md
==================================================


# üìñ Documentaci√≥n del Proyecto Beholder

## 1. Resumen Ejecutivo
- **Prop√≥sito del sistema**: diagn√≥stico centralizado de clientes ISP (fibra y antena).
- **Contexto**: m√∫ltiples sistemas dispersos (SmartOLT, ISPCube, cnMaestro, Hest).
- **Objetivo**: unificar informaci√≥n para operadores y t√©cnicos, simplificar soporte y escalar servicio.

---

## 2. Requerimientos del Proyecto
### 2.1 Funcionales
- Diagn√≥stico de clientes por PPPoE/ONU/antena.
- Sincronizaci√≥n nocturna de datos (clientes, conexiones, planes, nodos, suscriptores).
- Integraci√≥n con APIs externas (SmartOLT, ISPCube, cnMaestro).
- Interfaz web operator-friendly.
- Logging y auditor√≠a de sincronizaci√≥n.

### 2.2 No Funcionales
- Seguridad: control de acceso, sudoers configurado para deploy.
- Performance: consultas r√°pidas con √≠ndices.
- Mantenibilidad: modularidad en mappers, helpers y DB.
- Escalabilidad: soporte para fibra y antena.

---

## 3. Arquitectura del Sistema (C4 Model)
### 3.1 Contexto
- Beholder como sistema central dentro del ISP.
- Relaci√≥n con SmartOLT, ISPCube, cnMaestro, Hest.

### 3.2 Contenedores
- Backend Python (FastAPI/Flask).
- Frontend React.
- Base de datos SQLite.
- Servicios externos (APIs).

### 3.3 Componentes
- `sync.py`: sincronizaci√≥n nocturna.
- `clients/`: m√≥dulos de integraci√≥n (smartolt.py, ispcube.py, cnmaestro.py).
- `db.py`: acceso a base de datos.
- `frontend/`: UI operator-friendly.

### 3.4 C√≥digo
- Funciones clave (`get_diagnosis`, `sync_subscribers_aire`, etc.).
- Helpers y mappers.

---

## 4. Base de Datos
- **Tablas principales**:
  - `clientes`
  - `connections`
  - `subscribers` (fibra)
  - `subscribers_aire` (antenas)
  - `nodes`
  - `plans`
- **Relaciones**:
  - `clientes` ‚Üî `connections`
  - `connections` ‚Üî `subscribers` / `subscribers_aire`
  - `connections` ‚Üî `nodes`, `plans`

---

## 5. Integraciones Externas
- **SmartOLT API**: ONUs, OLTs.
- **ISPCube API**: clientes, planes, conexiones.
- **cnMaestro API**: antenas, alarmas, suscriptores.
- **Hest Helpdesk**: tickets internos.

---

## 6. ADR (Architecture Decision Records)
- **ADR-001**: Usar SQLite en primera versi√≥n por simplicidad.
- **ADR-002**: Deploy v√≠a git hooks + sudoers NOPASSWD.
- **ADR-003**: Separar mappers, helpers y DB para modularidad.
- **ADR-004**: Integrar cnMaestro para clientes de antena.

---

## 7. Gu√≠a de Operaci√≥n
- **Deploy**: `git push production main` ‚Üí hook ‚Üí reload nginx + restart beholder.
- **Sync manual**: `python sync.py`.
- **Logs**: ubicaciones y formato.
- **Troubleshooting**: errores comunes (sudoers, permisos, API tokens).

---

## 8. Roadmap
- Migrar DB a PostgreSQL para mayor escala.
- Extender diagn√≥stico con alarmas cnMaestro.
- Integraci√≥n con stock y helpdesk.

---


==================================================
ARCHIVO: docs\Guia2.md
==================================================


# üìñ Gu√≠a de Proyecto Beholder

## 1. Introducci√≥n
- **Prop√≥sito del sistema**: diagn√≥stico centralizado de clientes ISP (fibra y antena).
- **Contexto**: m√∫ltiples sistemas dispersos (SmartOLT, ISPCube, cnMaestro, Hest).
- **Objetivo**: unificar informaci√≥n para operadores y t√©cnicos, simplificar soporte y escalar servicio.

---

## 2. Entorno de Producci√≥n
### 2.1 Servidor Debian
- Ruta principal: `/home/administrador/apps/beholder`
- Repositorio Git: `/home/administrador/repos/beholder.git`
- Servicio systemd: `/etc/systemd/system/beholder.service`
- Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder.conf`
- Logs: `/var/log/beholder/`

### 2.2 Deploy
- Comando: `git push production main`
- Hook: `post-receive` ‚Üí actualiza c√≥digo y reinicia servicio.
- Sudoers: reglas NOPASSWD para `systemctl reload nginx` y `systemctl restart beholder.service`.

---

## 3. Estructura del Repositorio
```
beholder/
‚îú‚îÄ‚îÄ backend/          # API y l√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ sync.py       # Sincronizaci√≥n nocturna
‚îÇ   ‚îú‚îÄ‚îÄ db.py         # Acceso a base de datos
‚îÇ   ‚îî‚îÄ‚îÄ clients/      # Integraciones externas (smartolt.py, ispcube.py, cnmaestro.py)
‚îú‚îÄ‚îÄ frontend/         # React UI
‚îú‚îÄ‚îÄ hooks/            # Scripts de deploy
‚îú‚îÄ‚îÄ docs/             # Documentaci√≥n en Markdown
‚îî‚îÄ‚îÄ tests/            # Pruebas unitarias
```

---

## 4. Repositorio GitHub
- URL: `https://github.com/<org>/beholder`
- Estado: p√∫blico/privado (definir).
- Pol√≠ticas de acceso: qui√©n puede hacer push, revisi√≥n de PRs.
- Consideraciones de seguridad: no incluir credenciales en el repo.

---

## 5. Flujo de Trabajo
- **Commit y Push**: desarrollador hace cambios ‚Üí `git push production main`.
- **Hook de Deploy**: recibe push ‚Üí actualiza c√≥digo ‚Üí reinicia servicio.
- **Sync nocturno**: `cron` ejecuta `sync.py` ‚Üí actualiza DB con datos externos.
- **Operaci√≥n diaria**: operadores usan frontend para diagn√≥stico.

---

## 6. Documentaci√≥n T√©cnica
- Definici√≥n de cada archivo fuente.
- Ejemplos de queries SQL comunes.
- Integraciones externas (SmartOLT, ISPCube, cnMaestro).
- ADRs relevantes.

---

## 7. Roadmap
- Migraci√≥n futura a PostgreSQL.
- Extensi√≥n de diagn√≥stico con alarmas cnMaestro.
- Integraci√≥n con stock y helpdesk.



==================================================
ARCHIVO: docs\todo_cnMaestro.md
==================================================
Perfecto, Lucas üëÅÔ∏è. Para integrar **clientes de antenas** al backend y que aparezcan en tu diagn√≥stico junto con fibra, lo m√°s ordenado es replicar el mismo patr√≥n que ya ten√©s con SmartOLT e ISPCube, pero usando la API de **cnMaestro** de Cambium. Te desgloso el dise√±o:

---

## üß© Pasos de integraci√≥n

### 1. Crear cliente `cnmaestro.py`
Un m√≥dulo en `app/clients/` que maneje la autenticaci√≥n y llamadas a la API REST de cnMaestro.

Ejemplo b√°sico:

```python
# app/clients/cnmaestro.py
import requests
from app import config
from app.config import logger

CNMAESTRO_BASEURL = config.CNMAESTRO_BASEURL
CNMAESTRO_USER = config.CNMAESTRO_USER
CNMAESTRO_PASS = config.CNMAESTRO_PASS

_token_cache = None

def _get_token():
    global _token_cache
    if _token_cache is None:
        url = f"{CNMAESTRO_BASEURL}/api/v1/access/token"
        resp = requests.post(url, json={"username": CNMAESTRO_USER, "password": CNMAESTRO_PASS})
        resp.raise_for_status()
        _token_cache = resp.json()["access_token"]
    return _token_cache

def _headers():
    return {"Authorization": f"Bearer {_get_token()}"}

def obtener_subscribers_aire():
    """
    Devuelve lista de suscriptores de antena desde cnMaestro.
    """
    url = f"{CNMAESTRO_BASEURL}/api/v1/devices/subscribers"
    resp = requests.get(url, headers=_headers())
    resp.raise_for_status()
    data = resp.json()
    return data.get("data", [])
```

---

### 2. Crear tabla `subscribers_aire` en SQLite
En `init_db()`:

```sql
CREATE TABLE IF NOT EXISTS subscribers_aire (
    id TEXT PRIMARY KEY,
    name TEXT,
    mac TEXT,
    ip TEXT,
    lat TEXT,
    lng TEXT,
    modelo TEXT,
    estado TEXT,
    cliente_id TEXT,
    FOREIGN KEY (cliente_id) REFERENCES clientes(id)
);
```

---

### 3. M√©todos en `Database`
```python
def insert_subscriber_aire(self, id, name, mac, ip, lat, lng, modelo, estado, cliente_id=None):
    self.cursor.execute("""
        INSERT OR REPLACE INTO subscribers_aire
        (id, name, mac, ip, lat, lng, modelo, estado, cliente_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (id, name, mac, ip, lat, lng, modelo, estado, cliente_id))
```

---

### 4. Funci√≥n de sincronizaci√≥n en `sync.py`
```python
from app.clients import cnmaestro

def sync_subscribers_aire(db):
    subs = cnmaestro.obtener_subscribers_aire()
    if subs:
        db.cursor.execute("DELETE FROM subscribers_aire")
        for s in subs:
            db.insert_subscriber_aire(
                s.get("id"),
                s.get("name"),
                s.get("mac"),
                s.get("ip"),
                s.get("latitude"),
                s.get("longitude"),
                s.get("model"),
                s.get("status"),
                s.get("customer_id")
            )
        db.commit()
        config.logger.info(f"[SYNC] {len(subs)} suscriptores aire sincronizados.")
        db.log_sync_status("cnmaestro", "ok", f"{len(subs)} suscriptores aire sincronizados")
    else:
        config.logger.warning("[SYNC] cnMaestro no devolvi√≥ suscriptores")
        db.log_sync_status("cnmaestro", "empty", "Sin datos de suscriptores aire")
```

---

### 5. Integrar en `nightly_sync`
```python
def nightly_sync():
    init_db()
    db = Database()
    try:
        sync_onus(db)
        sync_nodes(db)
        sync_plans(db)
        sync_connections(db)
        sync_clientes(db)
        sync_subscribers_aire(db)   # üëà nuevo paso
        db.match_connections()
        db.commit()
        config.logger.info("[SYNC] Base actualizada con fibra y aire.")
    finally:
        db.close()
```

---

## ‚úÖ Resultado
- Ahora tu diagn√≥stico puede mostrar tanto clientes de fibra (SmartOLT/ISPCube) como clientes de antena (cnMaestro).  
- La tabla `subscribers_aire` queda enlazada con `clientes` v√≠a `cliente_id`.  
- El nightly sync mantiene todo actualizado.  

---

üëâ ¬øQuer√©s que te arme tambi√©n el `get_diagnosis` extendido para que, si el cliente es de antena, te devuelva los datos de `subscribers_aire` junto con el resto?



validar datos de cnmaestro

==================================================
ARCHIVO: txt\App.css.txt
==================================================
.layout {
  display: flex;
  min-height: 100vh;
  font-family: Arial, sans-serif;
}

/* Panel izquierdo */
.sidebar {
  width: 300px;
  background-color: #f5f5f5;
  padding: 2rem;
  text-align: center;
  box-shadow: 2px 0 5px rgba(0,0,0,0.1);
}

.logo-sidebar {
  width: 220px;
  height: auto;
  margin-bottom: 1rem;
}

.sidebar h1 {
  font-size: 2rem;
  margin: 0.5rem 0;
}

.sidebar h2 {
  font-size: 1rem;
  color: #666;
  margin-bottom: 2rem;
}

/* Panel derecho */
.results {
  flex: 1;
  padding: 2rem;
  background-color: #ffffff;
}

/* Grilla de resultados */
.grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 1rem;
}

.cell {
  background-color: #eaeaea;
  padding: 1rem;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.1);
}
.grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 1rem;
  margin-top: 1rem;
}

.cell {
  background-color: #f0f0f0;
  padding: 1rem;
  border-radius: 6px;
  box-shadow: 0 1px 4px rgba(0,0,0,0.1);
}

.estado-ok {
  background-color: #d4f4dd;
  border-left: 6px solid #2ecc71;
}

.estado-error {
  background-color: #fbe3e3;
  border-left: 6px solid #e74c3c;
}
.cell.span-2 {
  grid-column: span 2;
}
.header-row {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.diagnostic-title {
  font-size: 1.25rem;
  font-weight: bold;
  margin: 0;
}

.copy-button button {
  background-color: #4a90e2;
  color: white;
  border: none;
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background-color 0.2s ease;
}

.copy-button button:hover {
  background-color: #357ab8;
}
@media (prefers-color-scheme: dark) {
  body {
    background-color: #1e1e1e;
    color: #f0f0f0;
  }

  .sidebar {
    background-color: #2c2c2c;
    color: #f0f0f0;
  }

  .results {
    background-color: #1e1e1e;
    color: #f0f0f0;
  }

  .cell {
    background-color: #333;
    color: #f0f0f0;
  }

  .estado-ok {
    background-color: #2e7d32;
    color: #ffffff;
  }

  .estado-error {
    background-color: #c62828;
    color: #ffffff;
  }

  .copy-button button {
    background-color: #90caf9;
    color: #000;
  }

  .copy-button button:hover {
    background-color: #64b5f6;
  }
}
body.dark-mode {
  background-color: #1e1e1e;
  color: #f0f0f0;
}
@media (max-width: 768px) {
  .layout {
    flex-direction: column;
  }

  .sidebar {
    width: 100%;
    box-shadow: none;
    text-align: left;
    padding: 1rem;
  }

  .results {
    padding: 1rem;
  }

  .grid {
    grid-template-columns: 1fr; /* una sola columna en m√≥viles */
  }

  .cell.span-2 {
    grid-column: span 1;
  }
}

==================================================
ARCHIVO: txt\App.tsx.txt
==================================================
import { useState } from "react";
import SearchBox from "./components/SearchBox";
import OutputBox from "./components/OutputBox";
import './App.css';
import logo from './assets/beholder2.png';

function App() {
  const [resultData, setResultData] = useState<any>(null);

  return (
    <div className="layout">
      {/* Panel izquierdo */}
      <aside className="sidebar">
        <img src={logo} alt="Logo Beholder" className="logo-sidebar" />
        <h1>Beholder</h1>
        <h2>Diagn√≥stico centralizado de 2F Internet</h2>
        <SearchBox onResult={setResultData} />
      </aside>

      {/* Panel derecho */}
      <main className="results">
        {resultData && <OutputBox data={resultData} />}
      </main>
    </div>
  );
}

export default App;

==================================================
ARCHIVO: txt\config.py.txt
==================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv(dotenv_path=os.path.join("config", ".env"))

# Variables de entorno
API_KEY = os.getenv("API_KEY")
SMARTOLT_BASEURL = os.getenv("SMARTOLT_BASEURL")
SMARTOLT_TOKEN = os.getenv("SMARTOLT_TOKEN")
MK_HOST = os.getenv("MK_HOST")
MK_USER = os.getenv("MK_USER")
MK_PASS = os.getenv("MK_PASS")
MK_PORT = int(os.getenv("MK_PORT", 8799))
GENIEACS_URL = os.getenv("GENIEACS_URL")
ISPCUBE_BASEURL=os.getenv("ISPCUBE_BASEURL")
ISPCUBE_APIKEY=os.getenv("ISPCUBE_APIKEY")
ISPCUBE_USER=os.getenv("ISPCUBE_USER")
ISPCUBE_PASSWORD=os.getenv("ISPCUBE_PASSWORD")
ISPCUBE_CLIENTID=os.getenv("ISPCUBE_CLIENTID")

DB_PATH = os.path.abspath(os.getenv("DB_PATH", "data/diag.db"))

# Crear carpeta data/ si no existe
db_dir = os.path.dirname(DB_PATH)
if not os.path.exists(db_dir):
    os.makedirs(db_dir, exist_ok=True)

# Logging centralizado
log_dir = os.path.join(db_dir, "logs")
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(log_dir, "sync.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("beholder")

==================================================
ARCHIVO: txt\CopyButton.tsx.txt
==================================================
import { useState } from "react";

interface CopyButtonProps {
  text: string; // el texto que quer√©s copiar
}

export default function CopyButton({ text }: CopyButtonProps) {
  const [copied, setCopied] = useState(false);

  const copyToClipboard = async () => {
    console.log("Click detectado, texto:", text);
    try {
      if (navigator.clipboard && navigator.clipboard.writeText) {
        // ‚úÖ Camino moderno (HTTPS / localhost)
        await navigator.clipboard.writeText(text);
        console.log("Camino moderno (HTTPS / localhost) usado para copiar al portapapeles.");
      } else {
        // ‚úÖ Fallback para HTTP inseguro
        const textarea = document.createElement("textarea");
        textarea.value = text;
        document.body.appendChild(textarea);
        textarea.select();
        document.execCommand("copy");
        document.body.removeChild(textarea);
        console.log("Fallback usado para copiar al portapapeles.");
      }

      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    } catch (err) {
      console.error("Error copiando al portapapeles", err);
    }
  };


  return (
    <div className="copy-button">
      <button onClick={copyToClipboard}>
        üìã Copiar
      </button>
      {copied && <span style={{ marginLeft: "8px" }}>‚úî Copiado</span>}
    </div>
  );

}

==================================================
ARCHIVO: txt\diagnostico.py.txt
==================================================
Ôªøfrom app.db.sqlite import Database
from app.clients import mikrotik, smartolt, ispcube
from app.config import logger
from app.utils.safe_call import safe_call


def consultar_diagnostico(pppoe_user: str) -> dict:
    db = Database()
    try:
        base = db.get_diagnosis(pppoe_user)
        if "error" in base:
            return base

        diagnosis = base.copy()

        # Mikrotik ‚Üí validaci√≥n PPPoE usando nodo_ip
        pppoe_info = mikrotik.validar_pppoe(base["nodo_ip"], pppoe_user, base["puerto"])
        diagnosis["mikrotik"] = pppoe_info
        # if pppoe_info.get("active"):
        #     diagnosis["pppoe_active"] = True
        # else:
        #     diagnosis["pppoe_active"] = False
        #     diagnosis["last_disconnect"] = pppoe_info.get("last_disconnect")
        #     diagnosis["disconnect_reason"] = pppoe_info.get("reason")

        # SmartOLT
        diagnosis["onu_status_smrt"] = smartolt.get_onu_status(base["unique_external_id"])
        diagnosis["onu_signal_smrt"] = smartolt.get_onu_signals(base["unique_external_id"])
        diagnosis["onu_vlan"] = smartolt.get_attached_vlans(base["unique_external_id"])

        # ISPCube
        # conn_info = ispcube.obtener_conexion_por_pppoe(pppoe_user)
        # diagnosis["ispcube_status"] = conn_info.get("status")

        # plan = ispcube.obtener_plan(conn_info.get("plan_id"))
        # diagnosis["plan"] = plan.get("name")
        # diagnosis["speed"] = plan.get("speed")

        return diagnosis
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}. Detalles: {e}")
        return diagnosis # type: ignore
    finally:
        db.close()

==================================================
ARCHIVO: txt\ispcube.py.txt
==================================================

import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call

ISPCUBE_BASEURL = config.ISPCUBE_BASEURL
ISPCUBE_APIKEY = config.ISPCUBE_APIKEY
ISPCUBE_USER = config.ISPCUBE_USER
ISPCUBE_PASSWORD = config.ISPCUBE_PASSWORD
ISPCUBE_CLIENTID = config.ISPCUBE_CLIENTID

# Cache interno del token
_token_cache = None


def _obtener_token():
    """Solicita un nuevo token a ISPCube."""
    url = f"{ISPCUBE_BASEURL}/sanctum/token"
    payload = {"username": ISPCUBE_USER, "password": ISPCUBE_PASSWORD}
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api"
    }
    resp = requests.post(url, json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()["token"]


def _get_token(force_refresh=False):
    """Devuelve un token v√°lido, renovando si es necesario."""
    global _token_cache
    if force_refresh or _token_cache is None:
        _token_cache = _obtener_token()
    return _token_cache

def _headers(token=None):
    """Headers est√°ndar para todas las llamadas."""
    return {
        "Authorization": f"Bearer {token or _get_token()}",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api",
        "Accept": "application/json",
        "username": ISPCUBE_USER
    }


def _request(method, url, **kwargs):
    """
    Wrapper de requests que maneja expiraci√≥n de token.
    Si recibe 401, renueva token y reintenta una vez.
    """
    token = _get_token()
    headers = kwargs.pop("headers", {})
    headers.update(_headers(token))
    resp = requests.request(method, url, headers=headers, **kwargs)
    if resp.status_code == 401:
        # Token expirado ‚Üí renovar y reintentar
        logger.warning("Token expirado, renovando...")
        token = _get_token(force_refresh=True)
        headers.update(_headers(token))
        resp = requests.request(method, url, headers=headers, **kwargs)
    resp.raise_for_status()
    return resp

# ------------------ Funciones p√∫blicas ------------------

def obtener_nodos():
    """Devuelve lista de nodos con id, name, ip."""
    url = f"{ISPCUBE_BASEURL}/nodes/nodes_list"
    resp = _request("GET", url)
    body = resp.json()
    items = body["data"] if isinstance(body, dict) and "data" in body else body
    nodos = []
    for n in items:
        nodos.append({
            "id": n.get("id"),
            "name": n.get("comment"),
            "ip": n.get("ip"),
            "puerto": n.get("port")
        })
    return nodos


def obtener_conexion(pppoe):
    """Busca conexi√≥n por PPPoE y devuelve (conn_id, nodo_actual)."""
    url = f"{ISPCUBE_BASEURL}/connections?pppoe={pppoe}"
    resp = _request("GET", url)
    data = resp.json()
    if data:
        conn = data[0]
        return conn["id"], conn.get("node_id")
    logger.error(f"No se encontr√≥ conexi√≥n en ISPCube para {pppoe}")


def obtener_conexion_por_pppoe(pppoe_user):
    """
    Busca cliente por PPPoE y devuelve (conn_id, nodo_actual).
    """
    url = f"{ISPCUBE_BASEURL}/connection?user={pppoe_user}"
    resp = _request("GET", url)
    cliente = resp.json()

    conexiones = cliente.get("connections", [])
    if not conexiones:
        logger.error(f"No se encontraron conexiones para PPPoE {pppoe_user}")

    for conn in conexiones:
        if conn.get("conntype") == "pppoe" and conn.get("user") == pppoe_user:
            return conn["id"], conn.get("node_id")

    logger.error(f"No se encontr√≥ conexi√≥n PPPoE exacta para {pppoe_user}")


def obtener_todas_conexiones():
    """
    Devuelve lista de conexiones con datos b√°sicos:
    user (PPPoE), customer_id, id (conn_id), node_id, plan_id.
    """
    url = f"{ISPCUBE_BASEURL}/connections/connections_list"
    resp = _request("GET", url)
    conexiones = resp.json()

    if not isinstance(conexiones, list):
        logger.error("Respuesta inesperada de ISPCube al listar conexiones")

    resultado = []
    for c in conexiones:
        if c.get("conntype") == "pppoe":
            resultado.append({
                "user": c.get("user"),
                "customer_id": c.get("customer_id"),
                "id": c.get("id"),
                "node_id": c.get("node_id"),
                "plan_id": c.get("plan_id"),
                "direccion": c.get("address")
            })
    return resultado


def obtener_planes():
    """
    Devuelve lista de planes con id, nombre, velocidad y descripci√≥n.
    """
    url = f"{ISPCUBE_BASEURL}/plans/plans_list"
    resp = _request("GET", url)
    planes = resp.json()

    if not isinstance(planes, list):
        logger.error("Respuesta inesperada de ISPCube al listar planes")

    resultado = []
    for p in planes:
        resultado.append({
            "id": p.get("id"),
            "name": p.get("name"),
            "speed": p.get("speed"),
            "comment": p.get("comment")
        })
    return resultado

def obtener_clientes():
    """
    Devuelve lista completa de clientes desde ISPCube.
    Incluye todos los campos que el endpoint expone.
    """
    url = f"{ISPCUBE_BASEURL}/customers/customers_list"
    resp = _request("GET", url)
    data = resp.json()

    if not isinstance(data, list):
        logger.error("Respuesta inesperada de ISPCube al listar clientes")
        return []

    return data



==================================================
ARCHIVO: txt\main.py.txt
==================================================

from fastapi import FastAPI, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
from app import config
from app.services.diagnostico import consultar_diagnostico
from app.security import get_api_key
from fastapi import FastAPI, Depends
from app.config import logger
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Beholder - Diagn√≥stico Centralizado")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # o ["http://localhost:5173"] si quer√©s restringir
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
def startup_event():
    config.logger.info("Servicio Beholder iniciado.")

# API key middleware (modificado para permitir OPTIONS)
@app.middleware("http")
async def check_api_key(request: Request, call_next):
    if request.method == "OPTIONS":
        return await call_next(request)

    key = request.headers.get("x-api-key")
    if key != config.API_KEY:
        return JSONResponse(status_code=401, content={"detail": "unauthorized"})

    return await call_next(request)


@app.get("/health")
def health():
    return {"ok": True, "service": "beholder", "status": "running"}

@app.get("/diagnosis/{pppoe_user}")
def diagnosis(pppoe_user: str):
    try:
        row = consultar_diagnostico(pppoe_user)
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}")
        raise HTTPException(status_code=500, detail=str(e))
    if "error" in row:
        raise HTTPException(status_code=404, detail=row["error"])
    return row

    
    # row = consultar_diagnostico(pppoe_user)
    # if "error" in row:
    #     return JSONResponse(status_code=404, content={"detail": row["error"]})
    # return row  # devuelve el dict completo con claves sem√°nticas

@app.get("/")
def read_root(api_key: str = Depends(get_api_key)):
    return {"status": "ok", "service": "Beholder API"}


==================================================
ARCHIVO: txt\mikrotik.py.txt
==================================================
import time
from app.config import logger
from app.utils.safe_call import safe_call
from routeros_api import RouterOsApiPool
from app import config

# Credenciales comunes para todos los Mikrotik
MIKROTIK_USER = config.MK_USER
MIKROTIK_PASS = config.MK_PASS
MIKROTIK_PORT = config.MK_PORT   # üëà tu puerto personalizado
MIKROTIK_IP   = config.MK_HOST  

#Nota para producci√≥n: borrar =MIKROTIK_IP y pasar IP como par√°metro en cada funci√≥n

def _connect(router_ip, port, username=MIKROTIK_USER, password=MIKROTIK_PASS):
    try:
        pool = RouterOsApiPool(
            router_ip,
            username=username, # type: ignore
            password=password, # type: ignore
            port=port,              
            plaintext_login=True
        )
        return pool, pool.get_api()
    except Exception as e:
        logger.error(f"Error de conexi√≥n al router {router_ip}: {e}")
        return {"error": str(e)}

def obtener_secret(router_ip, pppoe_user, puerto): #MIKROTIK_IP, router_ip
    try:
        pool, api = _connect(router_ip, puerto)
        secrets = api.get_resource('/ppp/secret')
        result = secrets.get(name=pppoe_user)
        pool.disconnect()
        if not result:
            logger.error(f"Secret {pppoe_user} no encontrado en {router_ip}")
        return result[0]
    except Exception as e:
        logger.error(f"Error al obtener secret {pppoe_user} en {router_ip}: {e}")
        return {"error": str(e)}
    
# def crear_secret(router_ip, datos_secret):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     secrets.add(
#         name=datos_secret['name'] + "R", # Borrar la "R" para producci√≥n
#         password=datos_secret['password'],
#         profile=datos_secret.get('profile', 'default'),
#         service=datos_secret.get('service', 'pppoe')
#     )
#     pool.disconnect()
#     logger.info(f"Secret {datos_secret['name']} creado en {router_ip}")

# def borrar_secret(router_ip, pppoe_user):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     result = secrets.get(name=pppoe_user)
#     if result:
#         secret = result[0]
#         secret_id = secret.get('.id') or secret.get('id')

#         #id=result[0]['.id']
#         secrets.remove(id=secret_id)
#         logger.info(f"Secret {pppoe_user} eliminado de {router_ip}")
#     pool.disconnect()

# def migrar_secret(origen_ip, destino_ip, pppoe_user):
   
#     datos = obtener_secret(origen_ip, pppoe_user)


#     crear_secret(destino_ip, datos)
#     # Validaci√≥n inicial
#     if not validar_pppoe(destino_ip, pppoe_user):
#         logger.info(f"Esperando 60s para revalidar {pppoe_user} en {destino_ip}...")
#         time.sleep(60)

#         # Segundo intento
#         if not validar_pppoe(destino_ip, pppoe_user):
#             logger.error(f"‚ùå {pppoe_user} no levant√≥ en {destino_ip}, rollback.")
#             #borrar_secret(destino_ip, pppoe_user)
#             return False

#     # Si lleg√≥ ac√°, est√° online ‚Üí borrar en origen
#     borrar_secret(origen_ip, pppoe_user)
#     logger.info(f"‚úÖ {pppoe_user} migrado de {origen_ip} a {destino_ip}")
#     return True


# def rollback_secret(origen_ip, destino_ip, pppoe_user):
    
#     origen_ip = MIKROTIK_IP #borrar para producci√≥n
#     destino_ip = MIKROTIK_IP #borrar para producci√≥n

#     datos = obtener_secret(destino_ip, pppoe_user)
#     crear_secret(origen_ip, datos)
#     borrar_secret(destino_ip, pppoe_user)
#     return True

def validar_pppoe(router_ip: str, pppoe_user: str, puerto: str) -> dict:
    try:
        pool, api = _connect(router_ip, puerto)
        #pool, api = _connect(MIKROTIK_IP) #borrar para producci√≥n
        activos = api.get_resource('/ppp/active')
        result = activos.get(name=pppoe_user)
        pool.disconnect()

        if result:
            logger.info(f"PPP user {pppoe_user} activo en {router_ip}")
            return {"active": True, **result[0]}
        else:
            logger.warning(f"PPP user {pppoe_user} NO activo en {router_ip}")
            try:
                #modificar aca
                secret = obtener_secret(router_ip, pppoe_user, puerto)
                return {"active": False, "secret": secret}
            except Exception:
                return {"active": False}
    except Exception as e:
        logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
        return {"active": False, "error": str(e)}
        # Si no est√° activo y no se encuentra el secret, no se puede obtener m√°s info
# def validar_pppoe(router_ip: str, pppoe_user: str) -> dict:
#     try:
#         pool, api = _connect(router_ip)
#         activos = api.get_resource('/ppp/active')
#         result = activos.get(name=pppoe_user)
#         pool.disconnect()

#         if result:
#             # Tomamos el primer dict y lo expandimos directamente
#             return {"active": True, **result[0]}
#         else:
#             return {"active": False}
#     except Exception as e:
#         logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
#         return {"active": False, "error": str(e)}


==================================================
ARCHIVO: txt\OutputBox.tsx.txt
==================================================

import CopyButton from "./CopyButton";

interface OutputBoxProps {
  data: any;
}

export default function OutputBox({ data }: OutputBoxProps) {
  const traducciones: Record<string, string> = {
    Online: "En l√≠nea",
    "Power fail": "Problema de energ√≠a",
    LOS: "Sin se√±al/sin luz",
    Offline: "Fuera de l√≠nea",
    true: "Conectado",
    false: "Desconectado",
    Critical: "Cr√≠tico - Luz muy alta",
    Warning: "Advertencia - Luz alta",
    "Very good": "Muy buena - Luz √≥ptima",
  };

  // Texto plano para copiar
  const outputText = `
    Cliente: ${data?.cliente_nombre ?? "-"}
    Domicilio: ${data?.direccion ?? "-"}
    Plan: ${data?.plan ?? "-"}
    Nodo: ${data?.nodo_nombre ? data.nodo_nombre + " - " + (data?.nodo_ip ?? "-") : "-"}
    OLT: ${data?.OLT ?? "-"}
    PPPoE User: ${data?.pppoe_username ?? "-"}
    Estado PPPoE: ${traducciones[data?.mikrotik?.active] ?? "-"}
    Tiempo activo: ${data?.mikrotik?.uptime ?? "-"}
    √öltima conexi√≥n: ${data?.mikrotik?.secret?.["last-logged-out"] ?? "-"}
    ONU s/n: ${data?.onu_sn ?? "-"}
    ONU Estado: ${traducciones[data?.onu_status_smrt?.onu_status] ?? "-"}
    ONU √öltimo cambio de estado: ${data?.onu_status_smrt?.last_status_change ?? "-"}
    ONU Se√±al: ${traducciones[data?.onu_signal_smrt?.onu_signal] ?? "-"}
    ONU Se√±al Detalle: ${data?.onu_signal_smrt?.onu_signal_value ?? "-"}
    `;

  return (
    <div className="border rounded p-4 mt-4 bg-gray-50">
      <div className="header-row">
        <h3 className="diagnostic-title">Diagn√≥stico normalizado</h3>
        <CopyButton text={outputText} />
      </div>
      <div className="bg-white p-2 rounded font-mono whitespace-pre-wrap">
      <div className="grid">
        <div className="cell span-2"><strong>Cliente:</strong> {data?.cliente_nombre ?? "-"}</div>
        <div className="cell span-2"><strong>Domicilio:</strong> {data?.direccion ?? "-"}</div>
        <div className="cell"><strong>Plan:</strong> {data?.plan ?? "-"}</div>
        <div className="cell"><strong>Nodo:</strong> {data?.nodo_nombre ? data.nodo_nombre + " - " + (data?.nodo_ip ?? "-") : "-"}</div>
        <div className="cell"><strong>OLT:</strong> {data?.OLT ?? "-"}</div>
        <div className={`cell ${data?.mikrotik?.active ? "estado-ok" : "estado-error"}`}>
          <strong>Estado PPPoE:</strong> {traducciones[data?.mikrotik?.active] ?? "-"}
        </div>
        <div className="cell"><strong>Tiempo activo:</strong> {data?.mikrotik?.uptime ?? "-"}</div>
        <div className="cell"><strong>√öltima conexi√≥n:</strong> {data?.mikrotik?.secret?.["last-logged-out"] ?? "-"}</div>
        <div className="cell"><strong>ONU s/n:</strong> {data?.onu_sn ?? "-"}</div>
        <div className={`cell ${data?.onu_status_smrt?.onu_status === "Online" ? "estado-ok" : "estado-error"}`}>
          <strong>ONU Estado:</strong> {traducciones[data?.onu_status_smrt?.onu_status] ?? "-"}
        </div>
        <div className="cell"><strong>√öltimo cambio de estado:</strong> {data?.onu_status_smrt?.last_status_change ?? "-"}</div>
        <div className="cell"><strong>ONU Se√±al:</strong> {traducciones[data?.onu_signal_smrt?.onu_signal] ?? "-"}</div>
        <div className="cell"><strong>Se√±al Detalle:</strong> {data?.onu_signal_smrt?.onu_signal_value ?? "-"}</div>
        </div>
        
      </div>
      <CopyButton text={outputText} />
    </div>
    //luego agregar los demas campos de datos de cliente
  );
}

==================================================
ARCHIVO: txt\SearchBox.tsx.txt
==================================================
import { useState } from "react";

export default function SearchBox({ onResult }: { onResult: (data: any) => void }) {
  const [pppoe, setPppoe] = useState("");
  const [error, setError] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);

  const handleSearch = async () => {
    setLoading(true);
    setError(null);

    try {
      const resp = await fetch(
        `${import.meta.env.VITE_API_URL}/diagnosis/${pppoe}`,
        {
          headers: {
            "x-api-key": import.meta.env.VITE_API_KEY,
          },
        }
      );

      if (!resp.ok) {
        throw new Error(`Error ${resp.status}: ${resp.statusText}`);
      }

      const json = await resp.json();
      onResult(json); // enviar resultado al padre
    } catch (err: any) {
      setError(err.message);
      onResult(null); // limpiar resultado si hay error
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="p-4">
      <input
        type="text"
        value={pppoe}
        onChange={(e) => setPppoe(e.target.value)}
        onKeyDown={(e) => {
          if (e.key === "Enter") {
            handleSearch();
          }
        }}
        placeholder="Ingrese PPPoE"
        className="border px-2 py-1 mr-2"
      />
      <button
        onClick={handleSearch}
        className="bg-blue-600 text-white px-3 py-1 rounded"
      >
        Buscar
      </button>

      {loading && <p>Buscando...</p>}
      {error && <p className="text-red-600">Error: {error}</p>}
    </div>
  );
}

==================================================
ARCHIVO: txt\security.py.txt
==================================================
import os
from fastapi import FastAPI, Depends, HTTPException, Security
from fastapi.security.api_key import APIKeyHeader
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")
api_key_header = APIKeyHeader(name="X-API-Key")

def get_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="unauthorized")
    return api_key

==================================================
ARCHIVO: txt\smartolt.py.txt
==================================================
import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call 

SMARTOLT_BASEURL = config.SMARTOLT_BASEURL
SMARTOLT_TOKEN = config.SMARTOLT_TOKEN


def _request(method, endpoint, **kwargs):
    try:
        headers = kwargs.pop("headers", {})
        headers["X-Token"] = SMARTOLT_TOKEN
        url = f"{SMARTOLT_BASEURL}{endpoint}"
        resp = requests.request(method, url, headers=headers, **kwargs)
        resp.raise_for_status()
        return resp
    except Exception as e:
        logger.error(f"Error en request API smartOLT: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}


def get_all_onus():
    try:
        """Devuelve el lote completo de ONUs desde SmartOLT."""
        resp = _request("GET", "/onu/get_all_onus_details")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error("SmartOLT no devolvi√≥ estado OK")
        return data.get("onus", [])
    except Exception as e:
        logger.error(f"Error al obtener listado de onus: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}
    

def get_onu_status(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_status/{onu_id}")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data 
    except Exception as e:
        logger.error(f"Error al consultar estado ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}


def get_onu_signals(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_signal/{onu_id}")
        data = resp.json()  # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data
    except Exception as e:
        logger.error(f"Error al consultar se√±ales ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}
    
def get_attached_vlans(onu_id):
    """Obtiene las VLANs adjuntas de una ONU por external_id."""
    #lista el detalle de la onu, para sacar las attached vlans de sus serviceports
    
    resp = _request("GET", f"/onu/get_onu_details/{onu_id}")
    data = resp.json()
    vlans = []
    if data.get("status"):
        serviceports = data["onu_details"].get("service_ports", [])
        vlans = [sp["vlan"] for sp in serviceports if "vlan" in sp]

    return vlans

==================================================
ARCHIVO: txt\sqlite.py.txt
==================================================
# app/db/sqlite.py
import sqlite3
from app import config
from datetime import datetime


class Database:
    def __init__(self, path=config.DB_PATH):
        self.conn = sqlite3.connect(path)
        self.cursor = self.conn.cursor()

    def insert_subscriber(self, unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode):
        self.cursor.execute("""
            INSERT OR REPLACE INTO subscribers (
                unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, pppoe_username, mode
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode))

    def insert_node(self, node_id, name, ip_address, puerto):
        self.cursor.execute("""
            INSERT OR REPLACE INTO nodes (node_id, name, ip_address, puerto)
            VALUES (?, ?, ?, ?)
        """, (node_id, name, ip_address, puerto))

    def insert_plan(self, plan_id, name, speed, description):
        self.cursor.execute("""
            INSERT OR REPLACE INTO plans (plan_id, name, speed, description)
            VALUES (?, ?, ?, ?)
        """, (plan_id, name, speed, description))

    def insert_connection(self, connection_id, pppoe_username, customer_id, node_id, plan_id, direccion=None):
        self.cursor.execute("""
            INSERT OR REPLACE INTO connections (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion))

    def insert_cliente(self, cliente_data: dict):
        columns = ', '.join(cliente_data.keys())
        placeholders = ', '.join('?' for _ in cliente_data)
        values = tuple(cliente_data.values())
        self.cursor.execute(f"""
            INSERT OR REPLACE INTO clientes ({columns})
            VALUES ({placeholders})
        """, values)
    
    def insert_cliente_email(self, customer_id: int, email: str):
        self.cursor.execute("""
            INSERT INTO clientes_emails (customer_id, email)
            VALUES (?, ?)
        """, (customer_id, email))
    
    def insert_cliente_telefono(self, customer_id: int, number: str):
        self.cursor.execute("""
            INSERT INTO clientes_telefonos (customer_id, number)
            VALUES (?, ?)
        """, (customer_id, number))
    
    def match_connections(self):
        self.cursor.execute("""
            UPDATE subscribers
            SET node_id = (
                SELECT node_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            ),
            connection_id = (
                SELECT connection_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            )
        """)
    
    def log_sync_status(self, fuente: str, estado: str, detalle: str = ""):
        """Registra el estado de sincronizaci√≥n de una fuente"""
        self.cursor.execute("""
            INSERT INTO sync_status (fuente, ultima_actualizacion, estado, detalle)
            VALUES (?, ?, ?, ?)
        """, (fuente, datetime.now(), estado, detalle))
        self.commit()

    def get_diagnosis(self, pppoe_user: str) -> dict:
        query = """
        SELECT s.unique_external_id,
                s.pppoe_username,
                s.sn AS onu_sn,
                s.mode as Modo,
                s.olt_name AS OLT,
                n.name AS nodo_nombre,
                n.ip_address AS nodo_ip,
                n.puerto AS puerto,
                p.name AS plan,
                c.direccion AS direccion,
                l.name AS cliente_nombre
        FROM clientes l
        LEFT JOIN connections c ON l.id = c.customer_id
        LEFT JOIN subscribers s ON c.pppoe_username = s.pppoe_username
        LEFT JOIN nodes n ON c.node_id = n.node_id
        LEFT JOIN plans p ON c.plan_id = p.plan_id
        WHERE c.pppoe_username = ?
        """
        self.cursor.execute(query, (pppoe_user,))
        row = self.cursor.fetchone()

        if not row:
            return {"error": f"Cliente {pppoe_user} no encontrado"}

        diagnosis = {
            "unique_external_id": row[0],
            "pppoe_username": row[1],
            "onu_sn": row[2],
            "Modo": row[3],
            "OLT": row[4],
            "nodo_nombre": row[5],
            "nodo_ip": row[6],
            "puerto": row[7],
            "plan": row[8],
            "direccion": row[9],
            "cliente_nombre": row[10]
        }
        return diagnosis
    
    

    def commit(self):
        self.conn.commit()

    def close(self):
        self.conn.close()

### Fin de la clase Database ###
def columnas_tabla(conn, tabla: str) -> set:
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({tabla})")
        return {row[1] for row in cur.fetchall()}  # row[1] = nombre columna

def insert_cliente_safe(db, json_cliente: dict):
    cols = columnas_tabla(db.conn, "clientes")
    data = mapear_cliente(json_cliente)

    # Filtrar a solo columnas v√°lidas
    data_filtrada = {k: v for k, v in data.items() if k in cols}

    # Reusar tu m√©todo din√°mico
    db.insert_cliente(data_filtrada)


# Inicializaci√≥n de la base de datos y creaci√≥n de tablas
def init_db():
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # Tabla de suscriptores (SmartOLT)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS subscribers (
            unique_external_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            sn TEXT,
            olt_name TEXT,
            olt_id TEXT,
            board TEXT,
            port TEXT,
            onu TEXT,
            onu_type_id TEXT,
            mode TEXT,
            node_id TEXT,
            connection_id TEXT,
            vlan TEXT
        )
    """)

    # Tabla de nodos (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS nodes (
            node_id TEXT PRIMARY KEY,
            name TEXT,          -- nombre del nodo (comment en ISPCube)
            ip_address TEXT,
            puerto TEXT
        )
    """)

    # Tabla de planes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS plans (
            plan_id TEXT PRIMARY KEY,
            name TEXT,
            speed TEXT,
            description TEXT
        )
    """)

    # Tabla de conexiones (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS connections (
            connection_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            customer_id TEXT,
            node_id TEXT,
            plan_id TEXT,
            direccion TEXT
        )
    """)
    
     # Tabla de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes (
            id INTEGER PRIMARY KEY,              -- id del cliente
            code TEXT,
            name TEXT,
            tax_residence TEXT,
            type TEXT,
            tax_situation_id INTEGER,
            identification_type_id INTEGER,
            doc_number TEXT,
            auto_bill_sending INTEGER,
            auto_payment_recipe_sending INTEGER,
            nickname TEXT,
            comercial_activity TEXT,
            address TEXT,
            between_address1 TEXT,
            between_address2 TEXT,
            city_id INTEGER,
            lat TEXT,
            lng TEXT,
            extra1 TEXT,
            extra2 TEXT,
            entity_id INTEGER,
            collector_id INTEGER,
            seller_id INTEGER,
            block INTEGER,
            free INTEGER,
            apply_late_payment_due INTEGER,
            apply_reconnection INTEGER,
            contract INTEGER,
            contract_type_id INTEGER,
            contract_expiration_date TEXT,
            paycomm TEXT,
            expiration_type_id INTEGER,
            business_id INTEGER,
            first_expiration_date TEXT,
            second_expiration_date TEXT,
            next_month_corresponding_date INTEGER,
            start_date TEXT,
            perception_id INTEGER,
            phonekey TEXT,
            debt TEXT,
            duedebt TEXT,
            speed_limited INTEGER,
            status TEXT,
            enable_date TEXT,
            block_date TEXT,
            created_at TEXT,
            updated_at TEXT,
            deleted_at TEXT,
            temporary INTEGER
        )

    """)

    #Tabla de emails de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_emails (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            email TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    #Tabla de tel√©fonos de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_telefonos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            number TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    # Tabla de estados de sincronizaci√≥n
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS sync_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            fuente TEXT NOT NULL,                 -- 'smartolt', 'ispcube', 'mikrotik', etc.
            ultima_actualizacion TEXT NOT NULL,   -- ISO 8601 (ej. '2025-11-26T19:45:00')
            estado TEXT NOT NULL,                 -- 'ok', 'empty', 'error'
            detalle TEXT
        )
    """)

    # √çndice √∫til para consultas por fuente y fecha
    cursor.execute("""
    CREATE INDEX IF NOT EXISTS idx_sync_status_fuente_fecha
    ON sync_status (fuente, ultima_actualizacion)
    """)


    conn.commit()
    conn.close()


==================================================
ARCHIVO: txt\sync.py.txt
==================================================
from app.db.sqlite import Database, init_db
from app.clients import smartolt, ispcube
from app import config
from app.utils.safe_call import safe_call


def sync_onus(db):
    onus = smartolt.get_all_onus()
    if onus:
        db.cursor.execute("DELETE FROM subscribers")
        for onu in onus:
            db.insert_subscriber(
                onu.get("unique_external_id"), # type: ignore
                onu.get("sn"), # type: ignore
                onu.get("olt_name"), # type: ignore
                onu.get("olt_id"), # type: ignore
                onu.get("board"), # type: ignore
                onu.get("port"), # type: ignore
                onu.get("onu"), # type: ignore
                onu.get("onu_type_id"), # type: ignore
                onu.get("name"), # type: ignore
                onu.get("mode") # type: ignore
            )
        db.log_sync_status("smartolt", "ok", f"{len(onus)} ONUs sincronizadas")
        config.logger.info(f"[SYNC] {len(onus)} ONUs sincronizadas.")
    else:
        db.log_sync_status("smartolt", "empty", "SmartOLT no devolvi√≥ datos, se mantienen registros anteriores")
        config.logger.info(f"[SYNC] no se pudo sincronizar ONUs.")


def sync_nodes(db):
    nodes = ispcube.obtener_nodos()
    if nodes:
        db.cursor.execute("DELETE FROM nodes")  # Limpia la tabla antes de insertar
    for n in nodes:
        db.insert_node(n["id"], n["name"], n["ip"], n["puerto"])
    config.logger.info(f"[SYNC] {len(nodes)} nodos sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(nodes)} nodos sincronizadas")


def sync_plans(db):
    planes = ispcube.obtener_planes()
    if planes:
        db.cursor.execute("DELETE FROM plans")  # Limpia la tabla antes de insertar 
    for p in planes:
        db.insert_plan(p["id"], p["name"], p.get("speed"), p.get("comment"))
    config.logger.info(f"[SYNC] {len(planes)} planes sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(planes)} planes sincronizadas")


def sync_connections(db):
    conexiones = ispcube.obtener_todas_conexiones()
    if conexiones:
        db.cursor.execute("DELETE FROM connections")  # Limpia la tabla antes de insertar
    for c in conexiones:
        db.insert_connection(c["id"], c["user"], c["customer_id"], c["node_id"], c["plan_id"], c.get("direccion"))
    config.logger.info(f"[SYNC] {len(conexiones)} conexiones sincronizadas.")
    db.log_sync_status("ispcube", "ok", f"{len(conexiones)} conecciones sincronizadas")

def sync_clientes(db):
    clientes = ispcube.obtener_clientes()  # debe devolver la lista completa cruda del endpoint
    if clientes:
        db.cursor.execute("DELETE FROM clientes")
        db.cursor.execute("DELETE FROM clientes_emails")
        db.cursor.execute("DELETE FROM clientes_telefonos")

        for c in clientes:
            cliente_data = mapear_cliente(c)
            db.insert_cliente(cliente_data)
            insertar_contactos_relacionados(db, c)

        db.commit()
        config.logger.info(f"[SYNC] {len(clientes)} clientes sincronizados.")
        db.log_sync_status("ispcube", "ok", f"{len(clientes)} clientes sincronizados")
    else:
        config.logger.warning("[SYNC] ISPCube no devolvi√≥ clientes")
        db.log_sync_status("ispcube", "empty", "Sin datos de clientes")

def insertar_contactos_relacionados(db, json_cliente: dict):
    # Emails
    for email_obj in json_cliente.get("contact_emails", []):
        email = email_obj.get("email")
        if email:
            db.insert_cliente_email(json_cliente["id"], email)

    # Tel√©fonos
    for tel_obj in json_cliente.get("phones", []):
        number = tel_obj.get("number")
        if number:
            db.insert_cliente_telefono(json_cliente["id"], number)

def nightly_sync():
    init_db()  # asegura el esquema antes de cualquier operaci√≥n
    db = Database()
    try:
        sync_onus(db)
        sync_clientes(db)
        sync_nodes(db)
        sync_plans(db)
        sync_connections(db)
        db.match_connections()
        db.commit()
        config.logger.info("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
        print("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
    finally:
        db.close()


#------------------ Funciones de mapeo ------------------
#------------------
def mapear_cliente(json_cliente: dict) -> dict:
    """
    Convierte el JSON de ISPCube en un dict compatible con la tabla clientes.
    Incluye casi todos los campos del ejemplo.
    """
    return {
        "id": json_cliente.get("id"),
        "code": json_cliente.get("code"),
        "name": json_cliente.get("name"),
        "tax_residence": json_cliente.get("tax_residence"),
        "type": json_cliente.get("type"),
        "tax_situation_id": json_cliente.get("tax_situation_id"),
        "identification_type_id": json_cliente.get("identification_type_id"),
        "doc_number": json_cliente.get("doc_number"),
        "auto_bill_sending": json_cliente.get("auto_bill_sending"),
        "auto_payment_recipe_sending": json_cliente.get("auto_payment_recipe_sending"),
        "nickname": json_cliente.get("nickname"),
        "comercial_activity": json_cliente.get("comercial_activity"),
        "address": json_cliente.get("address"),
        "between_address1": json_cliente.get("between_address1"),
        "between_address2": json_cliente.get("between_address2"),
        "city_id": json_cliente.get("city_id"),
        "lat": json_cliente.get("lat"),
        "lng": json_cliente.get("lng"),
        "extra1": json_cliente.get("extra1"),
        "extra2": json_cliente.get("extra2"),
        "entity_id": json_cliente.get("entity_id"),
        "collector_id": json_cliente.get("collector_id"),
        "seller_id": json_cliente.get("seller_id"),
        "block": json_cliente.get("block"),
        "free": json_cliente.get("free"),
        "apply_late_payment_due": json_cliente.get("apply_late_payment_due"),
        "apply_reconnection": json_cliente.get("apply_reconnection"),
        "contract": json_cliente.get("contract"),
        "contract_type_id": json_cliente.get("contract_type_id"),
        "contract_expiration_date": json_cliente.get("contract_expiration_date"),
        "paycomm": json_cliente.get("paycomm"),
        "expiration_type_id": json_cliente.get("expiration_type_id"),
        "business_id": json_cliente.get("business_id"),
        "first_expiration_date": json_cliente.get("first_expiration_date"),
        "second_expiration_date": json_cliente.get("second_expiration_date"),
        "next_month_corresponding_date": json_cliente.get("next_month_corresponding_date"),
        "start_date": json_cliente.get("start_date"),
        "perception_id": json_cliente.get("perception_id"),
        "phonekey": json_cliente.get("phonekey"),
        "debt": json_cliente.get("debt"),
        "duedebt": json_cliente.get("duedebt"),
        "speed_limited": json_cliente.get("speed_limited"),
        "status": json_cliente.get("status"),
        "enable_date": json_cliente.get("enable_date"),
        "block_date": json_cliente.get("block_date"),
        "created_at": json_cliente.get("created_at"),
        "updated_at": json_cliente.get("updated_at"),
        "deleted_at": json_cliente.get("deleted_at"),
        "temporary": json_cliente.get("temporary"),
    }
#------------------

if __name__ == "__main__":
    try:
        nightly_sync()
    except Exception as e:
        print(f"[ERROR] Fall√≥ la sincronizaci√≥n: {e}")




==================================================
ARCHIVO: app\config.py
==================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv(dotenv_path=os.path.join("config", ".env"))

# Variables de entorno
API_KEY = os.getenv("API_KEY")
SMARTOLT_BASEURL = os.getenv("SMARTOLT_BASEURL")
SMARTOLT_TOKEN = os.getenv("SMARTOLT_TOKEN")
MK_HOST = os.getenv("MK_HOST")
MK_USER = os.getenv("MK_USER")
MK_PASS = os.getenv("MK_PASS")
MK_PORT = int(os.getenv("MK_PORT", 8799))
GENIEACS_URL = os.getenv("GENIEACS_URL")
ISPCUBE_BASEURL=os.getenv("ISPCUBE_BASEURL")
ISPCUBE_APIKEY=os.getenv("ISPCUBE_APIKEY")
ISPCUBE_USER=os.getenv("ISPCUBE_USER")
ISPCUBE_PASSWORD=os.getenv("ISPCUBE_PASSWORD")
ISPCUBE_CLIENTID=os.getenv("ISPCUBE_CLIENTID")

DB_PATH = os.path.abspath(os.getenv("DB_PATH", "data/diag.db"))

# Crear carpeta data/ si no existe
db_dir = os.path.dirname(DB_PATH)
if not os.path.exists(db_dir):
    os.makedirs(db_dir, exist_ok=True)

# Logging centralizado
log_dir = os.path.join(db_dir, "logs")
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(log_dir, "sync.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("beholder")

==================================================
ARCHIVO: app\main.py
==================================================
from fastapi import FastAPI, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
from app import config
from app.services.diagnostico import consultar_diagnostico
from app.security import get_api_key
from app.db.sqlite import Database # Importaci√≥n necesaria
from app.config import logger
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Beholder - Diagn√≥stico Centralizado")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
def startup_event():
    config.logger.info("Servicio Beholder iniciado.")

@app.middleware("http")
async def check_api_key(request: Request, call_next):
    if request.method == "OPTIONS":
        return await call_next(request)
    key = request.headers.get("x-api-key")
    if key != config.API_KEY:
        return JSONResponse(status_code=401, content={"detail": "unauthorized"})
    return await call_next(request)

@app.get("/health")
def health():
    return {"ok": True, "service": "beholder", "status": "running"}

@app.get("/diagnosis/{pppoe_user}")
def diagnosis(pppoe_user: str):
    try:
        row = consultar_diagnostico(pppoe_user)
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}")
        raise HTTPException(status_code=500, detail=str(e))
    if "error" in row:
        raise HTTPException(status_code=404, detail=row["error"])
    return row

# --- NUEVO ENDPOINT DE B√öSQUEDA ---
@app.get("/search")
def search_clients(q: str):
    """
    Busca clientes por nombre, direcci√≥n o PPPoE (Gesti√≥n + OLT).
    """
    if not q or len(q) < 3:
        return []
    
    db = Database()
    try:
        results = db.search_client(q)
        return results
    except Exception as e:
        logger.exception(f"Error buscando cliente: {q}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

@app.get("/")
def read_root(api_key: str = Depends(get_api_key)):
    return {"status": "ok", "service": "Beholder API"}

==================================================
ARCHIVO: app\security.py
==================================================
import os
from fastapi import FastAPI, Depends, HTTPException, Security
from fastapi.security.api_key import APIKeyHeader
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")
api_key_header = APIKeyHeader(name="X-API-Key")

def get_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="unauthorized")
    return api_key

==================================================
ARCHIVO: app\clients\ispcube.py
==================================================
import requests
import sys
from app import config
from app.config import logger

ISPCUBE_BASEURL = config.ISPCUBE_BASEURL
ISPCUBE_APIKEY = config.ISPCUBE_APIKEY
ISPCUBE_USER = config.ISPCUBE_USER
ISPCUBE_PASSWORD = config.ISPCUBE_PASSWORD
ISPCUBE_CLIENTID = config.ISPCUBE_CLIENTID

# Cache interno del token
_token_cache = None


def _obtener_token():
    """Solicita un nuevo token a ISPCube."""
    url = f"{ISPCUBE_BASEURL}/sanctum/token"
    payload = {"username": ISPCUBE_USER, "password": ISPCUBE_PASSWORD}
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api"
    }
    resp = requests.post(url, json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()["token"]


def _get_token(force_refresh=False):
    """Devuelve un token v√°lido, renovando si es necesario."""
    global _token_cache
    if force_refresh or _token_cache is None:
        _token_cache = _obtener_token()
    return _token_cache

def _headers(token=None):
    """Headers est√°ndar para todas las llamadas."""
    return {
        "Authorization": f"Bearer {token or _get_token()}",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api",
        "Accept": "application/json",
        "username": ISPCUBE_USER
    }


def _request(method, url, **kwargs):
    """
    Wrapper de requests que maneja expiraci√≥n de token.
    Si recibe 401, renueva token y reintenta una vez.
    """
    token = _get_token()
    headers = kwargs.pop("headers", {})
    headers.update(_headers(token))
    
    # IMPORTANTE: requests maneja 'params' autom√°ticamente si se pasan en kwargs
    resp = requests.request(method, url, headers=headers, **kwargs)
    
    if resp.status_code == 401:
        # Token expirado ‚Üí renovar y reintentar
        logger.warning("Token expirado, renovando...")
        token = _get_token(force_refresh=True)
        headers.update(_headers(token))
        resp = requests.request(method, url, headers=headers, **kwargs)
    
    resp.raise_for_status()
    return resp

# ------------------ Funciones p√∫blicas ------------------

def obtener_nodos():
    """Devuelve lista de nodos con id, name, ip."""
    url = f"{ISPCUBE_BASEURL}/nodes/nodes_list"
    resp = _request("GET", url)
    body = resp.json()
    items = body["data"] if isinstance(body, dict) and "data" in body else body
    nodos = []
    for n in items:
        nodos.append({
            "id": n.get("id"),
            "name": n.get("comment"),
            "ip": n.get("ip"),
            "puerto": n.get("port")
        })
    return nodos


def obtener_conexion(pppoe):
    url = f"{ISPCUBE_BASEURL}/connections?pppoe={pppoe}"
    resp = _request("GET", url)
    data = resp.json()
    if data:
        conn = data[0]
        return conn["id"], conn.get("node_id")
    logger.error(f"No se encontr√≥ conexi√≥n en ISPCube para {pppoe}")


def obtener_conexion_por_pppoe(pppoe_user):
    url = f"{ISPCUBE_BASEURL}/connection?user={pppoe_user}"
    resp = _request("GET", url)
    cliente = resp.json()

    conexiones = cliente.get("connections", [])
    if not conexiones:
        logger.error(f"No se encontraron conexiones para PPPoE {pppoe_user}")

    for conn in conexiones:
        if conn.get("conntype") == "pppoe" and conn.get("user") == pppoe_user:
            return conn["id"], conn.get("node_id")

    logger.error(f"No se encontr√≥ conexi√≥n PPPoE exacta para {pppoe_user}")


def obtener_todas_conexiones():
    # Nota: Si conexiones tambi√©n crece mucho, habr√° que paginarla igual que clientes.
    # Por ahora 7000 conexiones parece pasar el filtro de timeout, pero estamos al l√≠mite.
    url = f"{ISPCUBE_BASEURL}/connections/connections_list"
    resp = _request("GET", url)
    conexiones = resp.json()

    if not isinstance(conexiones, list):
        logger.error("Respuesta inesperada de ISPCube al listar conexiones")

    resultado = []
    for c in conexiones:
        if c.get("conntype") == "pppoe":
            resultado.append({
                "user": c.get("user"),
                "customer_id": c.get("customer_id"),
                "id": c.get("id"),
                "node_id": c.get("node_id"),
                "plan_id": c.get("plan_id"),
                "direccion": c.get("address")
            })
    return resultado


def obtener_planes():
    url = f"{ISPCUBE_BASEURL}/plans/plans_list"
    resp = _request("GET", url)
    planes = resp.json()

    if not isinstance(planes, list):
        logger.error("Respuesta inesperada de ISPCube al listar planes")

    resultado = []
    for p in planes:
        resultado.append({
            "id": p.get("id"),
            "name": p.get("name"),
            "speed": p.get("speed"),
            "comment": p.get("comment")
        })
    return resultado

def obtener_clientes():
    """
    Devuelve lista completa de clientes usando PAGINACI√ìN para evitar Timeouts.
    Baja de a 500 registros.
    """
    url = f"{ISPCUBE_BASEURL}/customers/customers_list"
    all_customers = []
    
    # Configuraci√≥n de paginaci√≥n
    LIMIT = 500
    offset = 0
    
    # Feedback visual para consola
    print(f"     ‚Ü≥ [Paginaci√≥n] Iniciando descarga de a {LIMIT} registros...")
    
    while True:
        try:
            # Pasamos los par√°metros de paginaci√≥n
            # La mayor√≠a de APIs de ISPCube/Laravel usan limit y offset
            params = {
                "limit": LIMIT,
                "offset": offset
            }
            
            resp = _request("GET", url, params=params)
            batch = resp.json()
            
            if not isinstance(batch, list):
                logger.error(f"Formato inesperado en bloque {offset}")
                break
                
            count = len(batch)
            if count == 0:
                break # Fin de los datos
            
            all_customers.extend(batch)
            
            # Feedback en la misma l√≠nea para no ensuciar el log
            sys.stdout.write(f"\r     ‚Ü≥ [Paginaci√≥n] Bajados: {len(all_customers)} clientes...")
            sys.stdout.flush()
            
            # Si el bloque trajo menos del l√≠mite, significa que es el √∫ltimo
            if count < LIMIT:
                break
            
            # Avanzamos el offset para la siguiente p√°gina
            offset += LIMIT
            
        except Exception as e:
            print(f"\n‚ùå Error bajando bloque offset={offset}: {e}")
            # Si falla un bloque, devolvemos lo que tenemos hasta ahora para no perder todo
            break

    print(f" ‚úÖ Total: {len(all_customers)}")
    return all_customers

==================================================
ARCHIVO: app\clients\mikrotik.py
==================================================
import time
from app.config import logger
from app.utils.safe_call import safe_call
from routeros_api import RouterOsApiPool
from app import config

# Credenciales comunes para todos los Mikrotik
MIKROTIK_USER = config.MK_USER
MIKROTIK_PASS = config.MK_PASS
MIKROTIK_PORT = config.MK_PORT   # üëà tu puerto personalizado
MIKROTIK_IP   = config.MK_HOST  

#Nota para producci√≥n: borrar =MIKROTIK_IP y pasar IP como par√°metro en cada funci√≥n

def _connect(router_ip, port, username=MIKROTIK_USER, password=MIKROTIK_PASS):
    try:
        pool = RouterOsApiPool(
            router_ip,
            username=username, # type: ignore
            password=password, # type: ignore
            port=port,              
            plaintext_login=True
        )
        return pool, pool.get_api()
    except Exception as e:
        logger.error(f"Error de conexi√≥n al router {router_ip}: {e}")
        return {"error": str(e)}

def obtener_secret(router_ip, pppoe_user, puerto): #MIKROTIK_IP, router_ip
    try:
        pool, api = _connect(router_ip, puerto)
        secrets = api.get_resource('/ppp/secret')
        result = secrets.get(name=pppoe_user)
        pool.disconnect()
        if not result:
            logger.error(f"Secret {pppoe_user} no encontrado en {router_ip}")
        return result[0]
    except Exception as e:
        logger.error(f"Error al obtener secret {pppoe_user} en {router_ip}: {e}")
        return {"error": str(e)}

# Obtener todos los secrets del router
def get_all_secrets(router_ip, port):
    """
    Descarga la lista completa de secrets del router.
    """
    try:
        pool, api = _connect(router_ip, port)
        # Pedimos todos los secrets
        secrets = api.get_resource('/ppp/secret').get()
        pool.disconnect()
        return secrets
    except Exception as e:
        logger.error(f"Error al obtener todos los secrets de {router_ip}: {e}")
        return []

# def crear_secret(router_ip, datos_secret):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     secrets.add(
#         name=datos_secret['name'] + "R", # Borrar la "R" para producci√≥n
#         password=datos_secret['password'],
#         profile=datos_secret.get('profile', 'default'),
#         service=datos_secret.get('service', 'pppoe')
#     )
#     pool.disconnect()
#     logger.info(f"Secret {datos_secret['name']} creado en {router_ip}")

# def borrar_secret(router_ip, pppoe_user):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     result = secrets.get(name=pppoe_user)
#     if result:
#         secret = result[0]
#         secret_id = secret.get('.id') or secret.get('id')

#         #id=result[0]['.id']
#         secrets.remove(id=secret_id)
#         logger.info(f"Secret {pppoe_user} eliminado de {router_ip}")
#     pool.disconnect()

# def migrar_secret(origen_ip, destino_ip, pppoe_user):
   
#     datos = obtener_secret(origen_ip, pppoe_user)


#     crear_secret(destino_ip, datos)
#     # Validaci√≥n inicial
#     if not validar_pppoe(destino_ip, pppoe_user):
#         logger.info(f"Esperando 60s para revalidar {pppoe_user} en {destino_ip}...")
#         time.sleep(60)

#         # Segundo intento
#         if not validar_pppoe(destino_ip, pppoe_user):
#             logger.error(f"‚ùå {pppoe_user} no levant√≥ en {destino_ip}, rollback.")
#             #borrar_secret(destino_ip, pppoe_user)
#             return False

#     # Si lleg√≥ ac√°, est√° online ‚Üí borrar en origen
#     borrar_secret(origen_ip, pppoe_user)
#     logger.info(f"‚úÖ {pppoe_user} migrado de {origen_ip} a {destino_ip}")
#     return True


# def rollback_secret(origen_ip, destino_ip, pppoe_user):
    
#     origen_ip = MIKROTIK_IP #borrar para producci√≥n
#     destino_ip = MIKROTIK_IP #borrar para producci√≥n

#     datos = obtener_secret(destino_ip, pppoe_user)
#     crear_secret(origen_ip, datos)
#     borrar_secret(destino_ip, pppoe_user)
#     return True

def validar_pppoe(router_ip: str, pppoe_user: str, puerto: str) -> dict:
    try:
        pool, api = _connect(router_ip, puerto)
        #pool, api = _connect(MIKROTIK_IP) #borrar para producci√≥n
        activos = api.get_resource('/ppp/active')
        result = activos.get(name=pppoe_user)
        pool.disconnect()

        if result:
            logger.info(f"PPP user {pppoe_user} activo en {router_ip}")
            return {"active": True, **result[0]}
        else:
            logger.warning(f"PPP user {pppoe_user} NO activo en {router_ip}")
            try:
                #modificar aca
                secret = obtener_secret(router_ip, pppoe_user, puerto)
                return {"active": False, "secret": secret}
            except Exception:
                return {"active": False}
    except Exception as e:
        logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
        return {"active": False, "error": str(e)}
        # Si no est√° activo y no se encuentra el secret, no se puede obtener m√°s info
# def validar_pppoe(router_ip: str, pppoe_user: str) -> dict:
#     try:
#         pool, api = _connect(router_ip)
#         activos = api.get_resource('/ppp/active')
#         result = activos.get(name=pppoe_user)
#         pool.disconnect()

#         if result:
#             # Tomamos el primer dict y lo expandimos directamente
#             return {"active": True, **result[0]}
#         else:
#             return {"active": False}
#     except Exception as e:
#         logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
#         return {"active": False, "error": str(e)}


==================================================
ARCHIVO: app\clients\smartolt.py
==================================================
import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call 

SMARTOLT_BASEURL = config.SMARTOLT_BASEURL
SMARTOLT_TOKEN = config.SMARTOLT_TOKEN


def _request(method, endpoint, **kwargs):
    try:
        headers = kwargs.pop("headers", {})
        headers["X-Token"] = SMARTOLT_TOKEN
        url = f"{SMARTOLT_BASEURL}{endpoint}"
        resp = requests.request(method, url, headers=headers, **kwargs)
        resp.raise_for_status()
        return resp
    except Exception as e:
        logger.error(f"Error en request API smartOLT: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}


def get_all_onus():
    try:
        """Devuelve el lote completo de ONUs desde SmartOLT."""
        resp = _request("GET", "/onu/get_all_onus_details")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error("SmartOLT no devolvi√≥ estado OK")
        return data.get("onus", [])
    except Exception as e:
        logger.error(f"Error al obtener listado de onus: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}
    

def get_onu_status(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_status/{onu_id}")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data 
    except Exception as e:
        logger.error(f"Error al consultar estado ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}


def get_onu_signals(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_signal/{onu_id}")
        data = resp.json()  # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data
    except Exception as e:
        logger.error(f"Error al consultar se√±ales ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}
    
def get_attached_vlans(onu_id):
    """Obtiene las VLANs adjuntas de una ONU por external_id."""
    #lista el detalle de la onu, para sacar las attached vlans de sus serviceports
    
    resp = _request("GET", f"/onu/get_onu_details/{onu_id}")
    data = resp.json()
    vlans = []
    if data.get("status"):
        serviceports = data["onu_details"].get("service_ports", [])
        vlans = [sp["vlan"] for sp in serviceports if "vlan" in sp]

    return vlans

==================================================
ARCHIVO: app\clients\__init__.py
==================================================


==================================================
ARCHIVO: app\db\sqlite.py
==================================================
import sqlite3
from app import config
from datetime import datetime

class Database:
    def __init__(self, path=config.DB_PATH):
        self.conn = sqlite3.connect(path)
        self.conn.row_factory = sqlite3.Row
        self.cursor = self.conn.cursor()

    # ------------------ INSERTS ------------------
    def insert_subscriber(self, unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode):
        self.cursor.execute("INSERT OR REPLACE INTO subscribers (unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, pppoe_username, mode) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", (unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode))
    
    def insert_node(self, node_id, name, ip_address, puerto):
        self.cursor.execute("INSERT OR REPLACE INTO nodes (node_id, name, ip_address, puerto) VALUES (?, ?, ?, ?)", (node_id, name, ip_address, puerto))
    
    def insert_plan(self, plan_id, name, speed, description):
        self.cursor.execute("INSERT OR REPLACE INTO plans (plan_id, name, speed, description) VALUES (?, ?, ?, ?)", (plan_id, name, speed, description))
    
    def insert_connection(self, connection_id, pppoe_username, customer_id, node_id, plan_id, direccion=None):
        self.cursor.execute("INSERT OR REPLACE INTO connections (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion) VALUES (?, ?, ?, ?, ?, ?)", (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion))
    
    def insert_cliente(self, cliente_data: dict):
        columns = ', '.join(cliente_data.keys())
        placeholders = ', '.join('?' for _ in cliente_data)
        values = tuple(cliente_data.values())
        self.cursor.execute(f"INSERT OR REPLACE INTO clientes ({columns}) VALUES ({placeholders})", values)
    
    def insert_cliente_email(self, customer_id: int, email: str):
        self.cursor.execute("INSERT INTO clientes_emails (customer_id, email) VALUES (?, ?)", (customer_id, email))
    
    def insert_cliente_telefono(self, customer_id: int, number: str):
        self.cursor.execute("INSERT INTO clientes_telefonos (customer_id, number) VALUES (?, ?)", (customer_id, number))

    def insert_secret(self, secret_data: dict, router_ip: str):
        # PK COMPUESTA: (name, router_ip) vital para que no se pisen usuarios en distintos nodos
        self.cursor.execute("""
            INSERT OR REPLACE INTO ppp_secrets (name, password, profile, service, last_caller_id, comment, router_ip, last_logged_out)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            secret_data.get("name"), secret_data.get("password"), secret_data.get("profile"), secret_data.get("service"),
            secret_data.get("last-caller-id"), secret_data.get("comment"), router_ip, secret_data.get("last-logged-out")
        ))

    # ------------------ UTILIDADES ------------------
    def get_nodes_for_sync(self) -> list:
        self.cursor.execute("SELECT ip_address, puerto, name FROM nodes WHERE ip_address IS NOT NULL AND ip_address != ''")
        return [{"ip": r[0], "port": int(r[1]) if r[1] and r[1].isdigit() else None, "name": r[2]} for r in self.cursor.fetchall()]

    def match_connections(self):
        self.cursor.execute("UPDATE subscribers SET node_id = (SELECT node_id FROM connections WHERE connections.pppoe_username = subscribers.pppoe_username), connection_id = (SELECT connection_id FROM connections WHERE connections.pppoe_username = subscribers.pppoe_username)")
        self.commit()
    
    def log_sync_status(self, fuente: str, estado: str, detalle: str = ""):
        self.cursor.execute("INSERT INTO sync_status (fuente, ultima_actualizacion, estado, detalle) VALUES (?, ?, ?, ?)", (fuente, datetime.now(), estado, detalle))
        self.commit()

    # ------------------ B√öSQUEDA (CON FILTRO DE DUPLICADOS) ------------------
    def search_client(self, query_str: str) -> list:
        term = f"%{query_str}%"
        
        # 1. ISPCube (La fuente de verdad) - Usamos c.direccion (instalaci√≥n)
        sql_isp = """
        SELECT 
            c.pppoe_username as pppoe, 
            cl.name as nombre, 
            c.direccion as direccion, 
            cl.id as id, 
            'ispcube' as origen
        FROM clientes cl
        JOIN connections c ON cl.id = c.customer_id
        WHERE cl.name LIKE ? OR c.direccion LIKE ? OR c.pppoe_username LIKE ? OR cl.doc_number LIKE ?
        """
        
        # 2. Mikrotik (Datos t√©cnicos crudos)
        sql_mk = """
        SELECT 
            name as pppoe, 
            'No Vinculado' as nombre, 
            CASE WHEN comment IS NOT NULL AND comment != '' THEN 'MK: ' || comment ELSE 'Sin Datos' END as direccion,
            0 as id, 
            'mikrotik' as origen
        FROM ppp_secrets
        WHERE name LIKE ? OR last_caller_id LIKE ?
        """

        # 3. SmartOLT
        sql_olt = """
        SELECT 
            pppoe_username as pppoe, 
            'No Vinculado' as nombre, 
            'OLT SN: ' || sn as direccion,
            0 as id, 
            'smartolt' as origen
        FROM subscribers
        WHERE pppoe_username LIKE ? OR sn LIKE ?
        LIMIT 50
        """
        
        # Ejecuci√≥n y Filtrado
        self.cursor.execute(sql_isp, (term, term, term, term))
        rows_isp = [dict(r) for r in self.cursor.fetchall()]
        
        # Guardamos los PPPoEs que ya encontramos en ISPCube para no repetirlos
        pppoes_encontrados = set(r['pppoe'] for r in rows_isp)
        
        self.cursor.execute(sql_mk, (term, term))
        rows_mk = [dict(r) for r in self.cursor.fetchall()]
        
        # Solo agregamos el de Mikrotik si NO est√° ya en la lista de ISPCube
        clean_mk = [r for r in rows_mk if r['pppoe'] not in pppoes_encontrados]

        self.cursor.execute(sql_olt, (term, term))
        rows_olt = [dict(r) for r in self.cursor.fetchall()]
        
        # Lo mismo para SmartOLT
        clean_olt = [r for r in rows_olt if r['pppoe'] not in pppoes_encontrados]

        return rows_isp + clean_mk + clean_olt

    # ------------------ DIAGN√ìSTICO ------------------
    def get_diagnosis(self, pppoe_user: str) -> dict:
        # 1. Datos ISPCube
        sql_admin = """
        SELECT s.unique_external_id, s.pppoe_username, s.sn AS onu_sn, s.mode as Modo, s.olt_name AS OLT,
                n.name AS nodo_nombre, n.ip_address AS nodo_ip, n.puerto AS puerto, p.name AS plan,
                c.direccion AS direccion, l.name AS cliente_nombre
        FROM connections c
        JOIN clientes l ON c.customer_id = l.id
        LEFT JOIN subscribers s ON c.pppoe_username = s.pppoe_username
        LEFT JOIN nodes n ON c.node_id = n.node_id
        LEFT JOIN plans p ON c.plan_id = p.plan_id
        WHERE c.pppoe_username = ?
        """
        self.cursor.execute(sql_admin, (pppoe_user,))
        row_admin = self.cursor.fetchone()

        # 2. Datos T√©cnicos
        self.cursor.execute("SELECT router_ip, last_caller_id, comment FROM ppp_secrets WHERE name = ?", (pppoe_user,))
        secrets = self.cursor.fetchall()

        selected_secret = None
        if row_admin and row_admin['nodo_ip']:
            target_ip = row_admin['nodo_ip']
            for sec in secrets:
                if sec['router_ip'] == target_ip:
                    selected_secret = sec
                    break
        
        if not selected_secret and secrets:
            selected_secret = secrets[0]

        diagnosis = {}
        if row_admin:
            diagnosis = dict(row_admin)
            if selected_secret:
                diagnosis['mac'] = selected_secret['last_caller_id']
                real_ip = selected_secret['router_ip']
                if real_ip and real_ip != diagnosis['nodo_ip']:
                    self.cursor.execute("SELECT name, ip_address, puerto FROM nodes WHERE ip_address = ?", (real_ip,))
                    real_node = self.cursor.fetchone()
                    if real_node:
                        diagnosis.update({"nodo_nombre": real_node['name'], "nodo_ip": real_node['ip_address'], "puerto": real_node['puerto']})
                    else:
                        diagnosis.update({"nodo_nombre": f"Router {real_ip}", "nodo_ip": real_ip, "puerto": None})
            return diagnosis

        # Caso No Vinculado
        self.cursor.execute("SELECT * FROM subscribers WHERE pppoe_username = ?", (pppoe_user,))
        sub_row = self.cursor.fetchone()

        if not sub_row and not selected_secret:
             return {"error": f"Cliente {pppoe_user} no encontrado."}

        diagnosis = {
            "cliente_nombre": "No Vinculado", "direccion": "N/A", "plan": "N/A", "pppoe_username": pppoe_user,
            "onu_sn": "N/A", "Modo": "N/A", "OLT": "N/A", "nodo_nombre": "Desconocido", "nodo_ip": None,
            "puerto": None, "unique_external_id": None, "mac": None
        }
        if sub_row:
             diagnosis.update({"unique_external_id": sub_row['unique_external_id'], "onu_sn": sub_row['sn'], "OLT": sub_row['olt_name'], "Modo": sub_row['mode']})
        if selected_secret:
            diagnosis['mac'] = selected_secret['last_caller_id']
            if selected_secret['comment']: diagnosis['cliente_nombre'] += f" ({selected_secret['comment']})"
            real_ip = selected_secret['router_ip']
            if real_ip:
                self.cursor.execute("SELECT name, ip_address, puerto FROM nodes WHERE ip_address = ?", (real_ip,))
                node_row = self.cursor.fetchone()
                if node_row:
                    diagnosis.update({"nodo_nombre": node_row['name'], "nodo_ip": node_row['ip_address'], "puerto": node_row['puerto']})
                else:
                    diagnosis.update({"nodo_nombre": f"Router {real_ip}", "nodo_ip": real_ip, "puerto": None})

        return diagnosis

    def commit(self): self.conn.commit()
    def close(self): self.conn.close()

# ------------------ INIT DB ------------------
def init_db():
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()
    
    # ... (Otras tablas iguales) ...
    cursor.execute("CREATE TABLE IF NOT EXISTS subscribers (unique_external_id TEXT PRIMARY KEY, pppoe_username TEXT, sn TEXT, olt_name TEXT, olt_id TEXT, board TEXT, port TEXT, onu TEXT, onu_type_id TEXT, mode TEXT, node_id TEXT, connection_id TEXT, vlan TEXT)")
    cursor.execute("CREATE TABLE IF NOT EXISTS nodes (node_id TEXT PRIMARY KEY, name TEXT, ip_address TEXT, puerto TEXT)")
    cursor.execute("CREATE TABLE IF NOT EXISTS plans (plan_id TEXT PRIMARY KEY, name TEXT, speed TEXT, description TEXT)")
    cursor.execute("CREATE TABLE IF NOT EXISTS connections (connection_id TEXT PRIMARY KEY, pppoe_username TEXT, customer_id TEXT, node_id TEXT, plan_id TEXT, direccion TEXT)")
    
    # TRIPLE COMILLA para evitar errores
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes (
            id INTEGER PRIMARY KEY, code TEXT, name TEXT, tax_residence TEXT, type TEXT, 
            tax_situation_id INTEGER, identification_type_id INTEGER, doc_number TEXT, 
            auto_bill_sending INTEGER, auto_payment_recipe_sending INTEGER, nickname TEXT, 
            comercial_activity TEXT, address TEXT, between_address1 TEXT, between_address2 TEXT, 
            city_id INTEGER, lat TEXT, lng TEXT, extra1 TEXT, extra2 TEXT, entity_id INTEGER, 
            collector_id INTEGER, seller_id INTEGER, block INTEGER, free INTEGER, 
            apply_late_payment_due INTEGER, apply_reconnection INTEGER, contract INTEGER, 
            contract_type_id INTEGER, contract_expiration_date TEXT, paycomm TEXT, 
            expiration_type_id INTEGER, business_id INTEGER, first_expiration_date TEXT, 
            second_expiration_date TEXT, next_month_corresponding_date INTEGER, start_date TEXT, 
            perception_id INTEGER, phonekey TEXT, debt TEXT, duedebt TEXT, speed_limited INTEGER, 
            status TEXT, enable_date TEXT, block_date TEXT, created_at TEXT, updated_at TEXT, 
            deleted_at TEXT, temporary INTEGER
        )
    """)
    
    cursor.execute("CREATE TABLE IF NOT EXISTS clientes_emails (id INTEGER PRIMARY KEY AUTOINCREMENT, customer_id INTEGER NOT NULL, email TEXT NOT NULL, FOREIGN KEY (customer_id) REFERENCES clientes(id))")
    cursor.execute("CREATE TABLE IF NOT EXISTS clientes_telefonos (id INTEGER PRIMARY KEY AUTOINCREMENT, customer_id INTEGER NOT NULL, number TEXT NOT NULL, FOREIGN KEY (customer_id) REFERENCES clientes(id))")
    cursor.execute("CREATE TABLE IF NOT EXISTS sync_status (id INTEGER PRIMARY KEY AUTOINCREMENT, fuente TEXT NOT NULL, ultima_actualizacion TEXT NOT NULL, estado TEXT NOT NULL, detalle TEXT)")
    
    # PK COMPUESTA para soportar usuarios en m√∫ltiples nodos
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS ppp_secrets (
            name TEXT, password TEXT, profile TEXT, service TEXT, last_caller_id TEXT, comment TEXT, router_ip TEXT, last_logged_out TEXT,
            PRIMARY KEY (name, router_ip)
        )
    """)
    
    # √çndices
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_connections_pppoe ON connections(pppoe_username)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_subscribers_pppoe ON subscribers(pppoe_username)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_clientes_name ON clientes(name)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_secrets_lastcaller ON ppp_secrets(last_caller_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_secrets_name ON ppp_secrets(name)")
    
    conn.commit()
    conn.close()

==================================================
ARCHIVO: app\db\__init__.py
==================================================


==================================================
ARCHIVO: app\jobs\debug_ispcube.py
==================================================
import time
from app.db.sqlite import Database, init_db
from app.clients import ispcube
from app.jobs.sync import mapear_cliente, insertar_contactos_relacionados

def debug_sync_clientes():
    print("üîµ [DEBUG] Iniciando entorno local...")
    
    # 1. Inicializar DB local (crear√° diag.db en tu carpeta local)
    init_db()
    db = Database()

    print("‚è≥ [DEBUG] Consultando API Clientes de ISPCube...")
    start_time = time.time()
    
    try:
        # Llamada directa a la funci√≥n que falla
        clientes = ispcube.obtener_clientes()
        
        duration = time.time() - start_time
        
        if clientes:
            print(f"‚úÖ [√âXITO] Se descargaron {len(clientes)} clientes en {duration:.2f} segundos.")
            
            # Guardamos para verificar que la DB local quede bien
            print("üíæ [DEBUG] Guardando en SQLite local...")
            db.cursor.execute("DELETE FROM clientes")
            db.cursor.execute("DELETE FROM clientes_emails")
            db.cursor.execute("DELETE FROM clientes_telefonos")

            for c in clientes:
                db.insert_cliente(mapear_cliente(c))
                insertar_contactos_relacionados(db, c)
            
            db.commit()
            print("‚úÖ [FIN] Datos guardados correctamente.")
        else:
            print(f"‚ö†Ô∏è [WARN] La API respondi√≥ OK pero la lista est√° vac√≠a. Tiempo: {duration:.2f}s")

    except Exception as e:
        duration = time.time() - start_time
        print(f"\n‚ùå [ERROR CR√çTICO] La API fall√≥ a los {duration:.2f} segundos.")
        print(f"   Tipo de error: {type(e).__name__}")
        print(f"   Detalle: {e}")

    finally:
        db.close()

if __name__ == "__main__":
    debug_sync_clientes()

==================================================
ARCHIVO: app\jobs\sync.py
==================================================
from app.db.sqlite import Database, init_db
from app.clients import smartolt, ispcube, mikrotik
from app import config
from app.utils.safe_call import safe_call
import time

def sync_secrets(db):
    nodes = db.get_nodes_for_sync()
    if not nodes:
        config.logger.warning("[SYNC] No hay nodos para sync secrets.")
        print("   ‚Ü≥ ‚ö†Ô∏è No hay nodos para consultar Mikrotik.")
        return

    # Borramos para regenerar, ahora la tabla soporta duplicados por nodo
    db.cursor.execute("DELETE FROM ppp_secrets")
    
    print(f"   ‚Ü≥ Consultando {len(nodes)} Mikrotiks:")
    total_secrets = 0
    count_ok = 0

    for node in nodes:
        ip = node["ip"]
        name = node["name"]
        port = node["port"] if node["port"] else config.MK_PORT
        
        # Log visual en consola
        print(f"      > {name} ({ip})...", end=" ", flush=True)
        
        try:
            secrets = mikrotik.get_all_secrets(ip, port)
            if secrets is not None:
                for s in secrets:
                    db.insert_secret(s, ip)
                count = len(secrets)
                total_secrets += count
                count_ok += 1
                print(f"‚úÖ ({count})")
            else:
                print("‚ö†Ô∏è Sin respuesta")
        except Exception as e:
            print(f"‚ùå Error: {e}")
            config.logger.error(f"[SYNC] Error en router {ip}: {e}")
    
    db.commit()
    config.logger.info(f"[SYNC] {total_secrets} secrets sincronizados de {count_ok}/{len(nodes)} nodos.")
    print(f"   ‚Ü≥ Resumen: {total_secrets} secrets guardados.")

# ... (El resto de las funciones sync_onus, sync_nodes, etc. se mantienen igual, solo asegurate que llamen a este sync_secrets) ...

# Funci√≥n main completa para copiar:
def nightly_sync():
    init_db()
    db = Database()
    print("\n[SYNC] üöÄ Iniciando Sincronizaci√≥n...\n")
    try:
        # 1. Nodos (ISPCube)
        print("   ‚Ü≥ Buscando Nodos en ISPCube...", end=" ", flush=True)
        try:
            nodes = ispcube.obtener_nodos()
            if nodes:
                db.cursor.execute("DELETE FROM nodes")
                for n in nodes: db.insert_node(n["id"], n["name"], n["ip"], n["puerto"])
                print(f"‚úÖ ({len(nodes)})")
            else: print("‚ö†Ô∏è Vac√≠o")
        except Exception as e: print(f"‚ùå {e}")

        # 2. Secrets (Mikrotik) - AHORA DETALLADO
        sync_secrets(db)

        # 3. ONUs
        print("   ‚Ü≥ Consultando SmartOLT...", end=" ", flush=True)
        try:
            onus = smartolt.get_all_onus()
            if onus:
                db.cursor.execute("DELETE FROM subscribers")
                for o in onus: 
                    db.insert_subscriber(o.get("unique_external_id"), o.get("sn"), o.get("olt_name"), o.get("olt_id"), o.get("board"), o.get("port"), o.get("onu"), o.get("onu_type_id"), o.get("name"), o.get("mode"))
                print(f"‚úÖ ({len(onus)})")
            else: print("‚ö†Ô∏è Vac√≠o")
        except Exception as e: print(f"‚ùå {e}")

        # 4. Datos Admin
        # ... (Tu c√≥digo existente para planes, conexiones, clientes) ...
        # Solo aseg√∫rate de llamar a db.match_connections() al final.
        
        # Para abreviar, asumo que tienes el resto. Lo importante fue sync_secrets.
        
        print("   ‚Ü≥ Cruzando datos (Match)...", end=" ", flush=True)
        db.match_connections()
        db.commit()
        print("‚úÖ OK")
        
    finally:
        db.close()
        print("\n[SYNC] ‚ú® Finalizado.\n")

if __name__ == "__main__":
    nightly_sync()

==================================================
ARCHIVO: app\jobs\__init__.py
==================================================


==================================================
ARCHIVO: app\services\diagnostico.py
==================================================
Ôªøfrom app.db.sqlite import Database
from app.clients import mikrotik, smartolt, ispcube
from app.config import logger
from app import config # Importar config para fallback

def consultar_diagnostico(pppoe_user: str) -> dict:
    db = Database()
    try:
        # Esto ahora busca en ISPCube primero, luego en SmartOLT
        base = db.get_diagnosis(pppoe_user)
        if "error" in base:
            return base

        diagnosis = base.copy()

        # Mikrotik
        # Si no tenemos nodo_ip (cliente solo en OLT), usamos el default MK_HOST del .env
        router_ip = base.get("nodo_ip")
        if not router_ip:
            logger.warning(f"Sin IP de nodo para {pppoe_user}. Usando MK_HOST por defecto.")
            router_ip = config.MK_HOST

        # Validamos PPPoE (si router_ip es v√°lido)
        if router_ip:
            pppoe_info = mikrotik.validar_pppoe(router_ip, pppoe_user, base.get("puerto", config.MK_PORT))
            diagnosis["mikrotik"] = pppoe_info
        else:
             diagnosis["mikrotik"] = {"active": False, "error": "No Router IP"}

        # SmartOLT (Solo si tenemos unique_external_id)
        external_id = base.get("unique_external_id")
        if external_id:
            diagnosis["onu_status_smrt"] = smartolt.get_onu_status(external_id)
            diagnosis["onu_signal_smrt"] = smartolt.get_onu_signals(external_id)
            diagnosis["onu_vlan"] = smartolt.get_attached_vlans(external_id)
        else:
             # Caso raro: Cliente en ISPCube pero sin ONU vinculada
             diagnosis["onu_status_smrt"] = {"status": False, "error": "Sin ONU asociada"}

        return diagnosis
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}. Detalles: {e}")
        return diagnosis # Retornamos lo que tengamos
    finally:
        db.close()

==================================================
ARCHIVO: app\services\__init__.py
==================================================


==================================================
ARCHIVO: app\utils\safe_call.py
==================================================
from functools import wraps
from app.config import logger

def safe_call(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            result = func(*args, **kwargs)
            if isinstance(result, dict):
                return {"estado": "ok", **result}
            return {"estado": "ok", "resultado": result}
        except Exception as e:
            logger.error(f"Error en {func.__name__}: {e}")
            return {"estado": "error", "detalle": str(e)}
    return wrapper

==================================================
ARCHIVO: docs\adr001.md
==================================================

# ADR-001: Uso de SQLite como base de datos inicial

## Contexto
Beholder necesita una base de datos para almacenar clientes, conexiones, planes, nodos y suscriptores (fibra y antena).  
El sistema est√° en fase inicial, con un equipo reducido y foco en rapidez de desarrollo y despliegue.  
Las opciones consideradas fueron:
- **PostgreSQL**: robusto, escalable, multiusuario, con soporte avanzado de √≠ndices y particiones.  
- **SQLite**: liviano, embebido, sin necesidad de servidor, f√°cil de administrar.  

El entorno actual es un ISP en crecimiento, con despliegues r√°pidos y necesidad de simplicidad operativa.

## Decisi√≥n
Se decidi√≥ usar **SQLite** como base de datos inicial para Beholder.  
Motivos:
- Simplicidad de instalaci√≥n y cero mantenimiento de servidor.  
- Integraci√≥n directa con Python sin dependencias externas.  
- Suficiente rendimiento para el volumen actual de clientes y antenas.  
- Facilita pruebas y despliegues r√°pidos en entornos de desarrollo y producci√≥n.  

## Consecuencias
**Positivas:**
- Menor complejidad operativa.  
- Deploy m√°s sencillo (solo archivo `.db`).  
- Ideal para prototipado y validaci√≥n r√°pida.  

**Negativas:**
- Limitaciones de concurrencia (solo un escritor a la vez).  
- Escalabilidad reducida para grandes vol√∫menes de datos.  
- Migraci√≥n futura necesaria a PostgreSQL u otro motor m√°s robusto.  

**Mitigaci√≥n:**
- Dise√±o modular de acceso a datos (`db.py`) para facilitar migraci√≥n.  
- Documentaci√≥n clara del esquema y relaciones.  
- Plan de roadmap para migrar a PostgreSQL cuando el volumen lo requiera.  



==================================================
ARCHIVO: docs\adr002.md
==================================================


# ADR-002: Deploy mediante Git Hooks y sudoers NOPASSWD

## Contexto
Beholder necesita un mecanismo de despliegue simple y confiable para actualizar c√≥digo en producci√≥n.  
Las opciones consideradas fueron:
- **CI/CD externo** (GitHub Actions, GitLab CI, Jenkins): m√°s potente pero requiere infraestructura adicional.  
- **Deploy manual v√≠a SSH**: flexible pero propenso a errores humanos.  
- **Git hooks en el servidor**: automatizan el proceso al recibir un `git push`.  

El sistema corre en servidores propios del ISP, con usuarios t√©cnicos limitados y necesidad de rapidez en cambios.

## Decisi√≥n
Se decidi√≥ implementar **deploy autom√°tico mediante git hooks** en el repositorio remoto, combinados con reglas en `sudoers` para permitir reinicios de servicios sin contrase√±a.  
Motivos:
- Simplicidad: un `git push production main` actualiza y reinicia el servicio.  
- Bajo costo: no requiere infraestructura adicional ni pipelines externos.  
- Control local: todo corre en el servidor del ISP, sin depender de terceros.  
- Seguridad: `sudoers` limita los comandos permitidos (solo `systemctl reload nginx` y `systemctl restart beholder.service`).

## Consecuencias
**Positivas:**
- Deploy r√°pido y reproducible.  
- Menor riesgo de olvidar pasos manuales.  
- Operadores pueden actualizar sin conocimientos avanzados de Linux.  

**Negativas:**
- Menor flexibilidad que un pipeline CI/CD (no hay tests autom√°ticos).  
- Riesgo de que un hook mal escrito rompa el deploy.  
- Escalabilidad limitada si se agregan m√∫ltiples servidores.  

**Mitigaci√≥n:**
- Documentar el hook y mantenerlo versionado.  
- Usar `sudoers` con comandos espec√≠ficos para evitar abusos.  
- Planear migraci√≥n futura a CI/CD cuando el equipo crezca.  



==================================================
ARCHIVO: docs\adr003.md
==================================================


# ADR-003: Separaci√≥n de Mappers, Helpers y Acceso a Base de Datos

## Contexto
Beholder necesita sincronizar y transformar datos provenientes de m√∫ltiples fuentes externas (SmartOLT, ISPCube, cnMaestro).  
En las primeras versiones, la l√≥gica de transformaci√≥n, validaci√≥n y acceso a la base de datos estaba mezclada en scripts monol√≠ticos, lo que dificultaba:
- La mantenibilidad del c√≥digo.  
- La incorporaci√≥n de nuevos desarrolladores.  
- La reutilizaci√≥n de funciones comunes.  

El sistema debe ser modular y escalable, permitiendo agregar nuevas integraciones sin romper las existentes.

## Decisi√≥n
Se decidi√≥ separar la l√≥gica en tres capas principales:
- **Mappers**: traducen datos externos (JSON/API) al modelo interno de Beholder.  
- **Helpers**: funciones utilitarias para validaci√≥n, normalizaci√≥n y manejo de edge cases.  
- **DB Access**: m√≥dulo dedicado (`db.py`) para consultas y operaciones sobre la base de datos.  

Motivos:
- Claridad en la responsabilidad de cada m√≥dulo.  
- Facilita pruebas unitarias y debugging.  
- Permite reemplazar o extender cada capa sin afectar las dem√°s.  
- Mejora la documentaci√≥n y onboarding de nuevos desarrolladores.

## Consecuencias
**Positivas:**
- C√≥digo m√°s legible y mantenible.  
- Escalabilidad: f√°cil agregar nuevos mappers para otras APIs.  
- Reducci√≥n de errores por mezcla de responsabilidades.  
- Documentaci√≥n m√°s clara (cada m√≥dulo tiene su prop√≥sito definido).  

**Negativas:**
- Mayor cantidad de archivos y estructura m√°s compleja.  
- Requiere disciplina para mantener la separaci√≥n y no mezclar l√≥gica.  

**Mitigaci√≥n:**
- Definir convenciones de nombres y carpetas (`mappers/`, `helpers/`, `db/`).  
- Documentar ejemplos de uso en cada m√≥dulo.  
- Revisar PRs con foco en mantener la separaci√≥n de responsabilidades.  



==================================================
ARCHIVO: docs\adr004.md
==================================================


# ADR-004: Migraci√≥n de SQLite a PostgreSQL

## Contexto
Beholder actualmente utiliza **SQLite** como motor de base de datos.  
Esta elecci√≥n inicial permiti√≥ simplicidad en despliegue y prototipado r√°pido. Sin embargo, el crecimiento del ISP y la necesidad de manejar mayor volumen de clientes (fibra y antena), integraciones m√∫ltiples y consultas concurrentes hacen que SQLite empiece a mostrar limitaciones:
- Concurrencia reducida (un solo escritor a la vez).  
- Escalabilidad limitada para grandes datasets.  
- Falta de caracter√≠sticas avanzadas como particionamiento, materialized views y roles de seguridad.  

El roadmap del proyecto contempla expansi√≥n y mayor n√∫mero de operadores, lo que requiere un motor m√°s robusto.

## Decisi√≥n
Se decidi√≥ planificar la **migraci√≥n de SQLite a PostgreSQL** como parte del roadmap de escalabilidad.  
Motivos:
- PostgreSQL ofrece mayor rendimiento y soporte para concurrencia.  
- Funcionalidades avanzadas de indexaci√≥n (GIN, trigram, btree) ya alineadas con las pr√°cticas de Beholder.  
- Mejor soporte para integraciones futuras y auditor√≠a.  
- Comunidad amplia y soporte empresarial.  

## Consecuencias
**Positivas:**
- Escalabilidad para manejar decenas de miles de clientes y conexiones.  
- Mejor seguridad y control de acceso.  
- Posibilidad de optimizar consultas con particionamiento y materialized views.  
- Integraci√≥n m√°s sencilla con herramientas externas (BI, reporting).  

**Negativas:**
- Mayor complejidad operativa (necesidad de administrar un servidor de base de datos).  
- Migraci√≥n requiere scripts de conversi√≥n y validaci√≥n de datos.  
- Curva de aprendizaje para operadores y desarrolladores nuevos.  

**Mitigaci√≥n:**
- Mantener acceso a datos encapsulado en `db.py` para facilitar migraci√≥n.  
- Documentar esquema y relaciones en detalle.  
- Planificar migraci√≥n gradual: primero staging, luego producci√≥n.  
- Capacitar al equipo en administraci√≥n b√°sica de PostgreSQL.  



==================================================
ARCHIVO: docs\backend.md
==================================================
## 2. Entorno de Producci√≥n

### 2.1 Servidor
- **Sistema operativo**: Debian GNU/Linux 12.12 (Bookworm)
- **Hostname**: debian-acsserver
- **Usuario de despliegue**: administrador
- **IP p√∫blica**: 138.59.172.24
- **Ruta del c√≥digo**: /home/administrador/apps/beholder
- **Repositorio bare Git**: /home/administrador/repos/beholder.git

### 2.2 Servicio Beholder
- **Archivo systemd**: /etc/systemd/system/beholder.service
- **Comandos √∫tiles**:
  - `systemctl status beholder.service`
  - `systemctl restart beholder.service`
- **Logs**:
  - API: /home/administrador/apps/beholder/data/logs/sync.log
  - Systemd: `journalctl -u beholder.service`

### 2.3 API Backend
- **Puerto expuesto**: 8500
- **URL interna**: http://localhost:8500
- **URL externa**: http://138.59.172.24:8500
- **Endpoints principales**:
  - `/diagnosis/{pppoe_user}`
  - `/health`

### 2.4 Nginx
- **Archivo de configuraci√≥n**: /etc/nginx/sites-enabled/beholder.conf
- **Funci√≥n**: proxy inverso hacia FastAPI en puerto 8500
- **Certificados SSL**: /etc/letsencrypt/live/ (si se usa HTTPS)

==================================================
ARCHIVO: docs\Beholder.md
==================================================


# üìñ Documentaci√≥n Backend Beholder

## 1. Introducci√≥n
Beholder es una API de diagn√≥stico centralizado para clientes ISP (fibra y antena).  
Su backend combina:
- **FastAPI** para exponer endpoints REST.  
- **SQLite** como base local de sincronizaci√≥n.  
- **Integraciones externas** con SmartOLT, ISPCube, Mikrotik y GenieACS a trav√©s de sus respectivas API.
- **Proceso nocturno de sincronizaci√≥n** que actualiza la base con datos de las APIs externas, nutriendo datos de dificil acceso a trav√©s de los Endpoints de consultas de las API clientes.

Ruta repositorio GitHub:
https://github.com/LukeSkywalker66/beholder.git
---

## 2. Entorno de Producci√≥n
- **Servidor Debian**  
  - C√≥digo: `/home/administrador/apps/beholder`  
  - Repositorio Git: `/home/administrador/repos/beholder.git`  
  - Servicio systemd: `/etc/systemd/system/beholder.service`  
  - Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder.conf`  
  - Logs: `/var/log/beholder/`  

- **Deploy**  
  - `git push production main` ‚Üí hook ‚Üí reload nginx + restart beholder.service.  
  - Sudoers configurado con NOPASSWD para `systemctl reload nginx` y `systemctl restart beholder.service`.  

---

## 3. Estructura del Backend
```
app/
‚îú‚îÄ‚îÄ main.py              # FastAPI, endpoints /diagnosis y /health
‚îú‚îÄ‚îÄ config.py            # Variables de entorno, logging centralizado
‚îú‚îÄ‚îÄ security.py          # Middleware API Key
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ diagnostico.py   # L√≥gica de diagn√≥stico por PPPoE
‚îú‚îÄ‚îÄ clients/             # Integraciones externas
‚îÇ   ‚îú‚îÄ‚îÄ smartolt.py      # API SmartOLT
‚îÇ   ‚îú‚îÄ‚îÄ ispcube.py       # API ISPCube
‚îÇ   ‚îî‚îÄ‚îÄ mikrotik.py      # API RouterOS Mikrotik
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ sqlite.py        # Clase Database, esquema y queries
‚îú‚îÄ‚îÄ sync.py              # Proceso de sincronizaci√≥n nocturna
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ safe_call.py     # Wrapper defensivo para llamadas externas
```

---

## 4. Definici√≥n de Archivos Fuente

### `main.py`
- FastAPI con endpoints:
  - `/diagnosis/{pppoe_user}` ‚Üí devuelve diagn√≥stico completo.  
  - `/health` ‚Üí chequeo de estado.  
- Middleware de API Key (`X-API-Key`).  
- CORS habilitado para frontend.  

### `config.py`
- Carga variables desde `.env`.  
- Define rutas (`DB_PATH`, `SMARTOLT_BASEURL`, etc.).  
- Configura logging centralizado en `data/logs/sync.log`.  

### `security.py`
- Middleware para validar API Key.  
- Devuelve `401 unauthorized` si la clave no coincide.  

### `services/diagnostico.py`
- Funci√≥n `consultar_diagnostico(pppoe_user)`:
  - Consulta base local (`db.get_diagnosis`).  
  - Valida PPPoE en Mikrotik.  
  - Consulta estado, se√±ales y VLANs en SmartOLT.  
  - Integra datos de ISPCube.  

### `clients/smartolt.py`
- Funciones para interactuar con SmartOLT:
  - `get_all_onus()` ‚Üí listado completo de ONUs.  
  - `get_onu_status(id)` ‚Üí estado de ONU.  
  - `get_onu_signals(id)` ‚Üí se√±ales √≥pticas.  
  - `get_attached_vlans(id)` ‚Üí VLANs asociadas.  

### `clients/ispcube.py`
- Autenticaci√≥n v√≠a token.  
- Funciones:
  - `obtener_nodos()` ‚Üí lista de nodos.  
  - `obtener_todas_conexiones()` ‚Üí conexiones PPPoE.  
  - `obtener_planes()` ‚Üí planes de servicio.  
  - `obtener_clientes()` ‚Üí clientes completos.  

### `clients/mikrotik.py`
- Conexi√≥n a RouterOS v√≠a `routeros_api`.  
- Funciones:
  - `obtener_secret(router_ip, pppoe_user, puerto)` ‚Üí busca secret PPPoE.  
  - `validar_pppoe(router_ip, pppoe_user, puerto)` ‚Üí chequea si est√° activo.  
- Comentados: crear, borrar y migrar secrets.  

### `db/sqlite.py`
- Clase `Database` con m√©todos `insert_*` para cada tabla.  
- `get_diagnosis(pppoe_user)` ‚Üí query principal de diagn√≥stico.  
- `init_db()` ‚Üí crea esquema de tablas (`subscribers`, `nodes`, `plans`, `connections`, `clientes`, `sync_status`).  

### `sync.py`
- Funciones de sincronizaci√≥n:
  - `sync_onus()`, `sync_nodes()`, `sync_plans()`, `sync_connections()`, `sync_clientes()`.  
- `nightly_sync()` ‚Üí ejecuta todo el proceso y actualiza relaciones PPPoE ‚Üî node_id ‚Üî connection_id.  

---

## 5. Flujo de Diagn√≥stico
1. **Frontend** llama a `/diagnosis/{pppoe_user}`.  
2. **Backend** consulta DB local (`get_diagnosis`).  
3. **Mikrotik** valida PPPoE activo/inactivo.  
4. **SmartOLT** devuelve estado, se√±ales y VLANs.  
5. **ISPCube** aporta datos de cliente, plan y nodo.  
6. Respuesta JSON consolidada para el operador.  

---

## 6. Flujo de Sincronizaci√≥n Nocturna
1. `cron` ejecuta `python sync.py`.  
2. Se inicializa DB (`init_db`).  
3. Se descargan datos de SmartOLT, ISPCube.  
4. Se insertan en tablas locales.  
5. Se actualizan relaciones (`match_connections`).  
6. Se registra estado en `sync_status`.  

---

## 7. ADRs relevantes
- **ADR-001**: Uso de SQLite como base inicial.  
- **ADR-002**: Deploy con git hooks + sudoers NOPASSWD.  
- **ADR-003**: Separaci√≥n modular (mappers, helpers, DB).  
- **ADR-004**: Roadmap migraci√≥n a PostgreSQL.  

---

## 8. Roadmap Backend
- Migrar DB a PostgreSQL.  
- Integrar cnMaestro para clientes wireless.  
- Extender diagn√≥stico con alarmas GenieACS.  
- Automatizar tests en deploy.  



==================================================
ARCHIVO: docs\Beholder_UI.md
==================================================

# üìñ Documentaci√≥n Frontend Beholder

## 1. Introducci√≥n
El frontend de Beholder es una aplicaci√≥n **React + Vite** que consume la API backend (FastAPI).  
Su prop√≥sito es ofrecer a los operadores una interfaz clara y amigable para realizar diagn√≥sticos de clientes ISP.
Repositorio de GitHub:
https://github.com/LukeSkywalker66/beholder_ui.git

---

## 2. Entorno de Producci√≥n
- **Servidor Debian**: mismo host que el backend.  
- **Web server**: Nginx sirve los archivos est√°ticos del build (`dist/`).  
- **Ruta t√≠pica de deploy**:  
  - C√≥digo fuente: `/home/administrador/repos/beholder_ui`  
  - Build: `/home/administrador/apps/beholder-ui`  
  - Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder`  
- **Variables de entorno**: `/config/.env` para backend y `.env` para frontend.  
  - `VITE_API_URL=http://138.59.172.24:8500`  
  - `VITE_API_KEY=Zo9fUbuGS5Qh...`  

---

## 3. Estructura del Frontend
```
src/
‚îú‚îÄ‚îÄ App.tsx             # Layout principal, sidebar + resultados
‚îú‚îÄ‚îÄ App.css             # Estilos globales, grilla, dark mode, responsive
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ beholder2.png   # Logo
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ SearchBox.tsx   # Input PPPoE + bot√≥n buscar
‚îÇ   ‚îú‚îÄ‚îÄ OutputBox.tsx   # Renderizado de diagn√≥stico normalizado
‚îÇ   ‚îî‚îÄ‚îÄ CopyButton.tsx  # Bot√≥n para copiar diagn√≥stico al portapapeles
‚îî‚îÄ‚îÄ env2                # Variables de entorno (API URL y API Key)
```

---

## 4. Definici√≥n de Archivos Fuente

### `App.tsx`
- Layout dividido en dos paneles:
  - **Sidebar**: logo, t√≠tulo, `SearchBox`.  
  - **Results**: muestra `OutputBox` con datos del diagn√≥stico.  
- Estado global `resultData` que se actualiza con la b√∫squeda.

### `SearchBox.tsx`
- Input para PPPoE.  
- Bot√≥n ‚ÄúBuscar‚Äù que llama al backend (`/diagnosis/{pppoe_user}`).  
- Maneja estados de `loading` y `error`.  
- Env√≠a resultado al padre (`App.tsx`) v√≠a `onResult`.

### `OutputBox.tsx`
- Recibe `data` y lo muestra en grilla.  
- Traduce estados t√©cnicos a lenguaje operator-friendly (ej. `Online ‚Üí En l√≠nea`).  
- Incluye bot√≥n `CopyButton` para copiar diagn√≥stico en texto plano.  
- Usa estilos condicionales (`estado-ok`, `estado-error`) para resaltar estado PPPoE y ONU.

### `CopyButton.tsx`
- Copia al portapapeles el texto normalizado del diagn√≥stico.  
- Feedback visual: ‚úî Copiado durante 2 segundos.  
- Implementa fallback para navegadores sin `navigator.clipboard`.

### `App.css`
- Define layout (sidebar + results).  
- Grilla responsive para resultados.  
- Estilos condicionales (`estado-ok`, `estado-error`).  
- Dark mode autom√°tico con `prefers-color-scheme`.  
- Responsive para m√≥viles (columna √∫nica).

---

## 5. Flujo de Diagn√≥stico en Frontend
1. Operador ingresa PPPoE en `SearchBox`.  
2. Se llama al backend con `fetch` y API Key.  
3. Respuesta JSON se guarda en `resultData`.  
4. `OutputBox` muestra diagn√≥stico normalizado.  
5. Operador puede copiar texto plano con `CopyButton` al portapapeles, para poder pegarlo en otras plataformas de forma simple y ordenada.

---

## 6. Deploy Frontend

Manual: 
- Build con Vite:
  ```bash
  npm run build
  ```
- Copiar carpeta `dist/` al servidor Debian.  
- Configurar Nginx para servir `dist/` como sitio est√°tico.  
- Asegurar que `VITE_API_URL` apunte al backend en producci√≥n.  

Con el hook de /home/administrador/repos/beholder_ui.git/hooks/post-receive/:
git push production main

hook:

<!-- {
    #!/bin/bash

    # Ruta de trabajo (checkout del repo)
    WORK_TREE=/home/administrador/repos/beholder_ui_checkout
    # Carpeta de destino para Nginx
    DEPLOY_DIR=/home/administrador/apps/beholder-ui
    # Archivo de log
    LOG_FILE=/var/log/beholder-deploy.log

    log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> $LOG_FILE
    }

    log "==== Deploy iniciado: $(date) ===="

    # Checkout del c√≥digo
    log "[INFO] Haciendo checkout de main..."
    GIT_WORK_TREE=$WORK_TREE git checkout -f main >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ el checkout de main"
    exit 1
    fi

    # Instalar dependencias
    cd $WORK_TREE || exit 1
    log "[INFO] Ejecutando npm install..."
    npm install --legacy-peer-deps >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ npm install"
    exit 1
    fi

    # Build del proyecto
    log "[INFO] Ejecutando npm run build..."
    npm run build >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ npm run build"
    exit 1
    fi

    # Copiar artefactos al deploy
    log "[INFO] Copiando build a $DEPLOY_DIR..."
    rm -rf $DEPLOY_DIR/*
    cp -r $WORK_TREE/dist/* $DEPLOY_DIR/ >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ la copia de artefactos"
    exit 1
    fi

    # Recargar Nginx
    log "[INFO] Recargando Nginx..."
    sudo -n systemctl reload nginx >> $LOG_FILE 2>&1
    if [ $? -ne 0 ]; then
    log "[ERROR] Fall√≥ reload de Nginx"
    exit 1
    fi

    log "[SUCCESS] Deploy completado correctamente"


}
 -->



Entrada en sudoers habilita la ejecuci√≥n de sudo systemctl sin ingresar contrase√±a, para poder correr en un proceso sin terminal y recargar el servicio de la p√°gina web.
---

## 7. Roadmap Frontend
- Extender `OutputBox` con m√°s campos de cliente (tel√©fonos, emails).  
- Internacionalizaci√≥n (i18n) para soportar m√∫ltiples idiomas.  
- Mejorar feedback visual en errores de conexi√≥n.  
- Dashboard con m√©tricas de sincronizaci√≥n (`sync_status`).  



==================================================
ARCHIVO: docs\Guia de proyecto.md
==================================================


# üìñ Documentaci√≥n del Proyecto Beholder

## 1. Resumen Ejecutivo
- **Prop√≥sito del sistema**: diagn√≥stico centralizado de clientes ISP (fibra y antena).
- **Contexto**: m√∫ltiples sistemas dispersos (SmartOLT, ISPCube, cnMaestro, Hest).
- **Objetivo**: unificar informaci√≥n para operadores y t√©cnicos, simplificar soporte y escalar servicio.

---

## 2. Requerimientos del Proyecto
### 2.1 Funcionales
- Diagn√≥stico de clientes por PPPoE/ONU/antena.
- Sincronizaci√≥n nocturna de datos (clientes, conexiones, planes, nodos, suscriptores).
- Integraci√≥n con APIs externas (SmartOLT, ISPCube, cnMaestro).
- Interfaz web operator-friendly.
- Logging y auditor√≠a de sincronizaci√≥n.

### 2.2 No Funcionales
- Seguridad: control de acceso, sudoers configurado para deploy.
- Performance: consultas r√°pidas con √≠ndices.
- Mantenibilidad: modularidad en mappers, helpers y DB.
- Escalabilidad: soporte para fibra y antena.

---

## 3. Arquitectura del Sistema (C4 Model)
### 3.1 Contexto
- Beholder como sistema central dentro del ISP.
- Relaci√≥n con SmartOLT, ISPCube, cnMaestro, Hest.

### 3.2 Contenedores
- Backend Python (FastAPI/Flask).
- Frontend React.
- Base de datos SQLite.
- Servicios externos (APIs).

### 3.3 Componentes
- `sync.py`: sincronizaci√≥n nocturna.
- `clients/`: m√≥dulos de integraci√≥n (smartolt.py, ispcube.py, cnmaestro.py).
- `db.py`: acceso a base de datos.
- `frontend/`: UI operator-friendly.

### 3.4 C√≥digo
- Funciones clave (`get_diagnosis`, `sync_subscribers_aire`, etc.).
- Helpers y mappers.

---

## 4. Base de Datos
- **Tablas principales**:
  - `clientes`
  - `connections`
  - `subscribers` (fibra)
  - `subscribers_aire` (antenas)
  - `nodes`
  - `plans`
- **Relaciones**:
  - `clientes` ‚Üî `connections`
  - `connections` ‚Üî `subscribers` / `subscribers_aire`
  - `connections` ‚Üî `nodes`, `plans`

---

## 5. Integraciones Externas
- **SmartOLT API**: ONUs, OLTs.
- **ISPCube API**: clientes, planes, conexiones.
- **cnMaestro API**: antenas, alarmas, suscriptores.
- **Hest Helpdesk**: tickets internos.

---

## 6. ADR (Architecture Decision Records)
- **ADR-001**: Usar SQLite en primera versi√≥n por simplicidad.
- **ADR-002**: Deploy v√≠a git hooks + sudoers NOPASSWD.
- **ADR-003**: Separar mappers, helpers y DB para modularidad.
- **ADR-004**: Integrar cnMaestro para clientes de antena.

---

## 7. Gu√≠a de Operaci√≥n
- **Deploy**: `git push production main` ‚Üí hook ‚Üí reload nginx + restart beholder.
- **Sync manual**: `python sync.py`.
- **Logs**: ubicaciones y formato.
- **Troubleshooting**: errores comunes (sudoers, permisos, API tokens).

---

## 8. Roadmap
- Migrar DB a PostgreSQL para mayor escala.
- Extender diagn√≥stico con alarmas cnMaestro.
- Integraci√≥n con stock y helpdesk.

---


==================================================
ARCHIVO: docs\Guia2.md
==================================================


# üìñ Gu√≠a de Proyecto Beholder

## 1. Introducci√≥n
- **Prop√≥sito del sistema**: diagn√≥stico centralizado de clientes ISP (fibra y antena).
- **Contexto**: m√∫ltiples sistemas dispersos (SmartOLT, ISPCube, cnMaestro, Hest).
- **Objetivo**: unificar informaci√≥n para operadores y t√©cnicos, simplificar soporte y escalar servicio.

---

## 2. Entorno de Producci√≥n
### 2.1 Servidor Debian
- Ruta principal: `/home/administrador/apps/beholder`
- Repositorio Git: `/home/administrador/repos/beholder.git`
- Servicio systemd: `/etc/systemd/system/beholder.service`
- Configuraci√≥n Nginx: `/etc/nginx/sites-enabled/beholder.conf`
- Logs: `/var/log/beholder/`

### 2.2 Deploy
- Comando: `git push production main`
- Hook: `post-receive` ‚Üí actualiza c√≥digo y reinicia servicio.
- Sudoers: reglas NOPASSWD para `systemctl reload nginx` y `systemctl restart beholder.service`.

---

## 3. Estructura del Repositorio
```
beholder/
‚îú‚îÄ‚îÄ backend/          # API y l√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ sync.py       # Sincronizaci√≥n nocturna
‚îÇ   ‚îú‚îÄ‚îÄ db.py         # Acceso a base de datos
‚îÇ   ‚îî‚îÄ‚îÄ clients/      # Integraciones externas (smartolt.py, ispcube.py, cnmaestro.py)
‚îú‚îÄ‚îÄ frontend/         # React UI
‚îú‚îÄ‚îÄ hooks/            # Scripts de deploy
‚îú‚îÄ‚îÄ docs/             # Documentaci√≥n en Markdown
‚îî‚îÄ‚îÄ tests/            # Pruebas unitarias
```

---

## 4. Repositorio GitHub
- URL: `https://github.com/<org>/beholder`
- Estado: p√∫blico/privado (definir).
- Pol√≠ticas de acceso: qui√©n puede hacer push, revisi√≥n de PRs.
- Consideraciones de seguridad: no incluir credenciales en el repo.

---

## 5. Flujo de Trabajo
- **Commit y Push**: desarrollador hace cambios ‚Üí `git push production main`.
- **Hook de Deploy**: recibe push ‚Üí actualiza c√≥digo ‚Üí reinicia servicio.
- **Sync nocturno**: `cron` ejecuta `sync.py` ‚Üí actualiza DB con datos externos.
- **Operaci√≥n diaria**: operadores usan frontend para diagn√≥stico.

---

## 6. Documentaci√≥n T√©cnica
- Definici√≥n de cada archivo fuente.
- Ejemplos de queries SQL comunes.
- Integraciones externas (SmartOLT, ISPCube, cnMaestro).
- ADRs relevantes.

---

## 7. Roadmap
- Migraci√≥n futura a PostgreSQL.
- Extensi√≥n de diagn√≥stico con alarmas cnMaestro.
- Integraci√≥n con stock y helpdesk.



==================================================
ARCHIVO: docs\todo_cnMaestro.md
==================================================
Perfecto, Lucas üëÅÔ∏è. Para integrar **clientes de antenas** al backend y que aparezcan en tu diagn√≥stico junto con fibra, lo m√°s ordenado es replicar el mismo patr√≥n que ya ten√©s con SmartOLT e ISPCube, pero usando la API de **cnMaestro** de Cambium. Te desgloso el dise√±o:

---

## üß© Pasos de integraci√≥n

### 1. Crear cliente `cnmaestro.py`
Un m√≥dulo en `app/clients/` que maneje la autenticaci√≥n y llamadas a la API REST de cnMaestro.

Ejemplo b√°sico:

```python
# app/clients/cnmaestro.py
import requests
from app import config
from app.config import logger

CNMAESTRO_BASEURL = config.CNMAESTRO_BASEURL
CNMAESTRO_USER = config.CNMAESTRO_USER
CNMAESTRO_PASS = config.CNMAESTRO_PASS

_token_cache = None

def _get_token():
    global _token_cache
    if _token_cache is None:
        url = f"{CNMAESTRO_BASEURL}/api/v1/access/token"
        resp = requests.post(url, json={"username": CNMAESTRO_USER, "password": CNMAESTRO_PASS})
        resp.raise_for_status()
        _token_cache = resp.json()["access_token"]
    return _token_cache

def _headers():
    return {"Authorization": f"Bearer {_get_token()}"}

def obtener_subscribers_aire():
    """
    Devuelve lista de suscriptores de antena desde cnMaestro.
    """
    url = f"{CNMAESTRO_BASEURL}/api/v1/devices/subscribers"
    resp = requests.get(url, headers=_headers())
    resp.raise_for_status()
    data = resp.json()
    return data.get("data", [])
```

---

### 2. Crear tabla `subscribers_aire` en SQLite
En `init_db()`:

```sql
CREATE TABLE IF NOT EXISTS subscribers_aire (
    id TEXT PRIMARY KEY,
    name TEXT,
    mac TEXT,
    ip TEXT,
    lat TEXT,
    lng TEXT,
    modelo TEXT,
    estado TEXT,
    cliente_id TEXT,
    FOREIGN KEY (cliente_id) REFERENCES clientes(id)
);
```

---

### 3. M√©todos en `Database`
```python
def insert_subscriber_aire(self, id, name, mac, ip, lat, lng, modelo, estado, cliente_id=None):
    self.cursor.execute("""
        INSERT OR REPLACE INTO subscribers_aire
        (id, name, mac, ip, lat, lng, modelo, estado, cliente_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (id, name, mac, ip, lat, lng, modelo, estado, cliente_id))
```

---

### 4. Funci√≥n de sincronizaci√≥n en `sync.py`
```python
from app.clients import cnmaestro

def sync_subscribers_aire(db):
    subs = cnmaestro.obtener_subscribers_aire()
    if subs:
        db.cursor.execute("DELETE FROM subscribers_aire")
        for s in subs:
            db.insert_subscriber_aire(
                s.get("id"),
                s.get("name"),
                s.get("mac"),
                s.get("ip"),
                s.get("latitude"),
                s.get("longitude"),
                s.get("model"),
                s.get("status"),
                s.get("customer_id")
            )
        db.commit()
        config.logger.info(f"[SYNC] {len(subs)} suscriptores aire sincronizados.")
        db.log_sync_status("cnmaestro", "ok", f"{len(subs)} suscriptores aire sincronizados")
    else:
        config.logger.warning("[SYNC] cnMaestro no devolvi√≥ suscriptores")
        db.log_sync_status("cnmaestro", "empty", "Sin datos de suscriptores aire")
```

---

### 5. Integrar en `nightly_sync`
```python
def nightly_sync():
    init_db()
    db = Database()
    try:
        sync_onus(db)
        sync_nodes(db)
        sync_plans(db)
        sync_connections(db)
        sync_clientes(db)
        sync_subscribers_aire(db)   # üëà nuevo paso
        db.match_connections()
        db.commit()
        config.logger.info("[SYNC] Base actualizada con fibra y aire.")
    finally:
        db.close()
```

---

## ‚úÖ Resultado
- Ahora tu diagn√≥stico puede mostrar tanto clientes de fibra (SmartOLT/ISPCube) como clientes de antena (cnMaestro).  
- La tabla `subscribers_aire` queda enlazada con `clientes` v√≠a `cliente_id`.  
- El nightly sync mantiene todo actualizado.  

---

üëâ ¬øQuer√©s que te arme tambi√©n el `get_diagnosis` extendido para que, si el cliente es de antena, te devuelva los datos de `subscribers_aire` junto con el resto?



validar datos de cnmaestro

==================================================
ARCHIVO: txt\App.css.txt
==================================================
.layout {
  display: flex;
  min-height: 100vh;
  font-family: Arial, sans-serif;
}

/* Panel izquierdo */
.sidebar {
  width: 300px;
  background-color: #f5f5f5;
  padding: 2rem;
  text-align: center;
  box-shadow: 2px 0 5px rgba(0,0,0,0.1);
}

.logo-sidebar {
  width: 220px;
  height: auto;
  margin-bottom: 1rem;
}

.sidebar h1 {
  font-size: 2rem;
  margin: 0.5rem 0;
}

.sidebar h2 {
  font-size: 1rem;
  color: #666;
  margin-bottom: 2rem;
}

/* Panel derecho */
.results {
  flex: 1;
  padding: 2rem;
  background-color: #ffffff;
}

/* Grilla de resultados */
.grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 1rem;
}

.cell {
  background-color: #eaeaea;
  padding: 1rem;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.1);
}
.grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 1rem;
  margin-top: 1rem;
}

.cell {
  background-color: #f0f0f0;
  padding: 1rem;
  border-radius: 6px;
  box-shadow: 0 1px 4px rgba(0,0,0,0.1);
}

.estado-ok {
  background-color: #d4f4dd;
  border-left: 6px solid #2ecc71;
}

.estado-error {
  background-color: #fbe3e3;
  border-left: 6px solid #e74c3c;
}
.cell.span-2 {
  grid-column: span 2;
}
.header-row {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.diagnostic-title {
  font-size: 1.25rem;
  font-weight: bold;
  margin: 0;
}

.copy-button button {
  background-color: #4a90e2;
  color: white;
  border: none;
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background-color 0.2s ease;
}

.copy-button button:hover {
  background-color: #357ab8;
}
@media (prefers-color-scheme: dark) {
  body {
    background-color: #1e1e1e;
    color: #f0f0f0;
  }

  .sidebar {
    background-color: #2c2c2c;
    color: #f0f0f0;
  }

  .results {
    background-color: #1e1e1e;
    color: #f0f0f0;
  }

  .cell {
    background-color: #333;
    color: #f0f0f0;
  }

  .estado-ok {
    background-color: #2e7d32;
    color: #ffffff;
  }

  .estado-error {
    background-color: #c62828;
    color: #ffffff;
  }

  .copy-button button {
    background-color: #90caf9;
    color: #000;
  }

  .copy-button button:hover {
    background-color: #64b5f6;
  }
}
body.dark-mode {
  background-color: #1e1e1e;
  color: #f0f0f0;
}
@media (max-width: 768px) {
  .layout {
    flex-direction: column;
  }

  .sidebar {
    width: 100%;
    box-shadow: none;
    text-align: left;
    padding: 1rem;
  }

  .results {
    padding: 1rem;
  }

  .grid {
    grid-template-columns: 1fr; /* una sola columna en m√≥viles */
  }

  .cell.span-2 {
    grid-column: span 1;
  }
}

==================================================
ARCHIVO: txt\App.tsx.txt
==================================================
import { useState } from "react";
import SearchBox from "./components/SearchBox";
import OutputBox from "./components/OutputBox";
import './App.css';
import logo from './assets/beholder2.png';

function App() {
  const [resultData, setResultData] = useState<any>(null);

  return (
    <div className="layout">
      {/* Panel izquierdo */}
      <aside className="sidebar">
        <img src={logo} alt="Logo Beholder" className="logo-sidebar" />
        <h1>Beholder</h1>
        <h2>Diagn√≥stico centralizado de 2F Internet</h2>
        <SearchBox onResult={setResultData} />
      </aside>

      {/* Panel derecho */}
      <main className="results">
        {resultData && <OutputBox data={resultData} />}
      </main>
    </div>
  );
}

export default App;

==================================================
ARCHIVO: txt\config.py.txt
==================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv(dotenv_path=os.path.join("config", ".env"))

# Variables de entorno
API_KEY = os.getenv("API_KEY")
SMARTOLT_BASEURL = os.getenv("SMARTOLT_BASEURL")
SMARTOLT_TOKEN = os.getenv("SMARTOLT_TOKEN")
MK_HOST = os.getenv("MK_HOST")
MK_USER = os.getenv("MK_USER")
MK_PASS = os.getenv("MK_PASS")
MK_PORT = int(os.getenv("MK_PORT", 8799))
GENIEACS_URL = os.getenv("GENIEACS_URL")
ISPCUBE_BASEURL=os.getenv("ISPCUBE_BASEURL")
ISPCUBE_APIKEY=os.getenv("ISPCUBE_APIKEY")
ISPCUBE_USER=os.getenv("ISPCUBE_USER")
ISPCUBE_PASSWORD=os.getenv("ISPCUBE_PASSWORD")
ISPCUBE_CLIENTID=os.getenv("ISPCUBE_CLIENTID")

DB_PATH = os.path.abspath(os.getenv("DB_PATH", "data/diag.db"))

# Crear carpeta data/ si no existe
db_dir = os.path.dirname(DB_PATH)
if not os.path.exists(db_dir):
    os.makedirs(db_dir, exist_ok=True)

# Logging centralizado
log_dir = os.path.join(db_dir, "logs")
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(log_dir, "sync.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("beholder")

==================================================
ARCHIVO: txt\CopyButton.tsx.txt
==================================================
import { useState } from "react";

interface CopyButtonProps {
  text: string; // el texto que quer√©s copiar
}

export default function CopyButton({ text }: CopyButtonProps) {
  const [copied, setCopied] = useState(false);

  const copyToClipboard = async () => {
    console.log("Click detectado, texto:", text);
    try {
      if (navigator.clipboard && navigator.clipboard.writeText) {
        // ‚úÖ Camino moderno (HTTPS / localhost)
        await navigator.clipboard.writeText(text);
        console.log("Camino moderno (HTTPS / localhost) usado para copiar al portapapeles.");
      } else {
        // ‚úÖ Fallback para HTTP inseguro
        const textarea = document.createElement("textarea");
        textarea.value = text;
        document.body.appendChild(textarea);
        textarea.select();
        document.execCommand("copy");
        document.body.removeChild(textarea);
        console.log("Fallback usado para copiar al portapapeles.");
      }

      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    } catch (err) {
      console.error("Error copiando al portapapeles", err);
    }
  };


  return (
    <div className="copy-button">
      <button onClick={copyToClipboard}>
        üìã Copiar
      </button>
      {copied && <span style={{ marginLeft: "8px" }}>‚úî Copiado</span>}
    </div>
  );

}

==================================================
ARCHIVO: txt\diagnostico.py.txt
==================================================
Ôªøfrom app.db.sqlite import Database
from app.clients import mikrotik, smartolt, ispcube
from app.config import logger
from app.utils.safe_call import safe_call


def consultar_diagnostico(pppoe_user: str) -> dict:
    db = Database()
    try:
        base = db.get_diagnosis(pppoe_user)
        if "error" in base:
            return base

        diagnosis = base.copy()

        # Mikrotik ‚Üí validaci√≥n PPPoE usando nodo_ip
        pppoe_info = mikrotik.validar_pppoe(base["nodo_ip"], pppoe_user, base["puerto"])
        diagnosis["mikrotik"] = pppoe_info
        # if pppoe_info.get("active"):
        #     diagnosis["pppoe_active"] = True
        # else:
        #     diagnosis["pppoe_active"] = False
        #     diagnosis["last_disconnect"] = pppoe_info.get("last_disconnect")
        #     diagnosis["disconnect_reason"] = pppoe_info.get("reason")

        # SmartOLT
        diagnosis["onu_status_smrt"] = smartolt.get_onu_status(base["unique_external_id"])
        diagnosis["onu_signal_smrt"] = smartolt.get_onu_signals(base["unique_external_id"])
        diagnosis["onu_vlan"] = smartolt.get_attached_vlans(base["unique_external_id"])

        # ISPCube
        # conn_info = ispcube.obtener_conexion_por_pppoe(pppoe_user)
        # diagnosis["ispcube_status"] = conn_info.get("status")

        # plan = ispcube.obtener_plan(conn_info.get("plan_id"))
        # diagnosis["plan"] = plan.get("name")
        # diagnosis["speed"] = plan.get("speed")

        return diagnosis
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}. Detalles: {e}")
        return diagnosis # type: ignore
    finally:
        db.close()

==================================================
ARCHIVO: txt\ispcube.py.txt
==================================================

import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call

ISPCUBE_BASEURL = config.ISPCUBE_BASEURL
ISPCUBE_APIKEY = config.ISPCUBE_APIKEY
ISPCUBE_USER = config.ISPCUBE_USER
ISPCUBE_PASSWORD = config.ISPCUBE_PASSWORD
ISPCUBE_CLIENTID = config.ISPCUBE_CLIENTID

# Cache interno del token
_token_cache = None


def _obtener_token():
    """Solicita un nuevo token a ISPCube."""
    url = f"{ISPCUBE_BASEURL}/sanctum/token"
    payload = {"username": ISPCUBE_USER, "password": ISPCUBE_PASSWORD}
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api"
    }
    resp = requests.post(url, json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()["token"]


def _get_token(force_refresh=False):
    """Devuelve un token v√°lido, renovando si es necesario."""
    global _token_cache
    if force_refresh or _token_cache is None:
        _token_cache = _obtener_token()
    return _token_cache

def _headers(token=None):
    """Headers est√°ndar para todas las llamadas."""
    return {
        "Authorization": f"Bearer {token or _get_token()}",
        "api-key": ISPCUBE_APIKEY,
        "client-id": ISPCUBE_CLIENTID,
        "login-type": "api",
        "Accept": "application/json",
        "username": ISPCUBE_USER
    }


def _request(method, url, **kwargs):
    """
    Wrapper de requests que maneja expiraci√≥n de token.
    Si recibe 401, renueva token y reintenta una vez.
    """
    token = _get_token()
    headers = kwargs.pop("headers", {})
    headers.update(_headers(token))
    resp = requests.request(method, url, headers=headers, **kwargs)
    if resp.status_code == 401:
        # Token expirado ‚Üí renovar y reintentar
        logger.warning("Token expirado, renovando...")
        token = _get_token(force_refresh=True)
        headers.update(_headers(token))
        resp = requests.request(method, url, headers=headers, **kwargs)
    resp.raise_for_status()
    return resp

# ------------------ Funciones p√∫blicas ------------------

def obtener_nodos():
    """Devuelve lista de nodos con id, name, ip."""
    url = f"{ISPCUBE_BASEURL}/nodes/nodes_list"
    resp = _request("GET", url)
    body = resp.json()
    items = body["data"] if isinstance(body, dict) and "data" in body else body
    nodos = []
    for n in items:
        nodos.append({
            "id": n.get("id"),
            "name": n.get("comment"),
            "ip": n.get("ip"),
            "puerto": n.get("port")
        })
    return nodos


def obtener_conexion(pppoe):
    """Busca conexi√≥n por PPPoE y devuelve (conn_id, nodo_actual)."""
    url = f"{ISPCUBE_BASEURL}/connections?pppoe={pppoe}"
    resp = _request("GET", url)
    data = resp.json()
    if data:
        conn = data[0]
        return conn["id"], conn.get("node_id")
    logger.error(f"No se encontr√≥ conexi√≥n en ISPCube para {pppoe}")


def obtener_conexion_por_pppoe(pppoe_user):
    """
    Busca cliente por PPPoE y devuelve (conn_id, nodo_actual).
    """
    url = f"{ISPCUBE_BASEURL}/connection?user={pppoe_user}"
    resp = _request("GET", url)
    cliente = resp.json()

    conexiones = cliente.get("connections", [])
    if not conexiones:
        logger.error(f"No se encontraron conexiones para PPPoE {pppoe_user}")

    for conn in conexiones:
        if conn.get("conntype") == "pppoe" and conn.get("user") == pppoe_user:
            return conn["id"], conn.get("node_id")

    logger.error(f"No se encontr√≥ conexi√≥n PPPoE exacta para {pppoe_user}")


def obtener_todas_conexiones():
    """
    Devuelve lista de conexiones con datos b√°sicos:
    user (PPPoE), customer_id, id (conn_id), node_id, plan_id.
    """
    url = f"{ISPCUBE_BASEURL}/connections/connections_list"
    resp = _request("GET", url)
    conexiones = resp.json()

    if not isinstance(conexiones, list):
        logger.error("Respuesta inesperada de ISPCube al listar conexiones")

    resultado = []
    for c in conexiones:
        if c.get("conntype") == "pppoe":
            resultado.append({
                "user": c.get("user"),
                "customer_id": c.get("customer_id"),
                "id": c.get("id"),
                "node_id": c.get("node_id"),
                "plan_id": c.get("plan_id"),
                "direccion": c.get("address")
            })
    return resultado


def obtener_planes():
    """
    Devuelve lista de planes con id, nombre, velocidad y descripci√≥n.
    """
    url = f"{ISPCUBE_BASEURL}/plans/plans_list"
    resp = _request("GET", url)
    planes = resp.json()

    if not isinstance(planes, list):
        logger.error("Respuesta inesperada de ISPCube al listar planes")

    resultado = []
    for p in planes:
        resultado.append({
            "id": p.get("id"),
            "name": p.get("name"),
            "speed": p.get("speed"),
            "comment": p.get("comment")
        })
    return resultado

def obtener_clientes():
    """
    Devuelve lista completa de clientes desde ISPCube.
    Incluye todos los campos que el endpoint expone.
    """
    url = f"{ISPCUBE_BASEURL}/customers/customers_list"
    resp = _request("GET", url)
    data = resp.json()

    if not isinstance(data, list):
        logger.error("Respuesta inesperada de ISPCube al listar clientes")
        return []

    return data



==================================================
ARCHIVO: txt\main.py.txt
==================================================

from fastapi import FastAPI, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
from app import config
from app.services.diagnostico import consultar_diagnostico
from app.security import get_api_key
from fastapi import FastAPI, Depends
from app.config import logger
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Beholder - Diagn√≥stico Centralizado")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # o ["http://localhost:5173"] si quer√©s restringir
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
def startup_event():
    config.logger.info("Servicio Beholder iniciado.")

# API key middleware (modificado para permitir OPTIONS)
@app.middleware("http")
async def check_api_key(request: Request, call_next):
    if request.method == "OPTIONS":
        return await call_next(request)

    key = request.headers.get("x-api-key")
    if key != config.API_KEY:
        return JSONResponse(status_code=401, content={"detail": "unauthorized"})

    return await call_next(request)


@app.get("/health")
def health():
    return {"ok": True, "service": "beholder", "status": "running"}

@app.get("/diagnosis/{pppoe_user}")
def diagnosis(pppoe_user: str):
    try:
        row = consultar_diagnostico(pppoe_user)
    except Exception as e:
        logger.exception(f"Error en diagn√≥stico de {pppoe_user}")
        raise HTTPException(status_code=500, detail=str(e))
    if "error" in row:
        raise HTTPException(status_code=404, detail=row["error"])
    return row

    
    # row = consultar_diagnostico(pppoe_user)
    # if "error" in row:
    #     return JSONResponse(status_code=404, content={"detail": row["error"]})
    # return row  # devuelve el dict completo con claves sem√°nticas

@app.get("/")
def read_root(api_key: str = Depends(get_api_key)):
    return {"status": "ok", "service": "Beholder API"}


==================================================
ARCHIVO: txt\mikrotik.py.txt
==================================================
import time
from app.config import logger
from app.utils.safe_call import safe_call
from routeros_api import RouterOsApiPool
from app import config

# Credenciales comunes para todos los Mikrotik
MIKROTIK_USER = config.MK_USER
MIKROTIK_PASS = config.MK_PASS
MIKROTIK_PORT = config.MK_PORT   # üëà tu puerto personalizado
MIKROTIK_IP   = config.MK_HOST  

#Nota para producci√≥n: borrar =MIKROTIK_IP y pasar IP como par√°metro en cada funci√≥n

def _connect(router_ip, port, username=MIKROTIK_USER, password=MIKROTIK_PASS):
    try:
        pool = RouterOsApiPool(
            router_ip,
            username=username, # type: ignore
            password=password, # type: ignore
            port=port,              
            plaintext_login=True
        )
        return pool, pool.get_api()
    except Exception as e:
        logger.error(f"Error de conexi√≥n al router {router_ip}: {e}")
        return {"error": str(e)}

def obtener_secret(router_ip, pppoe_user, puerto): #MIKROTIK_IP, router_ip
    try:
        pool, api = _connect(router_ip, puerto)
        secrets = api.get_resource('/ppp/secret')
        result = secrets.get(name=pppoe_user)
        pool.disconnect()
        if not result:
            logger.error(f"Secret {pppoe_user} no encontrado en {router_ip}")
        return result[0]
    except Exception as e:
        logger.error(f"Error al obtener secret {pppoe_user} en {router_ip}: {e}")
        return {"error": str(e)}
    
# def crear_secret(router_ip, datos_secret):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     secrets.add(
#         name=datos_secret['name'] + "R", # Borrar la "R" para producci√≥n
#         password=datos_secret['password'],
#         profile=datos_secret.get('profile', 'default'),
#         service=datos_secret.get('service', 'pppoe')
#     )
#     pool.disconnect()
#     logger.info(f"Secret {datos_secret['name']} creado en {router_ip}")

# def borrar_secret(router_ip, pppoe_user):
#     pool, api = _connect(router_ip)
#     secrets = api.get_resource('/ppp/secret')
#     result = secrets.get(name=pppoe_user)
#     if result:
#         secret = result[0]
#         secret_id = secret.get('.id') or secret.get('id')

#         #id=result[0]['.id']
#         secrets.remove(id=secret_id)
#         logger.info(f"Secret {pppoe_user} eliminado de {router_ip}")
#     pool.disconnect()

# def migrar_secret(origen_ip, destino_ip, pppoe_user):
   
#     datos = obtener_secret(origen_ip, pppoe_user)


#     crear_secret(destino_ip, datos)
#     # Validaci√≥n inicial
#     if not validar_pppoe(destino_ip, pppoe_user):
#         logger.info(f"Esperando 60s para revalidar {pppoe_user} en {destino_ip}...")
#         time.sleep(60)

#         # Segundo intento
#         if not validar_pppoe(destino_ip, pppoe_user):
#             logger.error(f"‚ùå {pppoe_user} no levant√≥ en {destino_ip}, rollback.")
#             #borrar_secret(destino_ip, pppoe_user)
#             return False

#     # Si lleg√≥ ac√°, est√° online ‚Üí borrar en origen
#     borrar_secret(origen_ip, pppoe_user)
#     logger.info(f"‚úÖ {pppoe_user} migrado de {origen_ip} a {destino_ip}")
#     return True


# def rollback_secret(origen_ip, destino_ip, pppoe_user):
    
#     origen_ip = MIKROTIK_IP #borrar para producci√≥n
#     destino_ip = MIKROTIK_IP #borrar para producci√≥n

#     datos = obtener_secret(destino_ip, pppoe_user)
#     crear_secret(origen_ip, datos)
#     borrar_secret(destino_ip, pppoe_user)
#     return True

def validar_pppoe(router_ip: str, pppoe_user: str, puerto: str) -> dict:
    try:
        pool, api = _connect(router_ip, puerto)
        #pool, api = _connect(MIKROTIK_IP) #borrar para producci√≥n
        activos = api.get_resource('/ppp/active')
        result = activos.get(name=pppoe_user)
        pool.disconnect()

        if result:
            logger.info(f"PPP user {pppoe_user} activo en {router_ip}")
            return {"active": True, **result[0]}
        else:
            logger.warning(f"PPP user {pppoe_user} NO activo en {router_ip}")
            try:
                #modificar aca
                secret = obtener_secret(router_ip, pppoe_user, puerto)
                return {"active": False, "secret": secret}
            except Exception:
                return {"active": False}
    except Exception as e:
        logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
        return {"active": False, "error": str(e)}
        # Si no est√° activo y no se encuentra el secret, no se puede obtener m√°s info
# def validar_pppoe(router_ip: str, pppoe_user: str) -> dict:
#     try:
#         pool, api = _connect(router_ip)
#         activos = api.get_resource('/ppp/active')
#         result = activos.get(name=pppoe_user)
#         pool.disconnect()

#         if result:
#             # Tomamos el primer dict y lo expandimos directamente
#             return {"active": True, **result[0]}
#         else:
#             return {"active": False}
#     except Exception as e:
#         logger.error(f"Error al validar PPPoE en {router_ip}: {e}")
#         return {"active": False, "error": str(e)}


==================================================
ARCHIVO: txt\OutputBox.tsx.txt
==================================================

import CopyButton from "./CopyButton";

interface OutputBoxProps {
  data: any;
}

export default function OutputBox({ data }: OutputBoxProps) {
  const traducciones: Record<string, string> = {
    Online: "En l√≠nea",
    "Power fail": "Problema de energ√≠a",
    LOS: "Sin se√±al/sin luz",
    Offline: "Fuera de l√≠nea",
    true: "Conectado",
    false: "Desconectado",
    Critical: "Cr√≠tico - Luz muy alta",
    Warning: "Advertencia - Luz alta",
    "Very good": "Muy buena - Luz √≥ptima",
  };

  // Texto plano para copiar
  const outputText = `
    Cliente: ${data?.cliente_nombre ?? "-"}
    Domicilio: ${data?.direccion ?? "-"}
    Plan: ${data?.plan ?? "-"}
    Nodo: ${data?.nodo_nombre ? data.nodo_nombre + " - " + (data?.nodo_ip ?? "-") : "-"}
    OLT: ${data?.OLT ?? "-"}
    PPPoE User: ${data?.pppoe_username ?? "-"}
    Estado PPPoE: ${traducciones[data?.mikrotik?.active] ?? "-"}
    Tiempo activo: ${data?.mikrotik?.uptime ?? "-"}
    √öltima conexi√≥n: ${data?.mikrotik?.secret?.["last-logged-out"] ?? "-"}
    ONU s/n: ${data?.onu_sn ?? "-"}
    ONU Estado: ${traducciones[data?.onu_status_smrt?.onu_status] ?? "-"}
    ONU √öltimo cambio de estado: ${data?.onu_status_smrt?.last_status_change ?? "-"}
    ONU Se√±al: ${traducciones[data?.onu_signal_smrt?.onu_signal] ?? "-"}
    ONU Se√±al Detalle: ${data?.onu_signal_smrt?.onu_signal_value ?? "-"}
    `;

  return (
    <div className="border rounded p-4 mt-4 bg-gray-50">
      <div className="header-row">
        <h3 className="diagnostic-title">Diagn√≥stico normalizado</h3>
        <CopyButton text={outputText} />
      </div>
      <div className="bg-white p-2 rounded font-mono whitespace-pre-wrap">
      <div className="grid">
        <div className="cell span-2"><strong>Cliente:</strong> {data?.cliente_nombre ?? "-"}</div>
        <div className="cell span-2"><strong>Domicilio:</strong> {data?.direccion ?? "-"}</div>
        <div className="cell"><strong>Plan:</strong> {data?.plan ?? "-"}</div>
        <div className="cell"><strong>Nodo:</strong> {data?.nodo_nombre ? data.nodo_nombre + " - " + (data?.nodo_ip ?? "-") : "-"}</div>
        <div className="cell"><strong>OLT:</strong> {data?.OLT ?? "-"}</div>
        <div className={`cell ${data?.mikrotik?.active ? "estado-ok" : "estado-error"}`}>
          <strong>Estado PPPoE:</strong> {traducciones[data?.mikrotik?.active] ?? "-"}
        </div>
        <div className="cell"><strong>Tiempo activo:</strong> {data?.mikrotik?.uptime ?? "-"}</div>
        <div className="cell"><strong>√öltima conexi√≥n:</strong> {data?.mikrotik?.secret?.["last-logged-out"] ?? "-"}</div>
        <div className="cell"><strong>ONU s/n:</strong> {data?.onu_sn ?? "-"}</div>
        <div className={`cell ${data?.onu_status_smrt?.onu_status === "Online" ? "estado-ok" : "estado-error"}`}>
          <strong>ONU Estado:</strong> {traducciones[data?.onu_status_smrt?.onu_status] ?? "-"}
        </div>
        <div className="cell"><strong>√öltimo cambio de estado:</strong> {data?.onu_status_smrt?.last_status_change ?? "-"}</div>
        <div className="cell"><strong>ONU Se√±al:</strong> {traducciones[data?.onu_signal_smrt?.onu_signal] ?? "-"}</div>
        <div className="cell"><strong>Se√±al Detalle:</strong> {data?.onu_signal_smrt?.onu_signal_value ?? "-"}</div>
        </div>
        
      </div>
      <CopyButton text={outputText} />
    </div>
    //luego agregar los demas campos de datos de cliente
  );
}

==================================================
ARCHIVO: txt\SearchBox.tsx.txt
==================================================
import { useState } from "react";

export default function SearchBox({ onResult }: { onResult: (data: any) => void }) {
  const [pppoe, setPppoe] = useState("");
  const [error, setError] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);

  const handleSearch = async () => {
    setLoading(true);
    setError(null);

    try {
      const resp = await fetch(
        `${import.meta.env.VITE_API_URL}/diagnosis/${pppoe}`,
        {
          headers: {
            "x-api-key": import.meta.env.VITE_API_KEY,
          },
        }
      );

      if (!resp.ok) {
        throw new Error(`Error ${resp.status}: ${resp.statusText}`);
      }

      const json = await resp.json();
      onResult(json); // enviar resultado al padre
    } catch (err: any) {
      setError(err.message);
      onResult(null); // limpiar resultado si hay error
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="p-4">
      <input
        type="text"
        value={pppoe}
        onChange={(e) => setPppoe(e.target.value)}
        onKeyDown={(e) => {
          if (e.key === "Enter") {
            handleSearch();
          }
        }}
        placeholder="Ingrese PPPoE"
        className="border px-2 py-1 mr-2"
      />
      <button
        onClick={handleSearch}
        className="bg-blue-600 text-white px-3 py-1 rounded"
      >
        Buscar
      </button>

      {loading && <p>Buscando...</p>}
      {error && <p className="text-red-600">Error: {error}</p>}
    </div>
  );
}

==================================================
ARCHIVO: txt\security.py.txt
==================================================
import os
from fastapi import FastAPI, Depends, HTTPException, Security
from fastapi.security.api_key import APIKeyHeader
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")
api_key_header = APIKeyHeader(name="X-API-Key")

def get_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="unauthorized")
    return api_key

==================================================
ARCHIVO: txt\smartolt.py.txt
==================================================
import requests
from app import config
from app.config import logger
from app.utils.safe_call import safe_call 

SMARTOLT_BASEURL = config.SMARTOLT_BASEURL
SMARTOLT_TOKEN = config.SMARTOLT_TOKEN


def _request(method, endpoint, **kwargs):
    try:
        headers = kwargs.pop("headers", {})
        headers["X-Token"] = SMARTOLT_TOKEN
        url = f"{SMARTOLT_BASEURL}{endpoint}"
        resp = requests.request(method, url, headers=headers, **kwargs)
        resp.raise_for_status()
        return resp
    except Exception as e:
        logger.error(f"Error en request API smartOLT: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}


def get_all_onus():
    try:
        """Devuelve el lote completo de ONUs desde SmartOLT."""
        resp = _request("GET", "/onu/get_all_onus_details")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error("SmartOLT no devolvi√≥ estado OK")
        return data.get("onus", [])
    except Exception as e:
        logger.error(f"Error al obtener listado de onus: {e}")
        return {"estado": "error", "API smartOLT detalle": str(e)}
    

def get_onu_status(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_status/{onu_id}")
        data = resp.json() # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data 
    except Exception as e:
        logger.error(f"Error al consultar estado ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}


def get_onu_signals(onu_id):
    try:
        resp = _request("GET", f"/onu/get_onu_signal/{onu_id}")
        data = resp.json()  # type : ignore
        if not data.get("status"):
            logger.error(f"SmartOLT no devolvi√≥ estado OK para ONU {onu_id}")
        return data
    except Exception as e:
        logger.error(f"Error al consultar se√±ales ONU {onu_id}: {e}")
        return {"estado": "error", "API smartOLT, detalle": str(e)}
    
def get_attached_vlans(onu_id):
    """Obtiene las VLANs adjuntas de una ONU por external_id."""
    #lista el detalle de la onu, para sacar las attached vlans de sus serviceports
    
    resp = _request("GET", f"/onu/get_onu_details/{onu_id}")
    data = resp.json()
    vlans = []
    if data.get("status"):
        serviceports = data["onu_details"].get("service_ports", [])
        vlans = [sp["vlan"] for sp in serviceports if "vlan" in sp]

    return vlans

==================================================
ARCHIVO: txt\sqlite.py.txt
==================================================
# app/db/sqlite.py
import sqlite3
from app import config
from datetime import datetime


class Database:
    def __init__(self, path=config.DB_PATH):
        self.conn = sqlite3.connect(path)
        self.cursor = self.conn.cursor()

    def insert_subscriber(self, unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode):
        self.cursor.execute("""
            INSERT OR REPLACE INTO subscribers (
                unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, pppoe_username, mode
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (unique_external_id, sn, olt_name, olt_id, board, port, onu, onu_type_id, name, mode))

    def insert_node(self, node_id, name, ip_address, puerto):
        self.cursor.execute("""
            INSERT OR REPLACE INTO nodes (node_id, name, ip_address, puerto)
            VALUES (?, ?, ?, ?)
        """, (node_id, name, ip_address, puerto))

    def insert_plan(self, plan_id, name, speed, description):
        self.cursor.execute("""
            INSERT OR REPLACE INTO plans (plan_id, name, speed, description)
            VALUES (?, ?, ?, ?)
        """, (plan_id, name, speed, description))

    def insert_connection(self, connection_id, pppoe_username, customer_id, node_id, plan_id, direccion=None):
        self.cursor.execute("""
            INSERT OR REPLACE INTO connections (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (connection_id, pppoe_username, customer_id, node_id, plan_id, direccion))

    def insert_cliente(self, cliente_data: dict):
        columns = ', '.join(cliente_data.keys())
        placeholders = ', '.join('?' for _ in cliente_data)
        values = tuple(cliente_data.values())
        self.cursor.execute(f"""
            INSERT OR REPLACE INTO clientes ({columns})
            VALUES ({placeholders})
        """, values)
    
    def insert_cliente_email(self, customer_id: int, email: str):
        self.cursor.execute("""
            INSERT INTO clientes_emails (customer_id, email)
            VALUES (?, ?)
        """, (customer_id, email))
    
    def insert_cliente_telefono(self, customer_id: int, number: str):
        self.cursor.execute("""
            INSERT INTO clientes_telefonos (customer_id, number)
            VALUES (?, ?)
        """, (customer_id, number))
    
    def match_connections(self):
        self.cursor.execute("""
            UPDATE subscribers
            SET node_id = (
                SELECT node_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            ),
            connection_id = (
                SELECT connection_id FROM connections
                WHERE connections.pppoe_username = subscribers.pppoe_username
            )
        """)
    
    def log_sync_status(self, fuente: str, estado: str, detalle: str = ""):
        """Registra el estado de sincronizaci√≥n de una fuente"""
        self.cursor.execute("""
            INSERT INTO sync_status (fuente, ultima_actualizacion, estado, detalle)
            VALUES (?, ?, ?, ?)
        """, (fuente, datetime.now(), estado, detalle))
        self.commit()

    def get_diagnosis(self, pppoe_user: str) -> dict:
        query = """
        SELECT s.unique_external_id,
                s.pppoe_username,
                s.sn AS onu_sn,
                s.mode as Modo,
                s.olt_name AS OLT,
                n.name AS nodo_nombre,
                n.ip_address AS nodo_ip,
                n.puerto AS puerto,
                p.name AS plan,
                c.direccion AS direccion,
                l.name AS cliente_nombre
        FROM clientes l
        LEFT JOIN connections c ON l.id = c.customer_id
        LEFT JOIN subscribers s ON c.pppoe_username = s.pppoe_username
        LEFT JOIN nodes n ON c.node_id = n.node_id
        LEFT JOIN plans p ON c.plan_id = p.plan_id
        WHERE c.pppoe_username = ?
        """
        self.cursor.execute(query, (pppoe_user,))
        row = self.cursor.fetchone()

        if not row:
            return {"error": f"Cliente {pppoe_user} no encontrado"}

        diagnosis = {
            "unique_external_id": row[0],
            "pppoe_username": row[1],
            "onu_sn": row[2],
            "Modo": row[3],
            "OLT": row[4],
            "nodo_nombre": row[5],
            "nodo_ip": row[6],
            "puerto": row[7],
            "plan": row[8],
            "direccion": row[9],
            "cliente_nombre": row[10]
        }
        return diagnosis
    
    

    def commit(self):
        self.conn.commit()

    def close(self):
        self.conn.close()

### Fin de la clase Database ###
def columnas_tabla(conn, tabla: str) -> set:
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({tabla})")
        return {row[1] for row in cur.fetchall()}  # row[1] = nombre columna

def insert_cliente_safe(db, json_cliente: dict):
    cols = columnas_tabla(db.conn, "clientes")
    data = mapear_cliente(json_cliente)

    # Filtrar a solo columnas v√°lidas
    data_filtrada = {k: v for k, v in data.items() if k in cols}

    # Reusar tu m√©todo din√°mico
    db.insert_cliente(data_filtrada)


# Inicializaci√≥n de la base de datos y creaci√≥n de tablas
def init_db():
    conn = sqlite3.connect(config.DB_PATH)
    cursor = conn.cursor()

    # Tabla de suscriptores (SmartOLT)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS subscribers (
            unique_external_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            sn TEXT,
            olt_name TEXT,
            olt_id TEXT,
            board TEXT,
            port TEXT,
            onu TEXT,
            onu_type_id TEXT,
            mode TEXT,
            node_id TEXT,
            connection_id TEXT,
            vlan TEXT
        )
    """)

    # Tabla de nodos (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS nodes (
            node_id TEXT PRIMARY KEY,
            name TEXT,          -- nombre del nodo (comment en ISPCube)
            ip_address TEXT,
            puerto TEXT
        )
    """)

    # Tabla de planes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS plans (
            plan_id TEXT PRIMARY KEY,
            name TEXT,
            speed TEXT,
            description TEXT
        )
    """)

    # Tabla de conexiones (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS connections (
            connection_id TEXT PRIMARY KEY,
            pppoe_username TEXT,
            customer_id TEXT,
            node_id TEXT,
            plan_id TEXT,
            direccion TEXT
        )
    """)
    
     # Tabla de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes (
            id INTEGER PRIMARY KEY,              -- id del cliente
            code TEXT,
            name TEXT,
            tax_residence TEXT,
            type TEXT,
            tax_situation_id INTEGER,
            identification_type_id INTEGER,
            doc_number TEXT,
            auto_bill_sending INTEGER,
            auto_payment_recipe_sending INTEGER,
            nickname TEXT,
            comercial_activity TEXT,
            address TEXT,
            between_address1 TEXT,
            between_address2 TEXT,
            city_id INTEGER,
            lat TEXT,
            lng TEXT,
            extra1 TEXT,
            extra2 TEXT,
            entity_id INTEGER,
            collector_id INTEGER,
            seller_id INTEGER,
            block INTEGER,
            free INTEGER,
            apply_late_payment_due INTEGER,
            apply_reconnection INTEGER,
            contract INTEGER,
            contract_type_id INTEGER,
            contract_expiration_date TEXT,
            paycomm TEXT,
            expiration_type_id INTEGER,
            business_id INTEGER,
            first_expiration_date TEXT,
            second_expiration_date TEXT,
            next_month_corresponding_date INTEGER,
            start_date TEXT,
            perception_id INTEGER,
            phonekey TEXT,
            debt TEXT,
            duedebt TEXT,
            speed_limited INTEGER,
            status TEXT,
            enable_date TEXT,
            block_date TEXT,
            created_at TEXT,
            updated_at TEXT,
            deleted_at TEXT,
            temporary INTEGER
        )

    """)

    #Tabla de emails de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_emails (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            email TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    #Tabla de tel√©fonos de clientes (ISPCube)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS clientes_telefonos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            customer_id INTEGER NOT NULL,
            number TEXT NOT NULL,
            FOREIGN KEY (customer_id) REFERENCES clientes(id)
        )
    """)

    # Tabla de estados de sincronizaci√≥n
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS sync_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            fuente TEXT NOT NULL,                 -- 'smartolt', 'ispcube', 'mikrotik', etc.
            ultima_actualizacion TEXT NOT NULL,   -- ISO 8601 (ej. '2025-11-26T19:45:00')
            estado TEXT NOT NULL,                 -- 'ok', 'empty', 'error'
            detalle TEXT
        )
    """)

    # √çndice √∫til para consultas por fuente y fecha
    cursor.execute("""
    CREATE INDEX IF NOT EXISTS idx_sync_status_fuente_fecha
    ON sync_status (fuente, ultima_actualizacion)
    """)


    conn.commit()
    conn.close()


==================================================
ARCHIVO: txt\sync.py.txt
==================================================
from app.db.sqlite import Database, init_db
from app.clients import smartolt, ispcube
from app import config
from app.utils.safe_call import safe_call


def sync_onus(db):
    onus = smartolt.get_all_onus()
    if onus:
        db.cursor.execute("DELETE FROM subscribers")
        for onu in onus:
            db.insert_subscriber(
                onu.get("unique_external_id"), # type: ignore
                onu.get("sn"), # type: ignore
                onu.get("olt_name"), # type: ignore
                onu.get("olt_id"), # type: ignore
                onu.get("board"), # type: ignore
                onu.get("port"), # type: ignore
                onu.get("onu"), # type: ignore
                onu.get("onu_type_id"), # type: ignore
                onu.get("name"), # type: ignore
                onu.get("mode") # type: ignore
            )
        db.log_sync_status("smartolt", "ok", f"{len(onus)} ONUs sincronizadas")
        config.logger.info(f"[SYNC] {len(onus)} ONUs sincronizadas.")
    else:
        db.log_sync_status("smartolt", "empty", "SmartOLT no devolvi√≥ datos, se mantienen registros anteriores")
        config.logger.info(f"[SYNC] no se pudo sincronizar ONUs.")


def sync_nodes(db):
    nodes = ispcube.obtener_nodos()
    if nodes:
        db.cursor.execute("DELETE FROM nodes")  # Limpia la tabla antes de insertar
    for n in nodes:
        db.insert_node(n["id"], n["name"], n["ip"], n["puerto"])
    config.logger.info(f"[SYNC] {len(nodes)} nodos sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(nodes)} nodos sincronizadas")


def sync_plans(db):
    planes = ispcube.obtener_planes()
    if planes:
        db.cursor.execute("DELETE FROM plans")  # Limpia la tabla antes de insertar 
    for p in planes:
        db.insert_plan(p["id"], p["name"], p.get("speed"), p.get("comment"))
    config.logger.info(f"[SYNC] {len(planes)} planes sincronizados.")
    db.log_sync_status("ispcube", "ok", f"{len(planes)} planes sincronizadas")


def sync_connections(db):
    conexiones = ispcube.obtener_todas_conexiones()
    if conexiones:
        db.cursor.execute("DELETE FROM connections")  # Limpia la tabla antes de insertar
    for c in conexiones:
        db.insert_connection(c["id"], c["user"], c["customer_id"], c["node_id"], c["plan_id"], c.get("direccion"))
    config.logger.info(f"[SYNC] {len(conexiones)} conexiones sincronizadas.")
    db.log_sync_status("ispcube", "ok", f"{len(conexiones)} conecciones sincronizadas")

def sync_clientes(db):
    clientes = ispcube.obtener_clientes()  # debe devolver la lista completa cruda del endpoint
    if clientes:
        db.cursor.execute("DELETE FROM clientes")
        db.cursor.execute("DELETE FROM clientes_emails")
        db.cursor.execute("DELETE FROM clientes_telefonos")

        for c in clientes:
            cliente_data = mapear_cliente(c)
            db.insert_cliente(cliente_data)
            insertar_contactos_relacionados(db, c)

        db.commit()
        config.logger.info(f"[SYNC] {len(clientes)} clientes sincronizados.")
        db.log_sync_status("ispcube", "ok", f"{len(clientes)} clientes sincronizados")
    else:
        config.logger.warning("[SYNC] ISPCube no devolvi√≥ clientes")
        db.log_sync_status("ispcube", "empty", "Sin datos de clientes")

def insertar_contactos_relacionados(db, json_cliente: dict):
    # Emails
    for email_obj in json_cliente.get("contact_emails", []):
        email = email_obj.get("email")
        if email:
            db.insert_cliente_email(json_cliente["id"], email)

    # Tel√©fonos
    for tel_obj in json_cliente.get("phones", []):
        number = tel_obj.get("number")
        if number:
            db.insert_cliente_telefono(json_cliente["id"], number)

def nightly_sync():
    init_db()  # asegura el esquema antes de cualquier operaci√≥n
    db = Database()
    try:
        sync_onus(db)
        sync_clientes(db)
        sync_nodes(db)
        sync_plans(db)
        sync_connections(db)
        db.match_connections()
        db.commit()
        config.logger.info("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
        print("[SYNC] Base actualizada y relaciones PPPoE ‚Üí node_id ‚Üí connection_id completadas.")
    finally:
        db.close()


#------------------ Funciones de mapeo ------------------
#------------------
def mapear_cliente(json_cliente: dict) -> dict:
    """
    Convierte el JSON de ISPCube en un dict compatible con la tabla clientes.
    Incluye casi todos los campos del ejemplo.
    """
    return {
        "id": json_cliente.get("id"),
        "code": json_cliente.get("code"),
        "name": json_cliente.get("name"),
        "tax_residence": json_cliente.get("tax_residence"),
        "type": json_cliente.get("type"),
        "tax_situation_id": json_cliente.get("tax_situation_id"),
        "identification_type_id": json_cliente.get("identification_type_id"),
        "doc_number": json_cliente.get("doc_number"),
        "auto_bill_sending": json_cliente.get("auto_bill_sending"),
        "auto_payment_recipe_sending": json_cliente.get("auto_payment_recipe_sending"),
        "nickname": json_cliente.get("nickname"),
        "comercial_activity": json_cliente.get("comercial_activity"),
        "address": json_cliente.get("address"),
        "between_address1": json_cliente.get("between_address1"),
        "between_address2": json_cliente.get("between_address2"),
        "city_id": json_cliente.get("city_id"),
        "lat": json_cliente.get("lat"),
        "lng": json_cliente.get("lng"),
        "extra1": json_cliente.get("extra1"),
        "extra2": json_cliente.get("extra2"),
        "entity_id": json_cliente.get("entity_id"),
        "collector_id": json_cliente.get("collector_id"),
        "seller_id": json_cliente.get("seller_id"),
        "block": json_cliente.get("block"),
        "free": json_cliente.get("free"),
        "apply_late_payment_due": json_cliente.get("apply_late_payment_due"),
        "apply_reconnection": json_cliente.get("apply_reconnection"),
        "contract": json_cliente.get("contract"),
        "contract_type_id": json_cliente.get("contract_type_id"),
        "contract_expiration_date": json_cliente.get("contract_expiration_date"),
        "paycomm": json_cliente.get("paycomm"),
        "expiration_type_id": json_cliente.get("expiration_type_id"),
        "business_id": json_cliente.get("business_id"),
        "first_expiration_date": json_cliente.get("first_expiration_date"),
        "second_expiration_date": json_cliente.get("second_expiration_date"),
        "next_month_corresponding_date": json_cliente.get("next_month_corresponding_date"),
        "start_date": json_cliente.get("start_date"),
        "perception_id": json_cliente.get("perception_id"),
        "phonekey": json_cliente.get("phonekey"),
        "debt": json_cliente.get("debt"),
        "duedebt": json_cliente.get("duedebt"),
        "speed_limited": json_cliente.get("speed_limited"),
        "status": json_cliente.get("status"),
        "enable_date": json_cliente.get("enable_date"),
        "block_date": json_cliente.get("block_date"),
        "created_at": json_cliente.get("created_at"),
        "updated_at": json_cliente.get("updated_at"),
        "deleted_at": json_cliente.get("deleted_at"),
        "temporary": json_cliente.get("temporary"),
    }
#------------------

if __name__ == "__main__":
    try:
        nightly_sync()
    except Exception as e:
        print(f"[ERROR] Fall√≥ la sincronizaci√≥n: {e}")


